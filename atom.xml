<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ThreeLanes&#39; Site</title>
  
  <subtitle>共享 开放 包容 改进</subtitle>
  <link href="https://deepcity.github.io/atom.xml" rel="self"/>
  
  <link href="https://deepcity.github.io/"/>
  <updated>2024-08-31T08:55:02.749Z</updated>
  <id>https://deepcity.github.io/</id>
  
  <author>
    <name>ThreeLanes</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Anaconda简明介绍</title>
    <link href="https://deepcity.github.io/2024/Anaconda%E7%AE%80%E6%98%8E%E4%BB%8B%E7%BB%8D/article.html"/>
    <id>https://deepcity.github.io/2024/Anaconda%E7%AE%80%E6%98%8E%E4%BB%8B%E7%BB%8D/article.html</id>
    <published>2024-08-31T08:53:55.000Z</published>
    <updated>2024-08-31T08:55:02.749Z</updated>
    
    <content type="html"><![CDATA[<h1 id="anaconda简明介绍">Anaconda简明介绍</h1><p>已然是不知道从何处了解到的anaconda了，但它默认成为了我的python编译器指定选项，于是今天来了解一下Anaconda是什么，它是干什么的。</p><h2 id="包管理器">包管理器</h2><p>Anaconda（<span class="exturl" data-url="aHR0cHM6Ly93d3cuYW5hY29uZGEuY29tL2Rvd25sb2FkLyNtYWNvcw==">官方网站<i class="fa fa-external-link-alt"></i></span>）就是可以便捷获取包且对包能够进行管理，同时对环境可以统一管理的发行版本。Anaconda包含了conda、Python在内的超过180个科学包及其依赖项。</p><h3 id="特点">特点</h3><ol type="1"><li>anaconda是一款开源软件</li><li>其安装过程非常简单</li><li>其能够以很好的性能解释R语言与Python语言</li><li>其拥有丰富且免费的社区支持</li></ol><h3 id="内容">内容</h3><ol type="1"><li>conda包</li><li>环境管理器</li><li>1000+开源库</li></ol><h3 id="与其他包管理器的区别">与其他包管理器的区别</h3><h4 id="conda">conda</h4><p>conda是包及其依赖项和环境的管理工具。</p><p>▪ 适用语言：Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++,FORTRAN。</p><p>▪ 适用平台：Windows, macOS, Linux</p><p>▪ 用途：</p><p>① 快速安装、运行和升级包及其依赖项。</p><p>② 在计算机中便捷地创建、保存、加载和切换环境。</p><blockquote><p>如果你需要的包要求不同版本的Python，你无需切换到不同的环境，因为conda同样是一个<strong>环境管理器</strong>。仅需要几条命令，你可以创建一个完全独立的环境来运行不同的Python版本，同时继续在你常规的环境中使用你常用的Python版本。——<span class="exturl" data-url="aHR0cHM6Ly9jb25kYS5pby9kb2NzLw==">Conda官方网站<i class="fa fa-external-link-alt"></i></span></p></blockquote><p>▪ conda为Python项目而创造，但可适用于上述的多种语言。</p><p>▪ conda包和环境管理器包含于Anaconda的所有版本当中。</p><h4 id="pip">pip</h4><p>pip是用于安装和管理软件包的包管理器。</p><p>▪ pip编写语言：Python。</p><p>▪ Python中默认安装的版本：</p><p>① Python 2.7.9及后续版本：默认安装，命令为 *<strong>pip*</strong></p><p>② Python 3.4及后续版本：默认安装，命令为 *<strong>pip3*</strong></p><p>▪pip名称的由来：pip采用的是<strong>递归缩写</strong>进行命名的。其名字被普遍认为来源于2处：</p><p>① “Pip installs Packages”（“pip安装包”）</p><p>② “Pip installs Python”（“pip安装Python”）</p><h4 id="virtualenv"><strong>virtualenv</strong></h4><p>virtualenv是用于创建一个<strong>独立的</strong>Python环境的工具。</p><p>▪ 解决问题：</p><ol type="1"><li>当一个程序需要使用Python 2.7版本，而另一个程序需要使用Python3.6版本，如何同时使用这两个程序？如果将所有程序都安装在系统下的默认路径，如：*<strong>/usr/lib/python2.7/site-packages*</strong>，当不小心升级了本不该升级的程序时，将会对其他的程序造成影响。</li><li>如果想要安装程序并在程序运行时对其库或库的版本进行修改，都会导致程序的中断。</li><li>在共享主机时，无法在全局 *<strong>site-packages*</strong>目录中安装包。</li></ol><p>▪virtualenv将会为它自己的安装目录创建一个环境，这并<strong>不与</strong>其他virtualenv环境共享库；同时也可以<strong>选择性</strong>地不连接已安装的全局库。</p><h4 id="pip与conda的比较">pip与conda的比较</h4><p>▪ pip：</p><p>① <strong>不一定</strong>会展示所需其他依赖包。</p><p>②安装包时<strong>或许</strong>会直接忽略依赖项而安装，仅在结果中提示错误。</p><p>▪ conda：</p><p>① 列出所需其他依赖包。</p><p>② 安装包时自动安装其依赖项。</p><p>③ 可以便捷地在包的不同版本中自由切换。</p><p><strong>→ 环境管理</strong></p><p>▪ pip：维护多个环境难度较大。</p><p>▪ conda：比较方便地在不同环境之间进行切换，环境管理较为简单。</p><p><strong>→ 对系统自带Python的影响</strong></p><p>▪ pip：在系统自带Python中包的更新/回退版本/卸载将影响其他程序。</p><p>▪ conda：不会影响系统自带Python。</p><p><strong>→ 适用语言</strong></p><p>▪ pip：仅适用于Python。</p><p>▪ conda：适用于Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++,FORTRAN。</p><h4 id="conda与pipvirtualenv的关系">conda与pip、virtualenv的关系</h4><p>▪ conda<strong>结合</strong>了pip和virtualenv的功能。</p><h3 id="总结">总结</h3><p>它是一个开源的，多语言的，多平台的，依赖检查，版本独立且云端同步的包管理工具，用于保存切换不同的编译环境与第三方库。</p><h2 id="使用说明">使用说明</h2><ol type="1"><li><p>通过通过anaconda中的python解释器中的pip安装的包同样也会被anaconda所管理</p></li><li><p>可视化界面：在win上可以打开anaconda-nagvitive可视化界面，查看当前环境与包</p></li><li><p>云同步，需要登录，在win可视化界面右上角可以连接到anaconda云端即可实现同步</p></li><li><p>canda channel的配置</p><p>默认canda channel是default，但这个代码包不全，建议使用conda-forgechannel，并严格设置优先使用conda-forge，因为这不同channel的包不完全兼容。</p><p>在安装这个这个渠道的时候无论使用什么样的方式都是可以的，比如图形化又或者命令行。</p><p>有关命令行的配置方法放在参考文献里了．</p></li><li><p>我应该使用pip安装还是使用conda安装第三方包</p><p>随意，在网络上两种建议都有，使用pip安装比较直接，而使用conda安装可以检查依赖，但据说这这个检查环境兼容性可能有问题，因此，我的建议是先尽量使用pip，出现依赖问题用condainstall</p></li><li><p>他是如何切换换第三方库的？应该如何调用不同的环境</p><p>这里有几种方式</p><ol type="1"><li>使用它自己的命令行方式通过命令更换当前所用的环境</li><li>通过图形界面或者命令找到每个环境对应的python.exe或其他语言编译可执行程序，通过调用这个程序获取不同的第三方库。</li></ol></li></ol><h2 id="参考文献">参考文献</h2><ol type="1"><li><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMjkyNTUwMA==">Anaconda介绍、安装及使用教程- 知乎 (zhihu.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zNDkwODEzNDQ=">Anaconda channel配置笔记 - 知乎 (zhihu.com)<i class="fa fa-external-link-alt"></i></span></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;anaconda简明介绍&quot;&gt;Anaconda简明介绍&lt;/h1&gt;
&lt;p&gt;已然是不知道从何处了解到的anaconda了，但它默认成为了我的python编译器指定选项，于是今天来了解一下Anaconda是什么，它是干什么的。&lt;/p&gt;
&lt;h2 id=&quot;包管理器&quot;&gt;包管</summary>
      
    
    
    
    <category term="软件" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="环境" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/%E7%8E%AF%E5%A2%83/"/>
    
    <category term="Anaconda" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/%E7%8E%AF%E5%A2%83/Anaconda/"/>
    
    
    <category term="Anaconda" scheme="https://deepcity.github.io/tags/Anaconda/"/>
    
    <category term="Python" scheme="https://deepcity.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Overleaf-toolkit部署</title>
    <link href="https://deepcity.github.io/2024/Overleaf-toolkit%E9%83%A8%E7%BD%B2/article.html"/>
    <id>https://deepcity.github.io/2024/Overleaf-toolkit%E9%83%A8%E7%BD%B2/article.html</id>
    <published>2024-08-25T09:22:58.000Z</published>
    <updated>2024-08-26T03:37:10.378Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Overleaf-toolkit部署"><a href="#Overleaf-toolkit部署" class="headerlink" title="Overleaf-toolkit部署"></a>Overleaf-toolkit部署</h1><blockquote><p>在写latex的过程中，第一个使用的在线latex编辑器就是overleaf，但是在使用过程中受到诸多限制，遂欲购买overleafpro，但发现其学生价也要500yuan/year，实在是财力不足，但overleaf是开源的，要花钱的只是服务器算力以及各种模板，于是就有了部署Overleaf-toolkit的想法</p></blockquote><p>Overleaf是一个在线多用户协作的Latex编辑网站，其采用了如同markdown的“所见即所得”思想，采用及时更新编译的方式辅助编辑latex文件，同时通过项目结构约束文件的排布。是一个是十分学术且普遍应用的latex编辑网站。</p><span id="more"></span><h2 id="安装前置条件"><a href="#安装前置条件" class="headerlink" title="安装前置条件"></a>安装前置条件</h2><ol><li>一台性能至少为2h/2g的服务器（cpu2h空闲且性能较强且剩余内存至少1.5g），个人使用也可以是一台虚拟机。</li><li>并且至少保留10g的内存余量</li><li>最好有个域名。</li></ol><p><img src="https://s2.loli.net/2024/08/25/Gc4RtmuqsK6lQM8.png" alt="Usage"></p><p>上图为容器运行后各个模块对资源的占用量，值得注意的是在本机中，配置好完整的texlatex与中文字集，对硬盘占用量达到了十个g，并且本机cpu为i7-11800h</p><h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><p>以下部分可能省略部分操作在参考资料中可以找到</p><h3 id="安装overleaf-toolkit"><a href="#安装overleaf-toolkit" class="headerlink" title="安装overleaf-toolkit"></a>安装overleaf-toolkit</h3><p>这一步十分简单，按照overleafgithub官方库中给的教程即可，唯一需要注意的点如下：</p><ol><li>修改overleaf.rc文件需要关闭所有相关服务并bin/up重新生成docker，慎重第一次生成</li><li>默认占用80端口，但是如果服务器配置了nginx并且希望方向代理，则需要更改overleaf.rc文件<ul><li><code>OVERLEAF_PORT</code> 指的是运行 Overleaf 的容器要选择曝露的端口，默认是 80 端口但如果有要使用 Nginx 反向代理的需求的话则需要自选一个端口（不常用的就行）；</li><li><code>SIBLING_CONTAINERS_ENABLED</code> 这个配置真的巨坑，默认的话是 <code>true</code> 但如果没有购买官方的 Server Pro 的话请直接修改成 <code>false</code>，因为这个功能很大程度上依赖于官方提供给 Server Pro 用户的镜像，如果不调到 <code>false</code> 的话极有可能出现编译失败的情况；</li></ul></li><li>站点标题在variables.env中</li></ol><h2 id="一些基础配置"><a href="#一些基础配置" class="headerlink" title="一些基础配置"></a>一些基础配置</h2><h3 id="安装完整版texLive"><a href="#安装完整版texLive" class="headerlink" title="安装完整版texLive"></a>安装完整版texLive</h3><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL292ZXJsZWFmL3Rvb2xraXQvYmxvYi9tYXN0ZXIvZG9jL2NlLXVwZ3JhZGluZy10ZXhsaXZlLm1kP3NwbT1hMmM2aC4xMjg3MzYzOS5hcnRpY2xlLWRldGFpbC4xNC41YTMzNjk0NVVtU01peCZmaWxlPWNlLXVwZ3JhZGluZy10ZXhsaXZlLm1k">官方升级TexLive文档<i class="fa fa-external-link-alt"></i></span></p><p>根据官方文档升级即可，注意version很有可能是不同的，overleaf官方每隔半年就会更新一次，因此，需要修改部分命令，如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker commit sharelatex sharelatex/sharelatex:[version]-with-texlive-full</span><br><span class="line">echo [version]-with-texlive-full &gt; config/version</span><br></pre></td></tr></table></figure><h3 id="新增中文字体"><a href="#新增中文字体" class="headerlink" title="新增中文字体"></a>新增中文字体</h3><p>我们可以通过导入我们自己电脑中的中文字体做到这一步</p><ol><li><p>如何将自己电脑中的winfonts.tar.gz生成出来</p><ol><li><p><img src="https://s2.loli.net/2024/08/24/iWBOjIt7LwRvDSe.png" alt="字体文件夹"></p><p>找到上图的这个文件夹，复制走想要的字体（绝大部分中文字体），然后压缩为winfonts.tar.gz(任意格式)</p></li><li><p>ftp传到linux主机中就好</p></li></ol></li><li><p>继续参照参考资料2进入docker操作</p><ol><li><p>安装必要的包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it share</span><br><span class="line">apt update</span><br><span class="line">apt install -y latex-cjk-all texlive-lang-chinese texlive-lang-english</span><br><span class="line">apt install -y xfonts-wqy</span><br></pre></td></tr></table></figure></li><li><p>将所有字体文件移动到/usr/share/fonts/winfonts中并执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkfontscale</span><br><span class="line">mkfontdir</span><br><span class="line">fc-cache -fv</span><br></pre></td></tr></table></figure></li></ol></li></ol><h2 id="修复XeLatex"><a href="#修复XeLatex" class="headerlink" title="修复XeLatex"></a>修复XeLatex</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it sharelatex /bin/bash/</span><br><span class="line">apt update</span><br><span class="line">apt install -y texlive-xetex texlive-latex-extra texlive-science</span><br></pre></td></tr></table></figure><h3 id="刻录镜像"><a href="#刻录镜像" class="headerlink" title="刻录镜像"></a>刻录镜像</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat config/version # 该命令会得到[version]</span><br><span class="line">docker commit sharelatex sharelatex/sharelatex:[version]-with-texlive-full</span><br><span class="line">echo [version]-with-texlive-full &gt; config/version</span><br></pre></td></tr></table></figure><p>注意在编写中文文档时需要调整至XeLaTex，并且调用Ctex包</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL292ZXJsZWFmL3Rvb2xraXQ=">overleaf/toolkit (github.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9kZXZlbG9wZXIuYWxpeXVuLmNvbS9hcnRpY2xlLzE1NzI2MDY=">Linux 快速搭建 Overleaf 5.0 附中文字体及完整 TexLive 安装教程（2024最新版）-阿里云开发者社区 (aliyun.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cudG5uaWRtLmNvbS9idWlsZC1hbmQtdXNlLW92ZXJsZWFmLXNlcnZlci8=">搭建和使用overleaf服务器 | Tnnidm-Blog<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL292ZXJsZWFmL3Rvb2xraXQvYmxvYi9tYXN0ZXIvZG9jL2NlLXVwZ3JhZGluZy10ZXhsaXZlLm1kP3NwbT1hMmM2aC4xMjg3MzYzOS5hcnRpY2xlLWRldGFpbC4xNC41YTMzNjk0NVVtU01peCZmaWxlPWNlLXVwZ3JhZGluZy10ZXhsaXZlLm1k">toolkit/doc/ce-upgrading-texlive.md at master · overleaf/toolkit (github.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly95eG5jaGVuLmdpdGh1Yi5pby90ZWNobmlxdWUvRG9ja2Vy6YOo572yU2hhcmVMYVRlWOW5tueugOWNlemFjee9ruS4reaWh+eOr+Wigy8j5YeG5aSH5bel5L2c">Docker部署ShareLaTeX并简单配置中文环境 | YXN’s Blog (yxnchen.github.io)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9taXJyb3JzLmliaWJsaW8ub3JnL0NUQU4vbGFuZ3VhZ2UvY2hpbmVzZS9jdGV4L2N0ZXgucGRm">CTeX 宏集手册 (ibiblio.org)<i class="fa fa-external-link-alt"></i></span></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Overleaf-toolkit部署&quot;&gt;&lt;a href=&quot;#Overleaf-toolkit部署&quot; class=&quot;headerlink&quot; title=&quot;Overleaf-toolkit部署&quot;&gt;&lt;/a&gt;Overleaf-toolkit部署&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;在写latex的过程中，第一个使用的在线latex编辑器就是overleaf，但是在使用过程中受到诸多限制，遂欲购买overleafpro，但发现其学生价也要500yuan/year，实在是财力不足，但overleaf是开源的，要花钱的只是服务器算力以及各种模板，于是就有了部署Overleaf-toolkit的想法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Overleaf是一个在线多用户协作的Latex编辑网站，其采用了如同markdown的“所见即所得”思想，采用及时更新编译的方式辅助编辑latex文件，同时通过项目结构约束文件的排布。是一个是十分学术且普遍应用的latex编辑网站。&lt;/p&gt;</summary>
    
    
    
    <category term="软件" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="latex" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/latex/"/>
    
    <category term="overleaf" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/latex/overleaf/"/>
    
    
    <category term="latex" scheme="https://deepcity.github.io/tags/latex/"/>
    
    <category term="overleaf" scheme="https://deepcity.github.io/tags/overleaf/"/>
    
  </entry>
  
  <entry>
    <title>Docker镜像与容器使用</title>
    <link href="https://deepcity.github.io/2024/Docker%E9%95%9C%E5%83%8F%E4%B8%8E%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8/article.html"/>
    <id>https://deepcity.github.io/2024/Docker%E9%95%9C%E5%83%8F%E4%B8%8E%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8/article.html</id>
    <published>2024-08-25T09:16:26.000Z</published>
    <updated>2024-08-25T11:17:18.833Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Docker-Image-amp-amp-container"><a href="#Docker-Image-amp-amp-container" class="headerlink" title="Docker Image &amp;&amp; container"></a>Docker Image &amp;&amp; container</h1><h2 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h2><ol><li><code>docker stats</code> 该命令可以查看docker contianer对各种资源的占用量</li><li><code>docker image ls -a</code> 查看image状况 -a表示所有的</li><li><code>docker container ls -a</code> 查看container状况 -a表示查看所有的</li><li><code>docker container start/stop [container_id]</code>启停对应的container</li><li><code>docker container/image rm [container_id]/[image_id]</code>移除镜像或容器。</li><li><code>docker commit sharelatex sharelatex:version_tag</code> 提交容器为镜像</li></ol><span id="more"></span><h2 id="Image与Container的关系"><a href="#Image与Container的关系" class="headerlink" title="Image与Container的关系"></a>Image与Container的关系</h2><p>Container可以commit为Image</p><p>Image也可以run为Container</p><h3 id="什么是docker-image"><a href="#什么是docker-image" class="headerlink" title="什么是docker image"></a>什么是docker image</h3><p>Docker Image（Docker镜像）是用于创建Docker容器的只读模板。它包含了运行应用程序所需的所有内容，包括代码、依赖项、库、环境变量和配置文件。Docker镜像是容器的“蓝图”，容器是镜像的运行实例。</p><ol><li><p>Docker Image 是只读的</p></li><li><p>Docker Image的存储是分层的</p><p><img src="https://s2.loli.net/2024/08/25/eZ5XUC1zKHLRfJh.png" alt="DockerImages"></p><p>对如图的1,2,4镜像，通过tag显然可以发现他们的顺序是2-3-4，即总共占用8g而非16g</p></li></ol><h3 id="什么是Docker-Container"><a href="#什么是Docker-Container" class="headerlink" title="什么是Docker Container"></a>什么是Docker Container</h3><p>Docker Container（Docker容器）是一个独立运行的应用程序实例，它基于Docker镜像启动，并包含了运行应用所需的所有依赖、配置和环境。Docker容器是轻量级的、可移植的，它们在隔离的环境中运行，确保应用程序的行为在任何系统中都是一致的。</p><ol><li>Container是共享主机的操作系统内核的（但是同样可以使用不同的操作系统）</li><li>Container之间是隔离的</li><li>Container是独立的，并不基于除主机以外的东西</li><li>Container是可以短时（瞬时）启动和关闭的</li></ol><h3 id="如何启动Container"><a href="#如何启动Container" class="headerlink" title="如何启动Container"></a>如何启动Container</h3><h4 id="通过Docker源，网络下载启动容器"><a href="#通过Docker源，网络下载启动容器" class="headerlink" title="通过Docker源，网络下载启动容器"></a>通过Docker源，网络下载启动容器</h4><p>一般来讲，我们可以通过</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p [HostIP]:[HostPort]:[DockerPort] --name [ContainerName] [SoftwareName]:[version]</span><br></pre></td></tr></table></figure><p>启动一个特定的容器并将docker的某一个开放端口映射到主机上，其中-d使得容器的输出并不同步到主机上</p><h4 id="通过本地Image仓库启动容器"><a href="#通过本地Image仓库启动容器" class="headerlink" title="通过本地Image仓库启动容器"></a>通过本地Image仓库启动容器</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p [HostIP]:[HostPort]:[DockerPort] &lt;image_name&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure><h3 id="如何将Container提交为Image"><a href="#如何将Container提交为Image" class="headerlink" title="如何将Container提交为Image"></a>如何将Container提交为Image</h3><p>相当简单</p><p>直接调用一条命令即可<code>docker commit sharelatex sharelatex:version_tag</code>即可</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Docker-Image-amp-amp-container&quot;&gt;&lt;a href=&quot;#Docker-Image-amp-amp-container&quot; class=&quot;headerlink&quot; title=&quot;Docker Image &amp;amp;&amp;amp; container&quot;&gt;&lt;/a&gt;Docker Image &amp;amp;&amp;amp; container&lt;/h1&gt;&lt;h2 id=&quot;基础命令&quot;&gt;&lt;a href=&quot;#基础命令&quot; class=&quot;headerlink&quot; title=&quot;基础命令&quot;&gt;&lt;/a&gt;基础命令&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;code&gt;docker stats&lt;/code&gt; 该命令可以查看docker contianer对各种资源的占用量&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker image ls -a&lt;/code&gt; 查看image状况 -a表示所有的&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker container ls -a&lt;/code&gt; 查看container状况 -a表示查看所有的&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker container start/stop [container_id]&lt;/code&gt;启停对应的container&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker container/image rm [container_id]/[image_id]&lt;/code&gt;移除镜像或容器。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker commit sharelatex sharelatex:version_tag&lt;/code&gt; 提交容器为镜像&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="软件" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="Docker" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/Docker/"/>
    
    
    <category term="Docker" scheme="https://deepcity.github.io/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker安装与网络配置</title>
    <link href="https://deepcity.github.io/2024/Docker%E5%AE%89%E8%A3%85%E4%B8%8E%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/article.html"/>
    <id>https://deepcity.github.io/2024/Docker%E5%AE%89%E8%A3%85%E4%B8%8E%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/article.html</id>
    <published>2024-08-25T07:23:56.000Z</published>
    <updated>2024-08-27T08:03:17.215Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><p>在部署服务器时，经常在各式各样的仓库中见到Docker部署这一方式，开始不以为然，后来发现它极高的普及率与及其方便的部署方式吸引了我的注意。</p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuZG9ja2VyLmNvbS8=">docker<i class="fa fa-external-link-alt"></i></span>是一个开源的平台，主要用于开发、运输和运行应用程序。它通过使用容器（Containers）技术，使得应用程序能够在任何环境下以一致的方式运行，无论是在开发、测试，还是在生产环境中。</p><span id="more"></span><p>可以说，只要你配置好了docker，所有知名的软件就都向你敞开了大门。下面，从我是用docker的角度出发，讲一下实用的docker概念与使用技巧。</p><ol><li><p>docker与dockercompose</p><p>Docker 和 Docker Compose 是两个密切相关的工具，但它们的功能和用途有所不同，通常一起使用来管理容器化的应用程序。</p><p>Docker是一个基础平台，安装docker 通常讲指单纯安装这一组件，实际上，很多下载方式也都是这么做的，<strong>但我并不推荐这种方式</strong>，实际上就截至目前的体验，dockercompose的体验对新手是要好于docker的。</p><p>dockercompose是docker的具体独立工具依赖 Docker，但它是一个独立的工具，需要单独安装。</p></li><li><p>网络问题</p><p>由于发展中的问题，对docker的下载时常是困难的，且下载完整且最新的docker很可能是“<strong>有误导性</strong>”的，因为，如果你挂了镜像而且即使更新了镜像，也无从得知下载的版本是否正确，能否运行所需的软件。</p><p>这里还是推荐直接上机场或VPS直连通过官网方式不通过镜像来下载，虽然经济上可能有损耗，但总体来看，减少时间成本是多于增加的经济成本的。</p><p>然而，<strong>挂载了加速可能你也会发现</strong>，docker的网络并不通过我们的代理，事实上，docker并不走“常见”的网络代理，在linux中，<strong>在执行docker pull时，是由守护进程dockerd来执行。因此，代理需要配在dockerd的环境中。而这个环境，则是受systemd所管控，因此实际是systemd的配置。</strong> </p></li></ol><h2 id="安装最新Docker"><a href="#安装最新Docker" class="headerlink" title="安装最新Docker"></a>安装最新Docker</h2><p>若只想安装一个可用的源，截至2024/7/24，有一份教程在参考资料第6个。</p><h3 id="科学上网"><a href="#科学上网" class="headerlink" title="科学上网"></a>科学上网</h3><p>对于安装最新Docker，科学上网几乎是必备的，无论你使用的任何镜像（ps：除非是确保可信且不会过期的，包括国内部分知名互联网公司及大部分学校镜像都是无效或过期的）</p><p>比较知名的源有：Aliyun，清华，ustc中科大</p><p>参考文章<a href="Linux网络设置/article.html">Linux网络设置</a></p><h3 id="通过yum安装"><a href="#通过yum安装" class="headerlink" title="通过yum安装"></a>通过yum安装</h3><p>该命令可移除全部docker</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo yum remove docker \</span><br><span class="line">                docker-client \</span><br><span class="line">                docker-client-latest \</span><br><span class="line">                docker-common \</span><br><span class="line">                docker-latest \</span><br><span class="line">                docker-latest-logrotate \</span><br><span class="line">                docker-logrotate \</span><br><span class="line">                docker-engine</span><br></pre></td></tr></table></figure><ol><li><p>更新系统</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum update -y</span><br></pre></td></tr></table></figure></li><li><p>安装依赖包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y yum-utils \</span><br><span class="line">    device-mapper-persistent-data \</span><br><span class="line">    lvm2 </span><br></pre></td></tr></table></figure></li><li><p>安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure></li><li><p>额外设置与验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start docker</span><br><span class="line">sudo systemctl enable docker</span><br><span class="line">docker version</span><br></pre></td></tr></table></figure></li></ol><p>你可能已经发现了，即使通过以上方式下载了docker，也不一定是最新版，甚至相当可能是1.1x等超老版本，这是因为使用的yum镜像源的问题，国内很多镜像源都在许多年前“停止了维护”。但如果你的yum是国外源的话，很有可能没这个问题，也就不用看下面的内容了，查找最新版本请看docker官网（在参考资料中）</p><h3 id="通过dnf进行安装"><a href="#通过dnf进行安装" class="headerlink" title="通过dnf进行安装"></a>通过dnf进行安装</h3><p>以下操作需要保证你的yum仓库状态正常，并且联通外网，如果原本<code>yum makecache</code>就无法成功，那么dnf也是救不了的</p><p><img src="https://s2.loli.net/2024/08/23/riq6ygcF9jKfEvA.png" alt="[Supported platforms](https://docs.docker.com/desktop/install/linux-install/#supported-platforms)"></p><p>在docker官网里，我们可以查询到他所支持的Linux列表，而在Centos中，我们可以通过<code>cat /proc/version</code> <code>uname -a</code>,<code>cat /etc/os-release</code>分别查询到内核以及系统版本，而Centos7属于RHEL的克隆版本。因此尝试使用RHEL的安装方式，即官网描述的dnf新一代RPM库安装</p><ol><li><p>安装依赖</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install epel-release -y</span><br></pre></td></tr></table></figure></li><li><p>安装dnf</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install dnf -y</span><br></pre></td></tr></table></figure></li><li><p>配置dnf，与添加常用的第三方库</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dnf install &#x27;dnf-command(config-manager)&#x27;</span><br><span class="line">dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm</span><br><span class="line">dnf install pass</span><br><span class="line">dnf install gnome-shell-extension-appindicator # GNOME</span><br><span class="line">gnome-extensions enable appindicatorsupport@rgcjonas.gmail.com # GNOME</span><br><span class="line">sudo dnf install gnome-terminal # GNOME</span><br><span class="line">dnf install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure></li><li><p>额外设置与验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start docker</span><br><span class="line">sudo systemctl enable docker</span><br><span class="line">docker version</span><br></pre></td></tr></table></figure></li></ol><h3 id="AliyunECS"><a href="#AliyunECS" class="headerlink" title="AliyunECS"></a>AliyunECS</h3><p>当服务器满足下图条件时，可通过扩展程序安装Docker</p><p><img src="https://s2.loli.net/2024/08/24/Eyqh8e6HoAnFVxr.png" alt="Aliyun"></p><p>详见对参考资料中阿里云的官方文档</p><h2 id="Docker的网络代理"><a href="#Docker的网络代理" class="headerlink" title="Docker的网络代理"></a>Docker的网络代理</h2><p><img src="https://s2.loli.net/2024/08/27/nPUjY3yCtleLosD.png" alt="docker与daemon在代理中的关系"></p><p><img src="https://s2.loli.net/2024/08/24/vYtQrRgiSsyd14E.png" alt="daemon与网络的关系"></p><p>事实上，daemon与client可以运行在两个主机上，在同一主机上运行时，真正与互联网进行交互的实际上是Daemon守护程序，也就是说，当我们普通的配置env进行代理的时候，我们配置的是Client与Daemon交互的代理，而配置Daemon后才能达到“端到端”的代理。</p><p>下面只阐述如何进行端到端的代理配置</p><p>在<code>/etc/systemd/system</code>该路径下寻找<code>docker.service.d/http-proxy.conf</code>,没有则新建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">Environment=&quot;HTTP_PROXY=http://IP:Port/&quot;</span><br><span class="line">Environment=&quot;HTTPS_PROXY=http://IP:Port/&quot;</span><br><span class="line">Environment=&quot;NO_PROXY=localhost,127.0.0.1,.example.com&quot;</span><br></pre></td></tr></table></figure><p>在这里，我是用的clash-for-linux的IP为127.0.0.1，Port为7890，可以通过 <a href="../Linux网络设置.md">Linux网络设置.md</a>设置。 </p><p>最后重启他俩即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h3 id="Dockers-Container的网络代理"><a href="#Dockers-Container的网络代理" class="headerlink" title="Dockers Container的网络代理"></a>Dockers Container的网络代理</h3><h3 id="直接在容器内添加代理"><a href="#直接在容器内添加代理" class="headerlink" title="直接在容器内添加代理"></a>直接在容器内添加代理</h3><p>这种方式如同在主机添加代理，步骤一致，但并不推荐，如果不是测试使用，最好还是保证容器的完整性。</p><blockquote><p>但如果需要该容器处处可用，修改环境变量也是可行的</p></blockquote><p>略</p><h3 id="在Docker17版本以上"><a href="#在Docker17版本以上" class="headerlink" title="在Docker17版本以上"></a>在Docker17版本以上</h3><p><code>Docker</code> 提供了一个<strong>全局的配置</strong>，<strong>可以通过配置 <code>Docker</code> 客户端以自动将代理信息传递给容器</strong>，从而让所有的容器内部都支持代理访问。</p><p>在<strong>启动容器的用户的主目录中</strong>创建或编辑文件 <code>~/.docker/config.json</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"> <span class="attr">&quot;proxies&quot;</span><span class="punctuation">:</span></span><br><span class="line"> <span class="punctuation">&#123;</span></span><br><span class="line">   <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span></span><br><span class="line">   <span class="punctuation">&#123;</span></span><br><span class="line">     <span class="attr">&quot;httpProxy&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://127.0.0.1:7890&quot;</span><span class="punctuation">,</span></span><br><span class="line">     <span class="attr">&quot;httpsProxy&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://127.0.0.1:7890&quot;</span><span class="punctuation">,</span></span><br><span class="line">     <span class="attr">&quot;noProxy&quot;</span><span class="punctuation">:</span> <span class="string">&quot;*.test.example.com,.example2.com,127.0.0.0/8&quot;</span></span><br><span class="line">   <span class="punctuation">&#125;</span></span><br><span class="line"> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>然后重启docker两兄弟即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0VsZWd5Y2xvdWQvY2xhc2gtZm9yLWxpbnV4LWJhY2t1cA==">Elegycloud/clash-for-linux-backup: 基于Clash Core 制作的Clash For Linux备份仓库 A Clash For Linux Backup Warehouse Based on Clash Core (github.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmRvY2tlci5jb20vZGVza3RvcC9pbnN0YWxsL2xpbnV4LWluc3RhbGwv">Install Docker Desktop on Linux | Docker Docs<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuZG9ja2VyLmNvbS8=">Docker: Accelerated Container Application Development<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9jbi5saW51eC10ZXJtaW5hbC5jb20vP3A9NTE4MA==">如何在CentOS 7上安装DNF (linux-terminal.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9oZWxwLmFsaXl1bi5jb20vemgvZWNzL3VzZS1jYXNlcy9pbnN0YWxsLWFuZC11c2UtZG9ja2VyLW9uLWEtbGludXgtZWNzLWluc3RhbmNlIzI5OGE4YzZiZGMxOTM=">安装Docker并使用_云服务器 ECS(ECS)-阿里云帮助中心 (aliyun.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vY29kZW5vb2IvcC8xODI4MTk5Mg==">使用国内源安装新版docker（2024.7.3） - navist2020 - 博客园 (cnblogs.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BlbmcyaHVpMTMxNC9hcnRpY2xlL2RldGFpbHMvMTI0MjY3MzMz">快速设置 Docker 的三种网络代理配置_docker 代理-CSDN博客<i class="fa fa-external-link-alt"></i></span></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Docker&quot;&gt;&lt;a href=&quot;#Docker&quot; class=&quot;headerlink&quot; title=&quot;Docker&quot;&gt;&lt;/a&gt;Docker&lt;/h1&gt;&lt;p&gt;在部署服务器时，经常在各式各样的仓库中见到Docker部署这一方式，开始不以为然，后来发现它极高的普及率与及其方便的部署方式吸引了我的注意。&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly93d3cuZG9ja2VyLmNvbS8=&quot;&gt;docker&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;是一个开源的平台，主要用于开发、运输和运行应用程序。它通过使用容器（Containers）技术，使得应用程序能够在任何环境下以一致的方式运行，无论是在开发、测试，还是在生产环境中。&lt;/p&gt;</summary>
    
    
    
    <category term="软件" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="Docker" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/Docker/"/>
    
    
    <category term="Docker" scheme="https://deepcity.github.io/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>CentOS运维记录</title>
    <link href="https://deepcity.github.io/2024/CentOS%E8%BF%90%E7%BB%B4%E8%AE%B0%E5%BD%95/article.html"/>
    <id>https://deepcity.github.io/2024/CentOS%E8%BF%90%E7%BB%B4%E8%AE%B0%E5%BD%95/article.html</id>
    <published>2024-08-25T07:23:35.000Z</published>
    <updated>2024-08-25T09:34:23.702Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CentOS运维"><a href="#CentOS运维" class="headerlink" title="CentOS运维"></a>CentOS运维</h1><p>记录我在CentOS中折腾的经验。</p><h2 id="存储空间不足"><a href="#存储空间不足" class="headerlink" title="存储空间不足"></a>存储空间不足</h2><p>在不断的使用CentOS虚拟机的过程中，docker对磁盘空间的庞大需求最终还是占满了我为学习准备的20g空间，因此，我对CentOS的磁盘开始了第一次折腾。</p><span id="more"></span><h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><p>写在前面为一些缩写给出解释</p><ol><li><p>LVM的基本组成</p><ol><li>物理卷 (PV，Physical Volume)<br>一个可供存储LVM的块设备. 如硬盘分区（MBR或GPT分区）、SAN 的硬盘、RAID 或 LUN，一个回环文件, 一个被内核映射的设备 (例如 dm-crypt)，它包含一个特殊的LVM头，它是 LVM 构建的实际硬件或存储系统。</li><li>卷组 (VG，Volume Group)<br>卷组是对一个或多个物理卷的集合，并在设备文件系统中显示为 /dev/VG_NAME。</li><li>逻辑卷 (LV，Logical Volume)<br>逻辑卷是可供系统使用的最终元设备，它们在卷组中创建和管理，由物理块组成，实际上就是一个虚拟分区，并显示为 /dev/VG_NAME/LV_NAME，通常在其上可以创建文件系统。</li><li>物理块 (PE，Physical Extends)<br>一个卷组中最小的连续区域(默认为4 MiB)，多个物理块将被分配给一个逻辑卷。你可以把它看成物理卷的一部分，这部分可以被分配给一个逻辑卷。</li></ol></li><li><p>xfs文件系统：一种自Centos7起使用的文件系统</p></li></ol><h3 id="常用命令阐述"><a href="#常用命令阐述" class="headerlink" title="常用命令阐述"></a>常用命令阐述</h3><ol><li><code>lsblk</code>该命令可以查看当前硬盘的分区状况</li><li><code>fdisk</code>该命令可以启动分盘程序，常用<code>fdisk -l</code>查看磁盘情况</li><li><code>pvdisplay</code>显示物理卷</li><li><code>vgdisplay</code>显示虚拟卷组</li><li><code>lvdisplay</code>显示逻辑卷</li><li><code>df</code>显示文件系统的容量以及挂载点位，常用参数<code>-h</code>显示适当的大小</li><li><code>pvcreate</code>创建物理分区</li><li><code>vgextend</code>扩容vg空间</li><li><code>lvextend</code> 扩容lv空间 <code>-L</code>指按照指定空间，<code>-l</code>指按照指定百分比</li><li><code>xfs_growfs</code>增加 XFS 文件系统的大小，必须挂载 XFS 文件系统，并且底层设备上必须有可用空间。</li></ol><h3 id="虚拟机扩容"><a href="#虚拟机扩容" class="headerlink" title="虚拟机扩容"></a>虚拟机扩容</h3><p>在Vmware虚拟机中，如果VM对硬盘预留了空间，那么可以直接二通过VMware进行扩容</p><p><img src="https://s2.loli.net/2024/08/25/JwhxWA1cV8niUu2.png" alt="VMware"></p><p>但很多情况下，这个方法都是不起作用的，尤其是分配了多块硬盘的情况。</p><h3 id="LVM扩容"><a href="#LVM扩容" class="headerlink" title="LVM扩容"></a>LVM扩容</h3><p>LVM是扩容时所使用的空间的格式，是Linux所特有的空间的处理方法。</p><ol><li><p>通过虚拟机或服务器提供商增加硬盘大小</p></li><li><p>为当前硬盘新建分区，并格式化为lvm</p><ol><li><code>lsblk</code>显示硬盘状态</li><li><code>fdisk [sdx]</code> 指定硬盘名调用fdisk系统</li><li>新建分区</li><li><code>t</code>指定<code>8e</code>lvm文件系统</li></ol></li><li><p>将新建硬盘加入vg</p><ol><li><p>创建pv，<code>pvcreate /dev/[sdx]</code> </p></li><li><p>合并到已有vg组</p><ol><li><code>vgdisplay</code> 查看当前vg</li><li>对欲增加容量的vg使用<code>vgextend [VG Name] /dev/[sdx]</code></li></ol></li><li><p>扩展lv空间</p><ol><li><p><code>lvdisplay</code>查看已有lv空间</p></li><li><p><code>df -h</code>查看对应挂载点空间</p><blockquote><p>如LV name是home，他的LV Path是/dev/centos/home。</p><p>假如我们想添加空间到/home中，可以在df -h的结果中看到其对应着/dev/mapper/centos-home</p></blockquote></li><li><p><code>lvextend -l/L +xx%/+xxG /dev/centos/xxxxx</code>扩展空间</p></li></ol></li><li><p><code>xfs_growfs</code>使新的空间可用</p></li></ol></li></ol><h2 id="掉网络问题"><a href="#掉网络问题" class="headerlink" title="掉网络问题"></a>掉网络问题</h2><p>见 <a href="../Linux网络设置/article.html">Linux网络设置.md</a> 中异常处理一章</p><h2 id="经验"><a href="#经验" class="headerlink" title="经验"></a>经验</h2><ol><li>多快照，尤其是当你修改/etc/目录下的一些配置文件，尤其是<code>/etc/fstab</code>该文件。</li><li>maintain模式下，小数字键盘是不起作用的，而且这时不会有提示告诉你有问题</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><span class="exturl" data-url="aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8yNDI0MTM2">Linux Centos系统 磁盘分区和文件系统管理 （深入理解）-腾讯云开发者社区-腾讯云 (tencent.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbGFiLXpqL3AvMTM0NzQ1NDkuaHRtbA==">VMware虚拟机（centos7）容量不足调整（LVM） - 小小小光子 - 博客园 (cnblogs.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vb3JhbmdlLUNDL3AvMTI3MTEwNzguaHRtbA==">存储系列之 XFS文件系统简介 - orange-C - 博客园 (cnblogs.com)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjkxNTQzMS9hcnRpY2xlL2RldGFpbHMvMTIxODgxMDU0">Linux下的磁盘管理之LVM详解及lvm的常用磁盘操作命令_lvm命令-CSDN博客<i class="fa fa-external-link-alt"></i></span></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;CentOS运维&quot;&gt;&lt;a href=&quot;#CentOS运维&quot; class=&quot;headerlink&quot; title=&quot;CentOS运维&quot;&gt;&lt;/a&gt;CentOS运维&lt;/h1&gt;&lt;p&gt;记录我在CentOS中折腾的经验。&lt;/p&gt;
&lt;h2 id=&quot;存储空间不足&quot;&gt;&lt;a href=&quot;#存储空间不足&quot; class=&quot;headerlink&quot; title=&quot;存储空间不足&quot;&gt;&lt;/a&gt;存储空间不足&lt;/h2&gt;&lt;p&gt;在不断的使用CentOS虚拟机的过程中，docker对磁盘空间的庞大需求最终还是占满了我为学习准备的20g空间，因此，我对CentOS的磁盘开始了第一次折腾。&lt;/p&gt;</summary>
    
    
    
    <category term="软件" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="Linux" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/Linux/"/>
    
    
    <category term="Linux" scheme="https://deepcity.github.io/tags/Linux/"/>
    
    <category term="CentOS" scheme="https://deepcity.github.io/tags/CentOS/"/>
    
  </entry>
  
  <entry>
    <title>Linux网络设置</title>
    <link href="https://deepcity.github.io/2024/Linux%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE/article.html"/>
    <id>https://deepcity.github.io/2024/Linux%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE/article.html</id>
    <published>2024-08-25T07:23:20.000Z</published>
    <updated>2024-08-27T08:07:33.479Z</updated>
    
    <content type="html"><![CDATA[<h1 id="linux的网络配置">Linux的网络配置</h1><p>在我反复鼓捣Linux的过程中，时常遇到Linux在网络配置上的问题，有个互联网笑话是“老钟是最擅长计算机网络的”。既然如此，我也有了一个想法——记录下我在Linux网络配置中所遭遇的坑。硬件主要集中于LinuxECS服务器与VMware虚拟机，软件版本则是以CentOS7，Ubuntu18.04为主。</p><h2 id="基础网络命令">基础网络命令</h2><ol type="1"><li><code>ifconfig</code>最基本最常用的命令，用于查看本地网卡的信息，一般查看值为IP或者本地物理地址</li><li><code>ping</code>简单的测试网络丢包率，有时<code>curl</code>命令对网站的检测更为准确，因为两者对于代理的检测并不完全一致</li><li><code>netstat</code>用于查看本地端口的状态信息，一般用于查看当前那些端口是开放的，那些端口是被某个特定应用监控的，一般搭配<code>grep</code>使用</li><li><code>traceroute</code>针对特定目标地址的报文转发追踪，基于IP报文中的生存时间TTL实现，一般用于查看对特定网络服务是否联通，也可用于查看本机某个端口是否对外界开放，最经典的例子就是mail端口25，这个端口国内很少开放</li><li><code>whois</code>查看域名建立时间，有效期等，一般用于查看网站的归属信息以及ssl证书的有效期</li><li><code>host</code>查看有关目的地址的信息，既可以通过IP查看域名，也可以通过域名查看IP</li><li><code>ifdown</code><code>ifup</code>,这两个命令用于对特定网卡的关启</li><li><code>nmtui</code> 通过调用一个内置的网卡配置图形化界面配置网卡</li><li><code>systemctl start/stop/enable/restart NetworkManager</code>这是一个特殊的通过systemctl控制网络服务以实现对网络进行开关的命令，常用于对<code>/etc/NetworkManager/NetworkManager.conf</code>该文件进行修改后的重新配置网络</li><li><code>env | grep -E 'http_proxy|https_proxy'</code>这条命令比较特殊，一般用于查看当前的代理</li></ol><span id="more"></span><h2 id="如何科学上网">如何科学上网</h2><h3 id="windows平台">Windows平台</h3><p>对于Windows平台，该平台有大量用户基础，并且生态良好，很容易找到代理上网的软件以及节点。（初接触者千万区分这两者，代理是代理也称机场，软件是软件）。两者一个收费最好，一个完全免费。</p><h4 id="推荐软件">推荐软件</h4><p>V2ray、ClashForWindows等</p><h3 id="linux平台">Linux平台</h3><p>推荐clash-for-linux，一个个人自用的备份库</p><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0VsZWd5Y2xvdWQvY2xhc2gtZm9yLWxpbnV4LWJhY2t1cA==">Elegycloud/clash-for-linux-backup:基于Clash Core 制作的Clash For Linux备份仓库 A Clash For Linux BackupWarehouse Based on Clash Core (github.com)<i class="fa fa-external-link-alt"></i></span></p><p>根据md文档操作即可</p><p>注：</p><ol type="1"><li>这样的操作一般用于加速对github的下载</li><li>配置其他的服务代理一般需要特别配置，因为很多服务实际上是通过守护进程来进行网络通信的</li></ol><h4 id="常用的软件配置">常用的软件配置</h4><h5 id="yum">yum</h5><p>注意对yum文件的禁用修改方式，不要使用rm，而是加文件名后缀禁用文件</p><ol type="1"><li><p>全局修改</p><p>修改/etc/yum.conf文件即可，在结尾添加你的本地代理网址</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">proxy=http://IP:Port</span><br><span class="line">// 在本文中为</span><br><span class="line">proxy=http://127.0.0.1：7890</span><br></pre></td></tr></table></figure></li><li><p>对特定的仓库启用代理</p><p>比如<code>CentOS-Base.repo</code>中有三个仓库：base、updates和extras。我们只想给base仓库设置代理，则只需要在对应的仓库后面添加一行，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[base]</span><br><span class="line">name=CentOS-$releasever - Base</span><br><span class="line">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os&amp;infra=$infra</span><br><span class="line">baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7</span><br><span class="line"># 下一行为新增,效果为base仓库走代理</span><br><span class="line">proxy=http://ip:port</span><br><span class="line"># 下注释一行为base不走代理</span><br><span class="line"># proxy=_none_</span><br><span class="line">#released updates </span><br><span class="line">[updates]</span><br><span class="line">name=CentOS-$releasever - Updates</span><br><span class="line">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates&amp;infra=$infra</span><br><span class="line">baseurl=http://mirror.centos.org/centos/$releasever/updates/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7</span><br><span class="line"></span><br><span class="line">#additional packages that may be useful</span><br><span class="line">[extras]</span><br><span class="line">name=CentOS-$releasever - Extras</span><br><span class="line">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras&amp;infra=$infra</span><br><span class="line">baseurl=http://mirror.centos.org/centos/$releasever/extras/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=file:///etc/pki/rpm-</span><br><span class="line">gpg/RPM-GPG-KEY-CentOS-7</span><br></pre></td></tr></table></figure></li></ol><h5 id="docker">docker</h5><p>按照需求修改文件即可，详见</p><p><a href="Docker安装与网络配置/article.html">Docker.md</a></p><h3 id="无广告个人自用机场">无广告，个人自用机场</h3><p><span class="exturl" data-url="aHR0cHM6Ly9qdXN0bXlzb2Nrcy5hcHAv">Just My Socks官网<i class="fa fa-external-link-alt"></i></span></p><h2 id="异常修复">异常修复</h2><p><strong>重装系统或恢复快照</strong></p><p>在花式乱搞后，虚拟机（服务器）的网络很容易会出现问题，比如，完全看不到虚拟机的网络选项，它有网卡但是却根本不获取ip！</p><figure><img src="https://s2.loli.net/2024/08/24/uRIr2VMaYvtkFhH.png"alt="Error" /><figcaption aria-hidden="true">Error</figcaption></figure><p>这种情况一般都是 network这个网卡服务出现了问题</p><ol type="1"><li><p>找到错误</p><p>查找虚拟机设置或者通过其他命令与文件查找到错误之后，通过<code>systemctl restart network</code>验证该服务是否出错</p></li><li><p>排除关联</p><p>通过</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop NetworkManager</span><br><span class="line">systemctl disable NetworkManager</span><br><span class="line">systemctl start network.service</span><br></pre></td></tr></table></figure><p>成功启动服务，确定network服务启动失败与NetworkManager之间的关联</p><p>但可以观察到，此时问题仍未解决，虚拟机仍无法上网，但是通过<code>ifconfig ens33</code>（ens33为网卡名）可以发现dhcp正常工作，更进一步的，我们从虚拟机ping主机也是可以ping通的</p></li><li><p>尝试解决上网问题</p><p>每种vm切换连接方式都解决不了问题，虚拟机仍无法上网，但可以发现，每次启动NetworkManager服务，就会导致虚拟机失去IP从而无法通信</p></li></ol><p>可见NetworkManager与network之间发生了一些冲突，导致两个服务相互影响使得网络处于要么能分配ip但上不了网，要么根本没ip的局面。</p><figure><img src="https://s2.loli.net/2024/08/24/1K8cfE5atGrgeAY.png"alt="xe" /><figcaption aria-hidden="true">xe</figcaption></figure><p>尝试查看错误信息可以发现其中奥秘。可以发现这一切都与一个名叫lo的本地环回接口有关，它被设置为不受管理。</p><p>在我询问chatgpt后，我得到了一种解决方式</p><p><strong>这种方式使得NetworkManager与network服务同时进行，可以访问网络，但无网络连接图标</strong>（虚拟机环境）</p><p>具体方式为</p><ol type="1"><li><p>确保 <code>lo</code> 接口没有被 NetworkManager管理。<code>/etc/NetworkManager/NetworkManager.conf</code>文件中修改配置</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="meta">main</span>]</span><br><span class="line">plugins=keyfile</span><br><span class="line"></span><br><span class="line">[<span class="meta">keyfile</span>]</span><br><span class="line"><span class="keyword">unmanaged</span>-devices=<span class="keyword">interface</span>-<span class="title">name</span>:<span class="title">lo</span></span><br></pre></td></tr></table></figure></li><li><p>清除可能的网络配置缓存</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo ip addr flush dev ens33</span><br><span class="line">sudo ip route flush table main</span><br></pre></td></tr></table></figure></li><li><p>重启服务</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart NetworkManager</span><br><span class="line">sudo systemctl restart network.service</span><br></pre></td></tr></table></figure></li></ol><p><del>对于虚拟机的网络显示问题，目前还未找到好的解决方式，网络上博主表示直接重装系统即可。。。</del>找到方法了，直接挂起然后启动就好，很神奇，重启解决不了，挂起能解决。。。</p><blockquote><p>网络管理器(NetworManager)是检测网络、自动连接网络的程序。无论是无线还是有线连接，它都可以令您轻松管理。对于无线网络,网络管理器优先连接已知的网络并可以自动切换到最可靠的无线网络。利用网络管理器的程序可以自由切换在线和离线模式。网络管理器会相对无线网络优先选择有线网络，支持VPN。网络管理器最初由 Redhat 公司开发，现在由 GNOME 管理。</p><p>NetworkManager由一个管理系统网络连接、并且将其状态通过D-BUS（是一个提供简单的应用程序互相通讯的途径的自由软件项目，它是作为freedesktoporg项目的一部分来开发的。）进行报告的后台服务，以及一个允许用户管理网络连接的客户端程序。</p></blockquote><h2 id="参考文献">参考文献</h2><ol type="1"><li><span class="exturl" data-url="aHR0cHM6Ly9wc2hpemhzeXN1LmdpdGJvb2suaW8vbGludXgveXVtL3dlaS15dW0teXVhbi1wZWktemhpLWRhaS1saQ==">为yum源配置代理| linux (gitbook.io)<i class="fa fa-external-link-alt"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vd2FuZ2Z4L3AvMTcyOTM0NzIuaHRtbA==">解决centos7网卡启动失败解决（亲测有效！！）- 王飞侠 - 博客园 (cnblogs.com)<i class="fa fa-external-link-alt"></i></span></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;linux的网络配置&quot;&gt;Linux的网络配置&lt;/h1&gt;
&lt;p&gt;在我反复鼓捣Linux的过程中，时常遇到Linux在网络配置上的问题，有个互联网笑话是“老钟是最擅长计算机网络的”。既然如此，我也有了一个想法——记录下我在Linux网络配置中所遭遇的坑。硬件主要集中于LinuxECS服务器与VMware虚拟机，软件版本则是以CentOS7，Ubuntu18.04为主。&lt;/p&gt;
&lt;h2 id=&quot;基础网络命令&quot;&gt;基础网络命令&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;code&gt;ifconfig&lt;/code&gt;最基本最常用的命令，用于查看本地网卡的信息，一般查看值为IP或者本地物理地址&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ping&lt;/code&gt;
简单的测试网络丢包率，有时&lt;code&gt;curl&lt;/code&gt;命令对网站的检测更为准确，因为两者对于代理的检测并不完全一致&lt;/li&gt;
&lt;li&gt;&lt;code&gt;netstat&lt;/code&gt;用于查看本地端口的状态信息，一般用于查看当前那些端口是开放的，那些端口是被某个特定应用监控的，一般搭配&lt;code&gt;grep&lt;/code&gt;使用&lt;/li&gt;
&lt;li&gt;&lt;code&gt;traceroute&lt;/code&gt;针对特定目标地址的报文转发追踪，基于IP报文中的生存时间TTL实现，一般用于查看对特定网络服务是否联通，也可用于查看本机某个端口是否对外界开放，最经典的例子就是mail端口25，这个端口国内很少开放&lt;/li&gt;
&lt;li&gt;&lt;code&gt;whois&lt;/code&gt;
查看域名建立时间，有效期等，一般用于查看网站的归属信息以及ssl证书的有效期&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host&lt;/code&gt;查看有关目的地址的信息，既可以通过IP查看域名，也可以通过域名查看IP&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ifdown&lt;/code&gt;
&lt;code&gt;ifup&lt;/code&gt;,这两个命令用于对特定网卡的关启&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nmtui&lt;/code&gt; 通过调用一个内置的网卡配置图形化界面配置网卡&lt;/li&gt;
&lt;li&gt;&lt;code&gt;systemctl start/stop/enable/restart NetworkManager&lt;/code&gt;这是一个特殊的通过systemctl控制网络服务以实现对网络进行开关的命令，常用于对&lt;code&gt;/etc/NetworkManager/NetworkManager.conf&lt;/code&gt;该文件进行修改后的重新配置网络&lt;/li&gt;
&lt;li&gt;&lt;code&gt;env | grep -E &#39;http_proxy|https_proxy&#39;&lt;/code&gt;这条命令比较特殊，一般用于查看当前的代理&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="软件" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="Linux" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/Linux/"/>
    
    
    <category term="Linux" scheme="https://deepcity.github.io/tags/Linux/"/>
    
    <category term="网络" scheme="https://deepcity.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>算法数论基础</title>
    <link href="https://deepcity.github.io/2024/%E7%AE%97%E6%B3%95%E6%95%B0%E8%AE%BA%E5%9F%BA%E7%A1%80/article.html"/>
    <id>https://deepcity.github.io/2024/%E7%AE%97%E6%B3%95%E6%95%B0%E8%AE%BA%E5%9F%BA%E7%A1%80/article.html</id>
    <published>2024-08-24T08:38:26.000Z</published>
    <updated>2024-08-27T08:33:08.752Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言需要用到的偏僻语法知识">前言：需要用到的偏僻语法知识</h1><h2 id="c随机数函数">c++随机数函数</h2><p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NDIwMDg1ODk=">如何优雅的用C++生成随机数 - 知乎 (zhihu.com)<i class="fa fa-external-link-alt"></i></span></p><p>头文件：c: cstdlib c++: random</p><p><code>cstdlib</code> 中的 rand（）和 srand（）函数是 C语言使用的随机数生成方法，通过 <strong><em>线性同余法</em></strong>计算。</p><span id="more"></span><blockquote><p>srand 常用时间作为种子</p></blockquote><p>C++标准建议使用 <code>random</code> 代替它们。</p><h3 id="随机数生成引擎-random-number-engines">随机数生成引擎<strong>Random number engines</strong></h3><p><code>random</code> 提供了三种引擎，使用哪种需要权衡：</p><ul><li>linear_congruential_engine（线性同余法）：速度比较快，储存很少的中间变量。</li><li>mersenne_twister_engine：比较慢，占用存储空间较大，但是在参数设置合理的情况下，可生成最长的不重复序列，且具有良好的频谱特征。</li><li>subtract_with_carry_engine：速度最快，占用存储空间较大，频谱特性有时不佳。</li></ul><h3 id="预定义算法">预定义算法</h3><p>算法包括minstd_rand0、minstd_rand、mt19937、mt19937_64、ranlux24_base、ranlux48_base等。</p><p>以下是费马小定理素性检验的随机数实际应用</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;random&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function">mt19937 <span class="title">eng</span><span class="params">(time(<span class="literal">nullptr</span>))</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">randint</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="function">uniform_int_distribution&lt;<span class="type">int</span>&gt; <span class="title">dis</span><span class="params">(a, b)</span></span>;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">dis</span>(eng);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">quickPow</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n, <span class="type">int</span> p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="type">int</span> res = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (n)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (n &amp; <span class="number">1</span>)res = (ll)res * x%p;</span><br><span class="line">x = (ll)x * x%p;</span><br><span class="line">n &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">isPrime</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (x &lt; <span class="number">3</span>)<span class="keyword">return</span> x == <span class="number">2</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">12</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> a = <span class="built_in">randint</span>(<span class="number">2</span>, x - <span class="number">1</span>);</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">quickPow</span>(a, x - <span class="number">1</span>, x) != <span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">isPrime</span>(<span class="number">9997579</span>))<span class="built_in">puts</span>(<span class="string">&quot;YES&quot;</span>);</span><br><span class="line"><span class="keyword">else</span> <span class="built_in">puts</span>(<span class="string">&quot;NO&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr /><p><strong>以下代码中将不会给出例如：randint, quickpow的代码（图个方便）</strong></p><h1 id="gcd-与-lcd-以及其衍生的素数判定问题">GCD 与 LCD以及其衍生的素数判定问题</h1><h2 id="gcd-的数学推导">GCD 的数学推导</h2><h3 id="取模运算">取模运算</h3><p>amodp 表示 a 除以 p 的余数</p><p><strong>模 ｐ 加法</strong> <span class="math inline">\((a+b)mod\ p =(amodp+bmodp)\ mod\ p\)</span></p><p><strong>模 p 减法</strong> <span class="math inline">\((a-b)mod\ p =(amodp-bmodp + p)\ mod\ p\)</span></p><p>注意在这里有个很容易犯得错误，在数学中，我们称mod是不会结果为负数得，但在计算机中，对负数进行去摸结果仍是负数。</p><blockquote><p>例如：</p><p>对-1进行取模，结果为n-1，而在计算机中，结果仍为-1</p></blockquote><p><strong>模 p 乘法</strong> <span class="math inline">\((a*b)mod\ p =(amodp*bmodp)mod\ p\)</span></p><p><strong>幂模 p</strong> <spanclass="math inline">\((a^b)modp=((amodp)^b)modp\)</span></p><p>  模运算满足结合律、交换律和分配律。<spanclass="math inline">\(a=b(mod\ n)\)</span> 表示 $ a$ 和 <spanclass="math inline">\(b\)</span> 模 <spanclass="math inline">\(n\)</span> 同余，即 <spanclass="math inline">\(a\)</span> 和 <spanclass="math inline">\(b\)</span> 除以 <spanclass="math inline">\(n\)</span> 的余数相等。</p><h3 id="最大公约数">最大公约数</h3><p>gcd 即最大公约数 lcm 即最小公倍数</p><p>## gcd 的具体实现与算法优化</p><figure><img src="https://s2.loli.net/2024/08/24/hjFAPLWQ98seZr5.png"alt="image-20220508102231840" /><figcaption aria-hidden="true">image-20220508102231840</figcaption></figure><p><strong>gcd 的基础实现</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">gcd</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> b ? <span class="built_in">gcd</span>(b, a % b) : a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>gcd 的运算符优化</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">int gcd(int a, int b) &#123;</span><br><span class="line">    // make sure a &gt;= b.</span><br><span class="line">    if (a &lt; b) &#123;</span><br><span class="line">        std::swap(a, b);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (b == 0) &#123;</span><br><span class="line">        return a;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    bool a_isodd = a &amp; 1;</span><br><span class="line">    bool b_isodd = b &amp; 1;</span><br><span class="line"></span><br><span class="line">    if (a_isodd &amp;&amp; b_isodd) &#123;</span><br><span class="line">        return gcd((a - b) &gt;&gt; 1, b);</span><br><span class="line">    &#125; else if (a_isodd &amp;&amp; !b_isodd) &#123;</span><br><span class="line">        return gcd(a, b &gt;&gt; 1);</span><br><span class="line">    &#125; else if (!a_isodd &amp;&amp; b_isodd) &#123;</span><br><span class="line">        return gcd(a &gt;&gt; 1, b);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // both a and b are even numbers.</span><br><span class="line">    return gcd(a &gt;&gt; 1, b &gt;&gt; 1) &lt;&lt; 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="素数检验算法">素数检验算法</h2><h3 id="纯暴力-o-n">纯暴力 O( n )</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">isprime</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=x/i;i++)</span><br><span class="line"><span class="keyword">if</span>(x%i==<span class="number">0</span>)<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="费马素性检验">费马素性检验</h3><p>那么反过来呢？如果存在某个 <span class="math inline">\(a^{p-1}\equiv1(mod\ p)\)</span>，是否就能判定 <span class="math inline">\(p\)</span>是素数呢？<strong>并不行</strong>，例如 <spanclass="math inline">\(2^{341-1}\equiv 1 (mod341)\)</span>，但 <spanclass="math inline">\(341\)</span> 是合数，满足该同余等式的合数被称为<strong>费马伪素数</strong>。</p><p>幸好，一个合数是费马伪素数的概率并不是很高。所以我们可以多测试几个<span class="math inline">\(a\)</span>。只要存在某个 <spanclass="math inline">\(a^{p-1}\not \equiv 1 (mod\ p)\)</span>，即可说明<span class="math inline">\(p\)</span> 不是素数。而如果多组测试下来<span class="math inline">\(a^{p-1}\equiv 1\)</span> 都成立，那它就<strong>很可能</strong> 是素数了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">isPrime</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (x &lt; <span class="number">3</span>)<span class="keyword">return</span> x == <span class="number">2</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">12</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> a = <span class="built_in">randint</span>(<span class="number">2</span>, x - <span class="number">1</span>);</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">quickPow</span>(a, x - <span class="number">1</span>, x) != <span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="米勒-拉宾素性检验">米勒-拉宾素性检验</h3><p>对于待检验的数为偶数，可直接判断其为非素数，而奇数则可写成 <spanclass="math inline">\(a^{x-1}\)</span> 表示为 <spanclass="math inline">\(a^{2^rd}\)</span> 当考虑 x 为奇数时，<spanclass="math inline">\(a^d,a^{2d},...,a^{2^rd}\)</span>这样一串数字的性质。</p><p>我们已经知道对奇素数 <span class="math inline">\(x\)</span>，<spanclass="math inline">\(a^{2^rd} \equiv 1 (mod\ x)\)</span> （a 是 x的倍数的情况下特判)，也就是说这串数字以 1 结尾，由于 x 是奇素数，且<span class="math inline">\(1^{\frac{x-1}{2}} \equiv 1 (mod\x)\)</span></p><h1 id="素数筛">素数筛</h1><p>##　暴力判断</p><h2 id="埃氏筛法">埃氏筛法</h2><h2 id="欧拉筛法">欧拉筛法</h2><p>上面得三种筛法都是十分简单而且基础得。这里就不多阐述了。</p><h2 id="不能秒杀的题">不能秒杀的题</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMTI5NS8=">1293夏洛特和他的女朋友<i class="fa fa-external-link-alt"></i></span></p><p>看到这道题，最先开始的想法，对每个数与其质因子连一条线，对建出来的图，做染色，保证每一条边的两个端点是不同颜色</p><p>但这并非正解，对于每一条边，其两端的链接必定是一个合数和一个素数，因此该图为一个二分图</p><figure><img src="https://s2.loli.net/2024/08/24/zKgVIluDya9mUxJ.png"alt="image-20220519164522508" /><figcaption aria-hidden="true">image-20220519164522508</figcaption></figure><p>剩下的很简单，n &lt;3时ans=1，n&gt; = 3 时 ans = 2；</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1000006</span>;</span><br><span class="line"><span class="type">int</span> prime[N], countNum;</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">oula</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>; i &lt;= N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (!st[i])prime[countNum++] = i;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; prime[j] * i &lt;= n; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            st[i * prime[j]] = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span> (i % prime[j] == <span class="number">0</span>)<span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">oula</span>(N);</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    <span class="keyword">if</span>(n&lt;<span class="number">3</span>)&#123;</span><br><span class="line">        <span class="built_in">puts</span>(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)<span class="built_in">printf</span>(<span class="string">&quot;1 &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="built_in">puts</span>(<span class="string">&quot;2&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">2</span>;i &lt;= n + <span class="number">1</span>;i++)</span><br><span class="line">            <span class="keyword">if</span>(st[i]) <span class="built_in">printf</span>(<span class="string">&quot;2 &quot;</span>);</span><br><span class="line">            <span class="keyword">else</span> <span class="built_in">printf</span>(<span class="string">&quot;1 &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="素数筛思想的实际应用">素数筛思想的实际应用</h2><p>对于每个区间内的所有数，合数必有一个sqrt（a）的因子，故可通过预处理出 5*10^4内的所有素数，再通过筛查质因子处理出每一个合数</p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMTk4Lw==">196质数距离<i class="fa fa-external-link-alt"></i></span></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1000010</span>;</span><br><span class="line"><span class="type">int</span> l, r;</span><br><span class="line"><span class="type">int</span> prime[N], countNum;</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">memset</span>(st, <span class="number">0</span>, <span class="keyword">sizeof</span> st);</span><br><span class="line">    countNum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">2</span>; i &lt;= n; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (!st[i])prime[countNum++] = i;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; prime[j] * i &lt;= n; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            st[prime[j] * i] = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span> (i % prime[j] == <span class="number">0</span>)<span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (cin &gt;&gt; l &gt;&gt; r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">init</span>(<span class="number">50000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">memset</span>(st, <span class="number">0</span>, <span class="keyword">sizeof</span> st);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; countNum; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            ll p = prime[i];</span><br><span class="line">            <span class="keyword">for</span> (ll j = <span class="built_in">max</span>(p * <span class="number">2</span>, (l + p - <span class="number">1</span>) / p * p); j &lt;= r; j += p)</span><br><span class="line">                st[j - l] = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        countNum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt;= r - l; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (!st[i] &amp;&amp; i + l &gt;= <span class="number">2</span>)</span><br><span class="line">                prime[countNum++] = i + l;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (countNum &lt; <span class="number">2</span>)<span class="built_in">puts</span>(<span class="string">&quot;There are no adjacent primes.&quot;</span>);</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">int</span> minp = <span class="number">0</span>, maxp = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; countNum - <span class="number">1</span>; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">int</span> d = prime[i + <span class="number">1</span>] - prime[i];</span><br><span class="line">                <span class="keyword">if</span> (d &lt; prime[minp + <span class="number">1</span>] - prime[minp])minp = i;</span><br><span class="line">                <span class="keyword">if</span> (d &gt; prime[maxp + <span class="number">1</span>] - prime[maxp])maxp = i;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%d,%d are closest, %d,%d are most distant.\n&quot;</span>,</span><br><span class="line">                prime[minp], prime[minp + <span class="number">1</span>], prime[maxp], prime[maxp + <span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="分解质因数">分解质因数</h1><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMTk5Lw==">197阶乘分解<i class="fa fa-external-link-alt"></i></span></p><p>最先开始想的是对于每一个 n以内的数都枚举一下，记录其对各个质数的约数，但这样就会有 1e6*1e5（1e6以内的素数个数）的时间复杂度，仍然超限，因此，转换一下思路，枚举素数，对每个该素数的倍数加入s 值，即： <span class="math display">\[s = n/p + n/p^2 + n/p^3 + n/p^4...\]</span></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1000006</span>;</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line"><span class="type">int</span> prime[N],countNum;</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=n;i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(!st[i])prime[countNum++]=i;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;prime[j]*i&lt;=n;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            st[i*prime[j]]=<span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(i%prime[j]==<span class="number">0</span>)<span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    <span class="built_in">init</span>(<span class="number">1000000</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;countNum;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(n&lt;prime[i])<span class="keyword">break</span>;</span><br><span class="line">        ll p=prime[i],s=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(n&gt;=p)s+=n/p,p*=prime[i];</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d %d\n&quot;</span>,prime[i],s);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="约数之和">约数之和</h1><p>约数定理 n 的 <spanclass="math inline">\((a_1+1)(a_2+1)...(a_k+1)\)</span> 个正约数之和为<spanclass="math inline">\((p_1^0+p_1^1+...p_1^{a1})(p_2^0+p_2^1+...+p_2^{a2})...(p_k^0+p_k^1+..+p_k^{ak})\)</span></p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9hY3Rpdml0eS9jb250ZW50L3Byb2JsZW0vY29udGVudC84MDQ2Lw==">AcWing97. 约数之和（算法提高课） - AcWing<i class="fa fa-external-link-alt"></i></span></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;cstdio&gt;</span><br><span class="line"></span><br><span class="line">const int mod = 9901;</span><br><span class="line"></span><br><span class="line">int qmi(int a, int k)</span><br><span class="line">&#123;</span><br><span class="line">    int res = 1;</span><br><span class="line">    a %= mod;</span><br><span class="line">    while (k)</span><br><span class="line">    &#123;</span><br><span class="line">        if (k &amp; 1) res = res * a % mod;</span><br><span class="line">        a = a * a % mod;</span><br><span class="line">        k &gt;&gt;= 1;</span><br><span class="line">    &#125;</span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int sum(int p, int k)</span><br><span class="line">&#123;</span><br><span class="line">    if (k == 1) return 1;</span><br><span class="line">    if (k % 2 == 0) return (1 + qmi(p, k / 2)) * sum(p, k / 2) % mod;</span><br><span class="line">    return (sum(p, k - 1) + qmi(p, k - 1)) % mod;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    int a, b;</span><br><span class="line">    scanf(&quot;%d%d&quot;, &amp;a, &amp;b);</span><br><span class="line"></span><br><span class="line">    int ans = 1;</span><br><span class="line">    for (int i = 2; i * i &lt;= a; i ++ )</span><br><span class="line">        if (a % i == 0)</span><br><span class="line">        &#123;</span><br><span class="line">            int s = 0;</span><br><span class="line">            while (a % i == 0)</span><br><span class="line">            &#123;</span><br><span class="line">                a /= i, s ++ ;</span><br><span class="line">            &#125;</span><br><span class="line">            ans = ans * sum(i, b * s + 1) % mod;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    if (a &gt; 1) ans = ans * sum(a, b + 1) % mod;</span><br><span class="line">    if (a == 0) ans = 0;</span><br><span class="line"></span><br><span class="line">    printf(&quot;%d\n&quot;, ans);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="约数个数">约数个数</h1><p>暴力求约数个数</p><h2id="求给定元素集中每一个数字的约数个数">求给定元素集中每一个数字的约数个数</h2><p>利用筛法思想，对于每一个数字枚举他的倍数</p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMTI5My8=">1291轻拍牛头<i class="fa fa-external-link-alt"></i></span></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1000010</span>;</span><br><span class="line"><span class="type">int</span> a[N],cnt[N],s[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">        cin&gt;&gt;a[i];</span><br><span class="line">        cnt[a[i]]++;</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;N;i++)</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=i;j&lt;N;j+=i)</span><br><span class="line">    &#123;</span><br><span class="line">        s[j]+=cnt[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) cout&lt;&lt;s[a[i]]<span class="number">-1</span>&lt;&lt;endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="阶乘平方的质数个数">阶乘、平方的质数个数</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMTI5Ni8=">1294樱花<i class="fa fa-external-link-alt"></i></span></p><p><span class="math inline">\(1/x+1/y=1/n!\)</span> =&gt; <spanclass="math inline">\(y=n!+n!^2/(x-n!)\)</span></p><p>因为 x, y 为正整数，因此要求的个数等价于 <spanclass="math inline">\(n!^2\)</span> 的约数个数</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1000010</span>;</span><br><span class="line"><span class="type">int</span> prime[N],countNum;</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(!st[i])prime[countNum++]=i;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;prime[j]*i&lt;=n;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            st[i*prime[j]]=<span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(i%prime[j]==<span class="number">0</span>)<span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> mod=<span class="number">1e9</span><span class="number">+7</span>;</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    <span class="built_in">init</span>(n);</span><br><span class="line">    </span><br><span class="line">    ll ans=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;countNum;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// cout&lt;&lt;prime[i]&lt;&lt;endl;</span></span><br><span class="line">        <span class="type">int</span> j=n;</span><br><span class="line">        <span class="type">int</span> s=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(j)s+=j/prime[i],j/=prime[i];</span><br><span class="line">        ans=(ans*(<span class="number">2</span>*s<span class="number">+1</span>))%mod;</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;ans&lt;&lt;endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2id="暴力枚举求最多约数个数的数一定范围内最大">暴力枚举求最多约数个数的数（一定范围内最大）</h2><p>dfs 搜索</p><ul><li>确定需要的质数数（2...23 共九个质数限定 1e9 内的约数最多的数）</li><li>确定需要的最大 α（30，确定 2e9 次方的数）</li></ul><p>注意可行性剪枝</p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMjAwLw==">198反素数<i class="fa fa-external-link-alt"></i></span></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> primes[<span class="number">9</span>]=&#123;<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">11</span>,<span class="number">13</span>,<span class="number">17</span>,<span class="number">19</span>,<span class="number">23</span>&#125;;</span><br><span class="line"><span class="type">int</span> maxs,number,n;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> u,<span class="type">int</span> last,<span class="type">int</span> p,<span class="type">int</span> s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(s &gt; maxs||s == maxs&amp;&amp;p&lt;number)</span><br><span class="line">    &#123;</span><br><span class="line">        maxs=s;</span><br><span class="line">        number=p;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(u==<span class="number">9</span>)<span class="keyword">return</span> ;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=last;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="number">1ll</span>*p*primes[u]&gt;n)<span class="keyword">break</span>;</span><br><span class="line">        p*=primes[u];</span><br><span class="line">        <span class="built_in">dfs</span>(u<span class="number">+1</span>,i,p,s*(i<span class="number">+1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">dfs</span>(<span class="number">0</span>,<span class="number">30</span>,<span class="number">1</span>,<span class="number">1</span>);<span class="comment">//初始最大的α为30</span></span><br><span class="line">    </span><br><span class="line">    cout&lt;&lt;number&lt;&lt;endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="分解质因数优化暴力枚举约数">分解质因数优化暴力枚举约数</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMjAwLw==">198反素数<i class="fa fa-external-link-alt"></i></span></p><p><strong>2e9 次方以内的数的最多约数的数共有 1600左右的约数数量</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> x first</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> y second</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; PII;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">50010</span>;</span><br><span class="line"><span class="type">int</span> prime[N],countNum;</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line">PII factor[N];</span><br><span class="line"><span class="type">int</span> dividor[N];</span><br><span class="line"><span class="type">int</span> fcnt,dcnt;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">gcd</span><span class="params">(<span class="type">int</span> a,<span class="type">int</span> b)</span></span>&#123;<span class="keyword">return</span> b?<span class="built_in">gcd</span>(b,a%b):a;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(!st[i])prime[countNum++]=i;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;prime[j]*i&lt;=n;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            st[i*prime[j]]=<span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(i%prime[j]==<span class="number">0</span>)<span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> u,<span class="type">int</span> p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(u==fcnt)</span><br><span class="line">    &#123;</span><br><span class="line">        dividor[dcnt++]=p;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=factor[u].y;i++)&#123;</span><br><span class="line">        <span class="built_in">dfs</span>(u<span class="number">+1</span>,p);</span><br><span class="line">        p*=factor[u].x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">init</span>(N - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="keyword">while</span> (n -- )</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> a, b, c, d;</span><br><span class="line">        cin &gt;&gt; a &gt;&gt; b &gt;&gt; c &gt;&gt; d;</span><br><span class="line"></span><br><span class="line">        fcnt = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> t = d;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; prime[i] &lt;= t / prime[i]; i ++ )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> p = prime[i];</span><br><span class="line">            <span class="keyword">if</span> (t % p == <span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">int</span> s = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">while</span> (t % p == <span class="number">0</span>) t /= p, s ++ ;</span><br><span class="line">                factor[fcnt ++ ] = &#123;p, s&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (t &gt; <span class="number">1</span>) factor[fcnt ++ ] = &#123;t, <span class="number">1</span>&#125;;</span><br><span class="line"></span><br><span class="line">        dcnt = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">dfs</span>(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; dcnt; i ++ )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> x = dividor[i];</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">gcd</span>(a, x) == b &amp;&amp; (ll)c * x / <span class="built_in">gcd</span>(c, x) == d) res ++ ;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        cout &lt;&lt; res &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="欧拉函数">欧拉函数</h1><h2 id="欧拉函数概念">欧拉函数概念</h2><p>1-N 中与 N 互质的数的个数被称为欧拉函数记为 <spanclass="math inline">\(φ(n)\)</span></p><p>由容斥原理推出的公式：<spanclass="math inline">\(φ(n)=N(1-\frac{1}{p_1})(1-\frac{1}{p_2})...(1-\frac{1}{p_k})\)</span></p><p>容斥原理证明公式</p><p>对于 1-N 当中的每一个数（假设 1-N 中有三个 N 的质因子分别设为 <spanclass="math inline">\(p_1p_2p_3\)</span>）</p><p><span class="math display">\[φ(N)=N-N/p_1-N/p_2-N/p_3+N/（p_1p_2)+N/(p_2p_3)+N/(p_3p_1)-N/(p_1p_2p_3)\]</span> 化简即可推出上面的公式</p><p>递推式：<spanclass="math inline">\(φ(ab)=\frac{φ(a)φ(b)gcd(a,b)}{φ(gcd(a,b))}\)</span></p><h2 id="欧拉函数的题目">欧拉函数的题目</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMjAzLw==">203可见的点<i class="fa fa-external-link-alt"></i></span></p><p><strong>思维+欧拉函数</strong></p><p>对于每一个被光照到的点，其 x, y 必然满足以下条件</p><ol type="1"><li>x, y 为整数</li><li>(x, y)是直线 y = kx 在第一象限以原点为端点的射线上的第一个整点</li><li>即 x, y 为互质的数</li></ol><p><strong>证明</strong></p><p>若 x, y 为非互质的数则存在这么一个整数点(x/d, y/d)使得其与(x,y)处于同一直线且位于(x, y)的左下方</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1010</span>;</span><br><span class="line"><span class="type">int</span> primes[N],countNum;</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line"><span class="type">int</span> eular[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initEular</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    eular[<span class="number">1</span>]=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(!st[i])&#123;</span><br><span class="line">            primes[countNum++]=i;</span><br><span class="line">            eular[i]=i<span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;primes[j]*i&lt;=n;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            st[i*primes[j]]=<span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(i%primes[j]==<span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                eular[primes[j]*i]=eular[i]*primes[j];</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            eular[primes[j]*i]=eular[i]*(primes[j]<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">initEular</span>(N<span class="number">-1</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> _;</span><br><span class="line">    cin&gt;&gt;_;</span><br><span class="line">    <span class="type">int</span> T=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(_--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> n;</span><br><span class="line">        cin&gt;&gt;n;</span><br><span class="line">        ll sum=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) sum+=eular[i]*<span class="number">2</span>;</span><br><span class="line">        cout&lt;&lt;++T&lt;&lt;<span class="string">&#x27; &#x27;</span>&lt;&lt;n&lt;&lt;<span class="string">&#x27; &#x27;</span>&lt;&lt;sum&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMjIyLw==">220最大公约数<i class="fa fa-external-link-alt"></i></span></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">1e7</span><span class="number">+10</span>;</span><br><span class="line"><span class="type">int</span> primes[N],countNum;</span><br><span class="line"><span class="type">bool</span> st[N];</span><br><span class="line">ll phi[N],s[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">eular</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(!st[i])&#123;</span><br><span class="line">            primes[countNum++]=i;</span><br><span class="line">            phi[i]=i<span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;primes[j]*i&lt;=n;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            st[i*primes[j]]=<span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(i%primes[j]==<span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                phi[i*primes[j]]=phi[i]*primes[j];</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;phi[i*primes[j]]=phi[i]*(primes[j]<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)s[i]=s[i<span class="number">-1</span>]+phi[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    <span class="built_in">eular</span>(n);</span><br><span class="line">    </span><br><span class="line">    ll ans=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;countNum;i++ [数论，算法]g)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> p=primes[i];</span><br><span class="line">        ans+=s[n/p]*<span class="number">2</span><span class="number">+1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;ans&lt;&lt;endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="同余">同余</h1><h2 id="扩展欧几里得算法裴蜀定理">扩展欧几里得算法（裴蜀定理）</h2><h3 id="概念与推导">概念与推导</h3><p><span class="math inline">\((a,b)=d =&gt; a * x +b * y = d\)</span><span class="math inline">\((b,a mod b)\)</span></p><p><strong>假定</strong> <span class="math inline">\(y * b + x * (a modb) =d\)</span></p><p><spanclass="math inline">\(y*b+x(a-\lfloor\frac{a}{b}\rfloor*b)=d\)</span></p><p><spanclass="math inline">\(y*b+a*x-\lfloor\frac{a}{b}\rfloor*b*x=d\)</span></p><p><span class="math inline">\(a*x +b*(y-\lfloor\frac{a}{b}\rfloor*x)=d\)</span></p><p><span class="math inline">\(=&gt; x&#39;=x\quady&#39;=y-\lfloor\frac{a}{b}\rfloor*x\)</span></p><h3 id="拓展">拓展</h3><p>对于 <span class="math inline">\((a,b)=d\)</span></p><p>对于该方程的一组解</p><p><span class="math inline">\(a*x_0+b*y_0=d\)</span></p><p>有以下结论: <span class="math display">\[x=x_0+k*(\frac{a}{d})\quad y=y_0-k*(\frac{b}{d})\]</span> 为该同余方程的通解</p><p>这种变形实际上也是一种十分常见得数学变形方式，在数学上叫做零和变形。</p><h2 id="同余方程">同余方程</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMjA1Lw==">203同余方程<i class="fa fa-external-link-alt"></i></span> <span class="math inline">\(ax≡1(modb)\)</span></p><p>=&gt; <span class="math inline">\(ax-by=1\)</span></p><p>且 x 一定为正值（数学中的取模不会取到正值）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">exgcd</span><span class="params">(<span class="type">int</span> a,<span class="type">int</span> b,<span class="type">int</span>&amp; x,<span class="type">int</span>&amp; y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(!b)&#123;</span><br><span class="line">        x=<span class="number">1</span>,y=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> a;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> d=<span class="built_in">exgcd</span>(b,a%b,y,x);</span><br><span class="line">    y-=(a/b)*x;</span><br><span class="line">    <span class="keyword">return</span> d;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> a,b,x,y;</span><br><span class="line">    cin&gt;&gt;a&gt;&gt;b;</span><br><span class="line">    <span class="built_in">exgcd</span>(a,b,x,y);</span><br><span class="line">    cout&lt;&lt;(x%b+b)%b&lt;&lt;endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="青蛙的约会">青蛙的约会</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMjI0Lw==">222青蛙的约会<i class="fa fa-external-link-alt"></i></span></p><p>A 追 B (b-a) , 每跳一次 A 追 B(m-n)米</p><p><span class="math inline">\((m-n)x=b-a+yL\)</span></p><p>=&gt; <span class="math inline">\((m-n)x=b-a+yL\)</span>[数论，算法]g =&gt; <spanclass="math inline">\((m-n)x-yL=b-a\)</span></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"></span><br><span class="line"><span class="function">ll <span class="title">exgcd</span><span class="params">(ll a,ll b,ll&amp; x,ll&amp; y)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(!b)</span><br><span class="line">    &#123;</span><br><span class="line">        x=<span class="number">1</span>,y=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> a;</span><br><span class="line">    &#125;</span><br><span class="line">    ll d=<span class="built_in">exgcd</span>(b,a%b,y,x);</span><br><span class="line">    y-=a/b*x;</span><br><span class="line">    <span class="keyword">return</span> d;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ll a,b,m,n,L;</span><br><span class="line">    cin&gt;&gt;a&gt;&gt;b&gt;&gt;m&gt;&gt;n&gt;&gt;L;</span><br><span class="line">    ll x,y;</span><br><span class="line">    ll d = <span class="built_in">exgcd</span>(m-n,L,x,y);</span><br><span class="line">    <span class="keyword">if</span>((b-a)%d!=<span class="number">0</span>)<span class="built_in">puts</span>(<span class="string">&quot;Impossible&quot;</span>);</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        x*=(b-a)/d;</span><br><span class="line">        ll t=<span class="built_in">abs</span>(L/d);</span><br><span class="line">        cout&lt;&lt;(x%t+t)%t&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="最幸运的数字">最幸运的数字</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYWN3aW5nLmNvbS9wcm9ibGVtL2NvbnRlbnQvMjA0Lw==">202最幸运的数字<i class="fa fa-external-link-alt"></i></span></p><p>对于一串 8，用一个公式表示这个数字</p><p>8888..8(x 个 8) =&gt; 8 * 1111..1 =&gt; 8 * 9999..9/9 =&gt; 8 *(10^x-1)/9</p><p>也可以用公比为 10，初项为 8 的等比数列求和思量</p><p>考量题目</p><p>对于一个 888..8 的约数 L|8*(10^x-1)/9 &lt;=&gt; (9L/d)|(10 ^ x-1)</p><p>&lt;=&gt; 10<sup>x</sup>= 1(mod C) C = 9L/d</p><p>eular 定理：对于 α<sup>phi(n)</sup>= 1(mod n) (α, n)= 1</p><p>根据 eular 与 10<sup>x</sup> = 1(mod C)</p><p>枚举 phi(c)的约数，最小的 10^i%c == 1 即为答案</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"></span><br><span class="line"><span class="function">ll <span class="title">gcd</span><span class="params">(ll a,ll b)</span></span>&#123;<span class="keyword">return</span> b?<span class="built_in">gcd</span>(b,a%b):a;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ll <span class="title">slow_mul</span><span class="params">(ll a,ll b,ll p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ll res=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(b)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(b&amp;<span class="number">1</span>)res=(res+a)%p;</span><br><span class="line">        a=(a+a)%p;</span><br><span class="line">        b&gt;&gt;=<span class="number">1</span>;</span><br><span class="line">     [数论，算法]g&#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ll <span class="title">qmi</span><span class="params">(ll a,ll b,ll c)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ll res=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(b)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(b&amp;<span class="number">1</span>)res=<span class="built_in">slow_mul</span>(res,a,c);</span><br><span class="line">        a=<span class="built_in">slow_mul</span>(a,a,c);</span><br><span class="line">        b&gt;&gt;=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res%c;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">ll <span class="title">get_eular</span><span class="params">(ll a)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ll res=a;</span><br><span class="line">    <span class="keyword">for</span>(ll i=<span class="number">2</span>;i&lt;=a/i;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(a%i==<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">while</span>(a%i==<span class="number">0</span>)a/=i;</span><br><span class="line">            res=res/i*(i<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(a&gt;<span class="number">1</span>) res=res/a*(a<span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> T=<span class="number">1</span>;</span><br><span class="line">    ll L;</span><br><span class="line">    <span class="keyword">while</span>(cin&gt;&gt;L,L)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> d=<span class="number">1</span>;</span><br><span class="line">        d=<span class="built_in">gcd</span>(L,<span class="number">8</span>) [数论，算法]g;</span><br><span class="line"></span><br><span class="line">        ll c= <span class="number">9</span>*L/d;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// cout&lt;&lt;c&lt;&lt;endl;</span></span><br><span class="line"></span><br><span class="line">        ll phi = <span class="built_in">get_eular</span>(c);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// cout&lt;&lt;phi&lt;&lt;endl;</span></span><br><span class="line"></span><br><span class="line">        ll ans=<span class="number">1e18</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">gcd</span>(c,<span class="number">10</span>)!=<span class="number">1</span>)ans=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(ll i=<span class="number">1</span>;i&lt;=phi/i;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(phi%i==<span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>((<span class="built_in">qmi</span>(<span class="number">10</span>,i,c))==<span class="number">1</span>)ans=<span class="built_in">min</span>(ans,i);</span><br><span class="line">                <span class="keyword">if</span>((<span class="built_in">qmi</span>(<span class="number">10</span>,phi/i,c))==<span class="number">1</span>)ans=<span class="built_in">min</span>(ans,phi/i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Case %d: %lld\n&quot;</span>,T++,ans);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="曹冲养猪">曹冲养猪</h2><p><strong>中国剩余定理</strong></p><p><span class="math display">\[\begin{cases}x=a_1(mod\quadm_1)\\x=a_2(mod\quad m_2)\\x=a_3(mod\quad m_3)\\...\\x=a_n(mod\quadm_n)\end{cases}\]</span></p><p>设 <span class="math inline">\(M=m_1m_2m_3...m_n\)</span>[数论，算法]g 令 <span class="math inline">\(M_i=M/m_i\)</span> <spanclass="math inline">\(t_i\)</span> 是 <spanclass="math inline">\(M_i\)</span> 关于 M 的逆元</p><p><span class="math inline">\(M_it_i=1(mod\quad m_i)\)</span></p><p><span class="math inline">\(x=\sum a_iM_it_i\)</span></p><p>==构造解，硬记，比较难==</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">20</span>;</span><br><span class="line">ll a[N],b[N];</span><br><span class="line"></span><br><span class="line"><span class="function">ll <span class="title">exgcd</span><span class="params">(ll a,ll b,ll&amp; x,ll&amp; y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(!b)</span><br><span class="line">    &#123;</span><br><span class="line">        x=<span class="number">1</span>,y=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> a;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> d=<span class="built_in">exgcd</span>(b,a%b,y,x);</span><br><span class="line">    y-=a/b*x;</span><br><span class="line">    <span class="keyword">return</span> d;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    ll M=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">        cin&gt;&gt;a[i]&gt;&gt;b[i] [数论，算法]g;</span><br><span class="line">        M*=a[i];</span><br><span class="line">    &#125;</span><br><span class="line">    ll ans=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        ll mi=M/a[i];</span><br><span class="line">        ll ti,x;</span><br><span class="line">        <span class="built_in">exgcd</span>(mi,a[i],ti,x);</span><br><span class="line">        ans+=b[i]*mi*ti;</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;(ans%M+M)%M&lt;&lt;endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="矩阵乘法">矩阵乘法</h1><h2 id="求斐波那契数列的和">求斐波那契数列的和</h2><p>fn+1 = fn+fn-1;</p><p>sn = f1+f2+f3+f4...+fn</p><p>sn+1 = f1+f2+f3+f4+...+fn+1</p><p><span class="math inline">\(s_{n+1}-s_n=f_{n+1}\)</span></p><p>构造一个矩阵 Fn = fn, fn+1, sn</p><p>Fn ={fn, fn+1, sn}*</p><p>{ {0,1,0}</p><p>{1,1,1}</p><p>{0,0,1}}= Fn+1 ={fn+1，fn+2，sn+1};</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector [数论，算法]g&gt;</span><br><span class="line">#include&lt;cstring&gt;</span><br><span class="line">#include&lt;cstdio&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line"></span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int N = 3;</span><br><span class="line">int n, m;</span><br><span class="line"></span><br><span class="line">void mul(int c[], int a[], int b[][N])</span><br><span class="line">&#123;</span><br><span class="line">    int t[N]=&#123;0&#125;;</span><br><span class="line">    for (int i = 0; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j = 0; j &lt; N; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            t[i] = (t[i] + 1ll * a[j] * b[j][i]) % m;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    memcpy(c, t, sizeof t);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void mul(int c[][N], int a[][N], int b[][N])</span><br><span class="line">&#123;</span><br><span class="line">    int t[N][N]=&#123;0&#125;;</span><br><span class="line">    for (int i = 0; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        for (int j = 0; j &lt; N; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            for (int k = 0; k &lt; N; k++)</span><br><span class="line">            &#123;</span><br><span class="line">                t[i][j] = (t[i][j] + 1ll * a[i][k] * b[k][j]) % m;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    memcpy(c, t, sizeof t);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line"> [数论，算法]g&#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; m;</span><br><span class="line">    int F1[N] = &#123; 1,1,1 &#125;;</span><br><span class="line">    int A[N][N] = &#123;</span><br><span class="line">        &#123;0,1,0&#125;,</span><br><span class="line">        &#123;1,1,1&#125;,</span><br><span class="line">        &#123;0,0,1&#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">n--;</span><br><span class="line">    while (n)</span><br><span class="line">    &#123;</span><br><span class="line">        /*for(int i=0;i&lt;N;i++)&#123;</span><br><span class="line">        for(int j=0;j&lt;N;j++)</span><br><span class="line">        cout&lt;&lt;A[i][j]&lt;&lt;&#x27; &#x27;;</span><br><span class="line">        puts(&quot;&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        for(int i=0;i&lt;N;i++)cout&lt;&lt;F1[i]&lt;&lt;&#x27; &#x27;;</span><br><span class="line">        puts(&quot;&quot;);*/</span><br><span class="line">        if (n &amp; 1)mul(F1, F1, A);</span><br><span class="line">        mul(A, A, A);</span><br><span class="line">        n &gt;&gt;= 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; F1[2] &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1id="求一个关于斐波那契数列的特殊数列和">求一个关于斐波那契数列的特殊数列和</h1><p>T(n)=(f1+2f2+3f3+…+nfn)modm</p><p>nsn-tn =(n-1)f1+(n-2)f2+...+fn-1</p><p>(n+1)sn+1-tn+1 = nf1+(n-1)f2+...+fn</p><p>(n+1)sn+1-tn+1-(nsn-tn)= sn</p><p>那么我们设 pn = sn-tn</p><p>Fn ={fn, fn+1, sn, pn} [数论，算法]g*</p><p>{</p><p>{0,1,0,0},</p><p>{1,1,1,0},</p><p>{0,0,1,1},</p><p>{0,0,0,1}</p><p>};= Fn+1 ={fn+1.fn+2, sn+1, sn+2}</p><p>ps: 为了简化代码，我们将初始的 F1 扩展为二维矩阵</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">4</span>;</span><br><span class="line"><span class="type">int</span> n,m;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">mul</span><span class="params">(<span class="type">int</span> c[][N],<span class="type">int</span> a[][N],<span class="type">int</span> b[][N])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> t[N][N]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;N;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;N;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> k=<span class="number">0</span>;k&lt;N;k++)</span><br><span class="line">            &#123;</span><br><span class="line">                t[i][j]=(t[i][j]<span class="number">+1ll</span>*a[i][k]*b[k][j])%m;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">memcpy</span>(c,t,<span class="keyword">sizeof</span> t);</span><br><span class="line"> [数论，算法]g&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cin&gt;&gt;n&gt;&gt;m;</span><br><span class="line">    <span class="type">int</span> F1[N][N]=&#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int</span> A[N][N]=&#123;</span><br><span class="line">        &#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>&#125;,</span><br><span class="line">        &#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>&#125;,</span><br><span class="line">        &#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>&#125;,</span><br><span class="line">        &#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>&#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> k=n<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">while</span>(k)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(k&amp;<span class="number">1</span>)<span class="built_in">mul</span>(F1,F1,A);</span><br><span class="line">        <span class="built_in">mul</span>(A,A,A);</span><br><span class="line">        k&gt;&gt;=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cout&lt;&lt;(<span class="number">1ll</span>*F1[<span class="number">0</span>][<span class="number">2</span>]*n-F1[<span class="number">0</span>][<span class="number">3</span>]+m)%m&lt;&lt;endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="组合数学">组合数学</h1><p>这里给出一下一个非常常用的全排列函数：</p><p>next_permutation()</p><p>这个函数也十分便于记忆，permutation即<code>排列</code>的意思。</p><h2 id="总结">总结</h2><p><strong>I</strong></p><p>利用 Cab = Ca-1b+Ca-1b-1 的组合数学规律 dp 出二位数组保存结果</p><p><strong>II</strong></p><p>利用除以一个数等于乘以一个数的逆元的形式预处理出阶乘，o1的时间内得到特定结果</p><h1 id="多重集合的全排列">多重集合的全排列</h1><p>多重集合的定义：<strong>多重集合不要求元素不能重复</strong></p><h2 id="多重集合表示">多重集合表示：</h2><p>M ={k1⋅a1, k2⋅a2, ⋯, kn⋅an}M ={k1⋅a1, k2⋅a2, ⋯, kn⋅an}(其中每个 ai代表是不同的元素，每个元素 ai 有 ki 个，ki 可以是有限数，也可以是∞。)(其中每个 ai 代表是不同的元素，每个元素 ai 有 ki 个，ki可以是有限数，也可以是 ∞。)</p><h2 id="多重集的排列">多重集的排列:</h2><ul><li>多重集合 M ={k1⋅a1, k2⋅a2, ⋯, kn⋅an}的 r 排列数为 kr 多重集合 M={k1⋅a1, k2⋅a2, ⋯, kn⋅an}的 r 排列数为 <spanclass="math inline">\(k^r\)</span></li><li>多重集合 M ={k1⋅a1, k2⋅a2, ⋯, kn⋅an}的全排列数为：<spanclass="math inline">\(\frac{(k1+k2+⋯+kn)!}{k1!k2!⋯kn!}\)</span></li></ul><h1 id="数学知识">数学知识</h1><h1 id="排列">排列</h1><h2 id="错排公式">错排公式</h2><h3 id="错排问题">错排问题</h3><p><strong>错排问题</strong> 考虑一个有 n个元素的排列，若一个排列中所有的元素都不在自己原来的位置上，那么这样的排列就称为原排列的一个错排。n 个元素的错排数记为D(n)。研究一个排列错排个数的问题，叫做错排问题或称为更列问题。</p><h3 id="错排公式的递推">错排公式的递推</h3><p>对于 $D(n) $，考虑第 <span class="math inline">\(n\)</span>个位置，它可以与 <span class="math inline">\(n-1\)</span>前的任意位置交换 <spanclass="math inline">\(((n-1)D(n-1))\)</span>，在考虑编号为 k的位置，这是有两种情况</p><p>（1）将它放到 <spanclass="math inline">\(n\)</span>，那么，对于剩下的 n-1 个元素，由于第 k个元素放到了位置 n，剩下 n-2 个元素就有 <spanclass="math inline">\(D(n-2)\)</span> 种方法，此时放置方法有 <spanclass="math inline">\(D(n-2)\)</span> 种。</p><p>（2）将它不放到 n，那么，剩下 n-2 个元素就有D(n-2)种方法，此时放置方法有 <spanclass="math inline">\(((n-2)*D(n-2))\)</span> 种。</p><p><strong>递推关系式：D(n) = (n-1) [D(n-2) + D(n-1)] (n &gt;=3)</strong></p><p>特别的 <span class="math inline">\(D(1)=0,D(2)=1\)</span>;</p><p>其实到这里就结束了，通过递推关系式可以计算机直接算出 <spanclass="math inline">\(D(n)\)</span></p><p>但是下面还是给出错排公式的推导</p><p>以上是必须要会的内容，最好是尝试自己在没有辅助材料的情况下过一遍。（这种方法又称费曼学习法）</p><h3 id="错排公式的推导">错排公式的推导</h3><p>[数论，算法]g 假设 <span class="math inline">\(D(k) = k! N(k), k = 1,2, …, n,\)</span> 且有 <span class="math inline">\(N(1) = 0, N(2) =1/2.\)</span> 当 <span class="math inline">\(n ≥ 3\)</span> 时，<spanclass="math inline">\(n!\cdot N(n) = (n-1) (n-1)! N(n-1) + (n-1)!N(n-2)\)</span></p><p>即有公式</p><p><span class="math display">\[N(n) = (n-1) N(n-1) +N(n-2)\]</span></p><p>于是有 <span class="math display">\[N(n) - N(n-1) = - [N(n-1) -N(n-2)] / n = (-1/n) [-1/(n-1)] [-1/(n-2)]…(-1/3) [N(2) - N(1)] = (-1)^n/ n!\]</span></p><p>因此</p><p><span class="math inline">\(N(n-1) - N(n-2) = (-1)^{(n-1)} /(n-1)!\)</span>,</p><p><span class="math display">\[N(2) - N(1) = (-1)^2 / 2!\]</span></p><p>相加，可得</p><p><span class="math display">\[N(n) = (-1)^2/2! + … + (-1)^(n-1) /(n-1)! + (-1)^n/n!\]</span></p><p>因此</p><p><span class="math display">\[D(n) = n! [(-1)^2/2! + … +(-1)^(n-1)/(n-1)! + (-1)^n/n!]\]</span></p><p><span class="math display">\[D(n) = ∑_{k=2}^{n} (-1)^k * n! /k!\]</span></p><p>此即错排公式。</p><p>### 另一种方式的推导——容斥原理</p><p>正整数 1, 2, 3, ……, n 的全排列有 n! 种，其中第 k 位是 k 的排列有(n-1)! 种; 当 k 分别取 1, 2, 3, ……, n 时，共有 n*(n-1)!种排列是至少放对了一个的，由于所求的是错排的种数，所以应当减去这些排列;但是此时把同时有两个数错排的排列多排除了一次，应补上;在补上时，把同时有三个数不错排的排列多补上了一次，应排除;……;继续这一过程，得到错排的排列种数为</p><p>D(n) = n! - n!/1! + n!/2! - n!/3! + … + (-1)^n <em>n!/n! = ∑(k = 2~n)(-1)^k </em> n! / k!,</p><p>即 D(n) = n! [1/0! - 1/1! + 1/2! - 1/3! + 1/4! + ... +(-1)^n/n!].</p><h2 id="线性代数">线性代数</h2><h3 id="线性基">线性基</h3><h4 id="有关线性基的一些概念">有关线性基的一些概念</h4><p>[数论，算法]g ##### 张成的概念</p><p>设 ，所有这样的子集 的异或和组成的集合称为集合 的<strong>张成</strong>，记作 。即，在中选出任意多个数，其异或和的所有可能的结果组成的集合。</p><h5 id="线性相关">线性相关</h5><p>对于一个集合 ，如果存在一个元素 ，使得， 在去除这个元素后得到的集合的张成 中包含 ，则称集合 <strong>线性相关</strong>。</p><p>更形象地，可以表示为，存在一个元素，可以用其它若干个元素异或起来得到。</p><p>相对的，如果不存在这样的元素 ，则称集合<strong>线性无关</strong>。</p><p>一个显然的结论是，对于这个线性相关的集合，去除这个元素后，集合的张成不变。</p><h4 id="概念与性质">概念与性质</h4><p>线性基是向量空间的一组基，通常用来解决有关异或的题目，通俗的讲法就是由一个集合构造出来的另一个集合，它有以下几个性质</p><ol type="1"><li>线性基的元素能相互异或得到原集合的所有相互异或得到的值</li><li>线性基是满足性质 1 的最小的集合</li><li>线性基没有异或和为 0 的子集</li><li>线性基种的每个元素的异或方案唯一，也就是说，线性基中的异或组合异或出的数都是不一样的</li><li>线性基中的每个元素的二级制最高位互不相同</li></ol><h4 id="线性基的构造方法">线性基的构造方法</h4><p>对原集合的每一个数 p 转化为二进制，从高位向低位扫，对于第 x 位为 1的，如果 <span class="math inline">\(a_x\)</span> 不存在，那么令 <spanclass="math inline">\(a_x = p\)</span> 并结束扫描，如果存在，令 <spanclass="math inline">\(p_i=p_ixor a_x\)</span></p><p>code:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">insert</span><span class="params">(<span class="type">long</span> <span class="type">long</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">55</span>; i + <span class="number">1</span>; i--) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!(x &gt;&gt; i))  <span class="comment">// x的第i位是0</span></span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    <span class="keyword">if</span> (!p[i]) &#123;</span><br><span class="line">      p[i] = x;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    x ^= p[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="查询原集合内任意几个元素-xor-的最大值">查询原集合内任意几个元素xor 的最大值</h4><p>将线性基从高位向低位扫，若 xor 上当前扫到的 <spanclass="math inline">\(a_x\)</span> 答案变大，就把答案异或上 <spanclass="math inline">\(a_x\)</span></p><h4 id="第-k-大的子集合异或和">第 k 大的子集合异或和</h4><p><span class="exturl" data-url="aHR0cHM6Ly92anVkZ2UuY3NncmFuZGV1ci5jbi9wcm9ibGVtL0hEVS0zOTQ5">HDU3949<i class="fa fa-external-link-alt"></i></span></p><p>要求我们查询一个数组能异或出来的第 k 大的值</p><p>构造一个特殊的线性基，使得每一个线性基中的值都只有一位是 1</p><p>如 a1:0001000 a2:0000010 a3:00000001</p><p>从小到大存入一个容器中，再枚举查询的第 k 大的 k 值某一位上是否为1，如果是 1，则将 ans 异或上对应下标的线性基数组中的值</p><p>注意如果线性基的大小与原数组的大小不一样，说明原数组是线性相关的，此时则需要将k-1，在进行查询（0 是最小的）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bitset&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;array&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;atomic&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iomanip&gt;</span></span></span><br><span class="line"><span class="comment">//#include&lt;bits/stdc++.h&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> int ll</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> pb push_back</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> endl <span class="string">&#x27;\n&#x27;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> x first</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> y second</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Endl endl</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> pre(i,a,b) for(int i=a;i&lt;=b;i++)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> rep(i,b,a) for(int i=b;i&gt;=a;i--)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> si(x) scanf(<span class="string">&quot;%d&quot;</span>, &amp;x);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> sl(x) scanf(<span class="string">&quot;%lld&quot;</span>, &amp;x);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ss(x) scanf(<span class="string">&quot;%s&quot;</span>, x);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> YES &#123;puts(<span class="string">&quot;YES&quot;</span>);return;&#125;</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NO &#123;puts(<span class="string">&quot;NO&quot;</span>); return;&#125;</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> all(x) x.begin(),x.end()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span> ull;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; PII;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, PII&gt; PIII;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">char</span>, <span class="type">int</span>&gt; PCI;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">char</span>&gt; PIC;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">double</span>, <span class="type">double</span>&gt; PDD;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;ll, ll&gt; PLL;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">200010</span>, M = <span class="number">2</span> * N, B = N, MOD = <span class="number">1000000007</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> INF = <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"><span class="type">const</span> ll LLINF = <span class="number">0x3f3f3f3f3f3f3f3f</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> dx[<span class="number">4</span>] = &#123; <span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span> &#125;, dy[<span class="number">4</span>] = &#123; <span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span> &#125;;</span><br><span class="line"><span class="type">int</span> n, m, k;</span><br><span class="line">ll a[N], p[N], q[N];</span><br><span class="line"></span><br><span class="line"><span class="function">ll <span class="title">gcd</span><span class="params">(ll a, ll b)</span> </span>&#123; <span class="keyword">return</span> b ? <span class="built_in">gcd</span>(b, a % b) : a; &#125;</span><br><span class="line"><span class="function">ll <span class="title">lowbit</span><span class="params">(ll x)</span> </span>&#123; <span class="keyword">return</span> x &amp; -x; &#125;</span><br><span class="line"><span class="function">ll <span class="title">qmi</span><span class="params">(ll a, ll b, ll mod)</span> </span>&#123;</span><br><span class="line">    ll res = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (b) &#123;</span><br><span class="line">        <span class="keyword">if</span> (b &amp; <span class="number">1</span>) res = res * a % mod;</span><br><span class="line">        a = a * a % mod;</span><br><span class="line">        b &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(ll x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">rep</span>(i, <span class="number">63</span>, <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (!(x &gt;&gt; i))<span class="keyword">continue</span>;</span><br><span class="line">        <span class="keyword">if</span> (!p[i]) &#123;</span><br><span class="line">            p[i] = x;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        x ^= p[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">slove</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">memset</span>(p, <span class="number">0</span>, <span class="keyword">sizeof</span> p);</span><br><span class="line">    <span class="type">static</span> <span class="type">int</span> T = <span class="number">0</span>;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="built_in">pre</span>(i, <span class="number">1</span>, n) &#123;</span><br><span class="line">        cin &gt;&gt; a[i];</span><br><span class="line">        <span class="built_in">insert</span>(a[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">rep</span>(i, <span class="number">63</span> - <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">pre</span>(j, i + <span class="number">1</span>, <span class="number">63</span> - <span class="number">1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (p[j] &gt;&gt; i &amp; <span class="number">1</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                p[j] ^= p[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    vector&lt;ll&gt; ves;</span><br><span class="line">    <span class="built_in">pre</span>(i, <span class="number">0</span>, <span class="number">63</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (p[i])ves.<span class="built_in">push_back</span>(p[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cin &gt;&gt; m;</span><br><span class="line">    <span class="built_in">pre</span>(i, <span class="number">1</span>, m) cin &gt;&gt; q[i];</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Case #%d:\n&quot;</span>, ++T);</span><br><span class="line">    <span class="built_in">pre</span>(i, <span class="number">1</span>, m)</span><br><span class="line">    &#123;</span><br><span class="line">        ll res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (n != ves.<span class="built_in">size</span>())q[i]--;</span><br><span class="line">        <span class="built_in">pre</span>(j, <span class="number">0</span>, <span class="number">63</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (q[i] &gt;&gt; j &amp; <span class="number">1</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (j &gt;= ves.<span class="built_in">size</span>()) &#123;</span><br><span class="line">                    res = <span class="number">-1</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                res ^= ves[j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        cout &lt;&lt; res &lt;&lt; Endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">signed</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> _;</span><br><span class="line">    <span class="built_in">si</span>(_);</span><br><span class="line">    <span class="comment">//_ = 1;</span></span><br><span class="line">    <span class="built_in">init</span>();</span><br><span class="line">    <span class="keyword">while</span> (_--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">slove</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="最大路径异或和">最大路径异或和</h4><p>[P4151 <span class="exturl" data-url="aHR0cHM6Ly93d3cubHVvZ3UuY29tLmNuL3Byb2JsZW0vUDQxNTE=">WC2011]最大XOR 和路径 - 洛谷 | 计算机科学教育新生态 (luogu.com.cn)<i class="fa fa-external-link-alt"></i></span></p><p>求从 1 到 n的最大路径异或和，首先在纸上作图，发现，来回的走一条路径是等价于没有走过的，因此，我们可以从图上的任一点到达另一点后走回来是等价于停留在原地的，因此我们可以将1-n的路径拓展到所有的点上而保持值不变，通过观察，我们可以发现，环可以为我们的路径权值提供贡献值，因为它们是可以在（扩展到全图后的路径）路径中走奇数遍的。</p><p>因此，我们 dfs 对环建立线性基，刚开始随机选取一条 1-n的路径，与线性基异或取最大值（注意，因为 ans 刚开始并不是0，因此每次选取需要 max）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bitset&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;array&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;atomic&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iomanip&gt;</span></span></span><br><span class="line"><span class="comment">//#include&lt;bits/stdc++.h&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> int ll</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> pb push_back</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> endl <span class="string">&#x27;\n&#x27;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> x first</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> y second</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Endl endl</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> pre(i,a,b) for(int i=a;i&lt;=b;i++)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> rep(i,b,a) for(int i=b;i&gt;=a;i--)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> si(x) scanf(<span class="string">&quot;%d&quot;</span>, &amp;x);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> sl(x) scanf(<span class="string">&quot;%lld&quot;</span>, &amp;x);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ss(x) scanf(<span class="string">&quot;%s&quot;</span>, x);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> YES &#123;puts(<span class="string">&quot;YES&quot;</span>);return;&#125;</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NO &#123;puts(<span class="string">&quot;NO&quot;</span>); return;&#125;</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> all(x) x.begin(),x.end()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span> ull;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; PII;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, PII&gt; PIII;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">char</span>, <span class="type">int</span>&gt; PCI;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">char</span>&gt; PIC;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">double</span>, <span class="type">double</span>&gt; PDD;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;ll, ll&gt; PLL;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">200010</span>, M = <span class="number">2</span> * N, B = N, MOD = <span class="number">1000000007</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> INF = <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"><span class="type">const</span> ll LLINF = <span class="number">0x3f3f3f3f3f3f3f3f</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> dx[<span class="number">4</span>] = &#123; <span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span> &#125;, dy[<span class="number">4</span>] = &#123; <span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span> &#125;;</span><br><span class="line"><span class="type">int</span> n, m, k;</span><br><span class="line"><span class="type">int</span> h[N], ne[M], e[M], idx;</span><br><span class="line">ll w[M], p[N], verval[N];</span><br><span class="line">ll ans;</span><br><span class="line"></span><br><span class="line"><span class="function">ll <span class="title">gcd</span><span class="params">(ll a, ll b)</span> </span>&#123; <span class="keyword">return</span> b ? <span class="built_in">gcd</span>(b, a % b) : a; &#125;</span><br><span class="line"><span class="function">ll <span class="title">lowbit</span><span class="params">(ll x)</span> </span>&#123; <span class="keyword">return</span> x &amp; -x; &#125;</span><br><span class="line"><span class="function">ll <span class="title">qmi</span><span class="params">(ll a, ll b, ll mod)</span> </span>&#123;</span><br><span class="line">    ll res = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (b) &#123;</span><br><span class="line">        <span class="keyword">if</span> (b &amp; <span class="number">1</span>) res = res * a % mod;</span><br><span class="line">        a = a * a % mod;</span><br><span class="line">        b &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b, <span class="type">int</span> c)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    e[idx] = b, w[idx] = c, ne[idx] = h[a], h[a] = idx++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">insert</span><span class="params">(ll x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">rep</span>(i, <span class="number">63</span>, <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (!(x &gt;&gt; i &amp; <span class="number">1</span>))<span class="keyword">continue</span>;</span><br><span class="line">        <span class="keyword">if</span> (!p[i]) &#123;</span><br><span class="line">            p[i] = x;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        x ^= p[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> u, ll val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    verval[u] = val;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = h[u]; ~i; i = ne[i])</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> j = e[i];</span><br><span class="line">        <span class="keyword">if</span> (verval[j] != <span class="number">-1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">insert</span>(val ^ verval[j] ^ w[i]);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">dfs</span>(j, val ^ w[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">slove</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">memset</span>(verval, <span class="number">-1</span>, <span class="keyword">sizeof</span> verval);</span><br><span class="line">    <span class="built_in">memset</span>(h, <span class="number">-1</span>, <span class="keyword">sizeof</span> h);</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; m; </span><br><span class="line">    <span class="type">int</span> a, b, c;</span><br><span class="line">    <span class="built_in">pre</span>(i, <span class="number">1</span>, m)</span><br><span class="line">    &#123;</span><br><span class="line">        cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;</span><br><span class="line">        <span class="built_in">add</span>(a, b, c); <span class="built_in">add</span>(b, a, c);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">dfs</span>(<span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    ll t = ans= verval[n];</span><br><span class="line">    <span class="built_in">rep</span>(i, <span class="number">63</span>, <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        ans = <span class="built_in">max</span>(ans, ans ^ p[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; ans &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">signed</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> _;</span><br><span class="line">    <span class="comment">//si(_);</span></span><br><span class="line">    _ = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">init</span>();</span><br><span class="line">    <span class="keyword">while</span> (_--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">slove</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="线性无关的特性线性基的大小">线性无关的特性，线性基的大小</h4><p>https://vjudge.csgrandeur.cn/problem/CodeForces-1101G</p><p>该题要求将一个数组分成若干个段，保证段本身，段与段之间的异或都不为 0的最大段数量</p><p>由于段与段之间的异或和不为0，因此，可判断，各段的异或值是线性无关的，且根据题目要求各段的异或值是不为0 的，因此，数组中线性相关的值必须放在同一段里另外加任意值。</p><p>应该敏锐的察觉到，上述特性与线性基的特性高度重合，因此，题目所求的值即位线性基的大小</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bitset&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;array&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;atomic&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iomanip&gt;</span></span></span><br><span class="line"><span class="comment">//#include&lt;bits/stdc++.h&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//#define int ll</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> pb push_back</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> endl <span class="string">&#x27;\n&#x27;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> x first</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> y second</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Endl endl</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> pre(i,a,b) for(int i=a;i&lt;=b;i++)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> rep(i,b,a) for(int i=b;i&gt;=a;i--)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> si(x) scanf(<span class="string">&quot;%d&quot;</span>, &amp;x);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> sl(x) scanf(<span class="string">&quot;%lld&quot;</span>, &amp;x);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ss(x) scanf(<span class="string">&quot;%s&quot;</span>, x);</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> YES &#123;puts(<span class="string">&quot;YES&quot;</span>);return;&#125;</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NO &#123;puts(<span class="string">&quot;NO&quot;</span>); return;&#125;</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> all(x) x.begin(),x.end()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span> ull;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; PII;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, PII&gt; PIII;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">char</span>, <span class="type">int</span>&gt; PCI;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">char</span>&gt; PIC;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">double</span>, <span class="type">double</span>&gt; PDD;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;ll, ll&gt; PLL;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">200010</span>, M = <span class="number">2</span> * N, B = N, MOD = <span class="number">998244353</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> INF = <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"><span class="type">const</span> ll LLINF = <span class="number">0x3f3f3f3f3f3f3f3f</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> dx[<span class="number">4</span>] = &#123; <span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span> &#125;, dy[<span class="number">4</span>] = &#123; <span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span> &#125;;</span><br><span class="line"><span class="type">int</span> n, m, k;</span><br><span class="line"><span class="type">int</span> a[N], p[<span class="number">35</span>];</span><br><span class="line"></span><br><span class="line"><span class="function">ll <span class="title">gcd</span><span class="params">(ll a, ll b)</span> </span>&#123; <span class="keyword">return</span> b ? <span class="built_in">gcd</span>(b, a % b) : a; &#125;</span><br><span class="line"><span class="function">ll <span class="title">lowbit</span><span class="params">(ll x)</span> </span>&#123; <span class="keyword">return</span> x &amp; -x; &#125;</span><br><span class="line"><span class="function">ll <span class="title">qmi</span><span class="params">(ll a, ll b, ll mod)</span> </span>&#123;</span><br><span class="line">    ll res = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (b) &#123;</span><br><span class="line">        <span class="keyword">if</span> (b &amp; <span class="number">1</span>) res = res * a % mod;</span><br><span class="line">        a = a * a % mod;</span><br><span class="line">        b &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">insert</span><span class="params">(<span class="type">int</span> x)</span> </span>&#123;</span><br><span class="line">    <span class="type">bool</span> res = <span class="literal">false</span>;</span><br><span class="line">    <span class="built_in">rep</span>(i, <span class="number">30</span>, <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (((x &gt;&gt; i) &amp; <span class="number">1</span>)==<span class="number">0</span>)<span class="keyword">continue</span>;</span><br><span class="line">        <span class="keyword">if</span> (p[i]==<span class="number">0</span>) &#123;</span><br><span class="line">            p[i] = x; res = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        x ^= p[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">slove</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="built_in">pre</span>(i, <span class="number">1</span>, n)cin &gt;&gt; a[i];</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> t=<span class="number">0</span>;</span><br><span class="line">    <span class="built_in">pre</span>(i, <span class="number">1</span>, n) &#123;</span><br><span class="line">        <span class="built_in">insert</span>(a[i]);</span><br><span class="line">        t ^= a[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!t) &#123; cout &lt;&lt; <span class="number">-1</span> &lt;&lt; endl; <span class="keyword">return</span>; &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">int</span> cnt = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">pre</span>(i, <span class="number">0</span>, <span class="number">30</span>)<span class="keyword">if</span> (p[i])cnt++;</span><br><span class="line">        cout &lt;&lt; cnt &lt;&lt; Endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">signed</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> _;</span><br><span class="line">    <span class="comment">//si(_);</span></span><br><span class="line">    _ = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">init</span>();</span><br><span class="line">    <span class="keyword">while</span> (_--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">slove</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="常见数学模型的特殊性质">常见数学模型的特殊性质</h1><h2 id="斐波那契数列">斐波那契数列</h2><p><strong><spanclass="math inline">\(\sum{_i^k}F[i]+1=F[k+2]\)</span></strong></p><p>如果 k 为奇数</p><p><spanclass="math inline">\(F[k]=F[1]+\sum{_{i=1}^{k/2}}F[2*i]\)</span></p><p>如果 k 为偶数</p><p><spanclass="math inline">\(F[k]=\sum{_{i=1}^{k/2}}F[2*i-1]\)</span></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言需要用到的偏僻语法知识&quot;&gt;前言：需要用到的偏僻语法知识&lt;/h1&gt;
&lt;h2 id=&quot;c随机数函数&quot;&gt;c++随机数函数&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NDIwMDg1ODk=&quot;&gt;如何优雅的用
C++生成随机数 - 知乎 (zhihu.com)&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;头文件：c: cstdlib c++: random&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cstdlib&lt;/code&gt; 中的 rand（）和 srand（）函数是 C
语言使用的随机数生成方法，通过 &lt;strong&gt;&lt;em&gt;线性同余法&lt;/em&gt;&lt;/strong&gt;
计算。&lt;/p&gt;</summary>
    
    
    
    <category term="算法" scheme="https://deepcity.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="数学" scheme="https://deepcity.github.io/categories/%E7%AE%97%E6%B3%95/%E6%95%B0%E5%AD%A6/"/>
    
    <category term="数论" scheme="https://deepcity.github.io/categories/%E7%AE%97%E6%B3%95/%E6%95%B0%E5%AD%A6/%E6%95%B0%E8%AE%BA/"/>
    
    
    <category term="算法" scheme="https://deepcity.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="数论" scheme="https://deepcity.github.io/tags/%E6%95%B0%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>Nodejs安装简要建议</title>
    <link href="https://deepcity.github.io/2024/Nodejs%E5%AE%89%E8%A3%85%E7%AE%80%E8%A6%81%E5%BB%BA%E8%AE%AE/article.html"/>
    <id>https://deepcity.github.io/2024/Nodejs%E5%AE%89%E8%A3%85%E7%AE%80%E8%A6%81%E5%BB%BA%E8%AE%AE/article.html</id>
    <published>2024-08-15T02:28:48.000Z</published>
    <updated>2024-08-15T02:41:25.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="NodeJS"><a href="#NodeJS" class="headerlink" title="NodeJS"></a>NodeJS</h2><h3 id="什么是Nodejs"><a href="#什么是Nodejs" class="headerlink" title="什么是Nodejs"></a>什么是Nodejs</h3><p><span class="exturl" data-url="aHR0cHM6Ly9ub2RlanMub3JnLw==">Node.js — Run JavaScript Everywhere<i class="fa fa-external-link-alt"></i></span>这是NodeJS的官网标题，很简单的概括，他就是在任何地方都可以运行javascript。</p><p>具体的讲，如下。。</p><blockquote><p> Node.js 就是运行在服务端的 JavaScript。 Node.js 是一个基于 Chrome JavaScript 运行时建立的一个平台。 Node.js 是一个事件驱动 I/O 服务端 JavaScript 环境，基于 Google 的 V8 引擎，V8 引擎执行 Javascript 的速度非常快，性能非常好。</p></blockquote><span id="more"></span><h3 id="下载时一步步涉及到的包管理"><a href="#下载时一步步涉及到的包管理" class="headerlink" title="下载时一步步涉及到的包管理"></a>下载时一步步涉及到的包管理</h3><p>nvm——Node Version Manager</p><p>fnm——Fast Node Manager</p><p>nvm 有一个致命的缺点，就是它的自动切换版本极其麻烦，而 fnm 就没这个问题。并且 Windows 上的 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL252bS1zaC9udm0=">nvm<i class="fa fa-external-link-alt"></i></span> 与 macOS 上的 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NvcmV5YnV0bGVyL252bS13aW5kb3dz">nvm<i class="fa fa-external-link-alt"></i></span> 实际上并不是同一个，Windows 的只是借了 nvm 的名称，API略有不同，构建两者的语言更是完全不相同。而 fnm 在三大系统上都是同一个，这保证了 API 的一致性。</p><p>下面以fnm为例</p><h3 id="fnm-下载"><a href="#fnm-下载" class="headerlink" title="fnm 下载"></a>fnm 下载</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://fnm.vercel.app/install | bash</span><br></pre></td></tr></table></figure><p>如果安装不成功，考虑是不是服务器连不上外网，通过其他渠道下载fnm软件包并解压到对应位置，在.bashrc中添加环境变量即可。下载链接如下：</p><p><span class="exturl" data-url="aHR0cHM6Ly9vYmplY3RzLmdpdGh1YnVzZXJjb250ZW50LmNvbS9naXRodWItcHJvZHVjdGlvbi1yZWxlYXNlLWFzc2V0LTJlNjViZS8xNjYwNDU0MjQvNGMwYTllMmEtOWIyMi00ZWJlLWIwMjYtZGU1ZTc4ZGU5MzUxP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9cmVsZWFzZWFzc2V0cHJvZHVjdGlvbiUyRjIwMjQwNTI5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDUyOVQwODMzMjRaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kNWUxMzc2M2I5NzUwNzI3YmQ0NWIwMTRkMTJhYTdlM2E4OTNmZmUyNzU4MTg5NzEwZDhjMTFkODc0ZWI5ZTY2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD05MTI3MzE2MSZrZXlfaWQ9MCZyZXBvX2lkPTE2NjA0NTQyNCZyZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRGZubS1saW51eC56aXAmcmVzcG9uc2UtY29udGVudC10eXBlPWFwcGxpY2F0aW9uJTJGb2N0ZXQtc3RyZWFtb2JqZWN0cy5naXRodWJ1c2VyY29udGVudC5jb20vZ2l0aHViLXByb2R1Y3Rpb24tcmVsZWFzZS1hc3NldC0yZTY1YmUvMTY2MDQ1NDI0LzRjMGE5ZTJhLTliMjItNGViZS1iMDI2LWRlNWU3OGRlOTM1MT9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPXJlbGVhc2Vhc3NldHByb2R1Y3Rpb24lMkYyMDI0MDUyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MjlUMDgzMzI0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZDVlMTM3NjNiOTc1MDcyN2JkNDViMDE0ZDEyYWE3ZTNhODkzZmZlMjc1ODE4OTcxMGQ4YzExZDg3NGViOWU2NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9OTEyNzMxNjEma2V5X2lkPTAmcmVwb19pZD0xNjYwNDU0MjQmcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj1hdHRhY2htZW50JTNCJTIwZmlsZW5hbWUlM0Rmbm0tbGludXguemlwJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT1hcHBsaWNhdGlvbiUyRm9jdGV0LXN0cmVhbQ==">fnm.zip<i class="fa fa-external-link-alt"></i></span></p><h3 id="NodeJS18版本以上的gcc-amp-make版本要求"><a href="#NodeJS18版本以上的gcc-amp-make版本要求" class="headerlink" title="NodeJS18版本以上的gcc&amp;make版本要求"></a>NodeJS18版本以上的gcc&amp;make版本要求</h3><p>要求gcc必须版本8以上（较流行的版本为11），make版本4以上，并且在一些环境下需要更新GLIBC（只能通过源码安装，因为涉及Linux底层动态链接库），通过下载源代码包configure（注意参数）以及make，make install即可安装，注意，此步骤为高级操作，操作前请备份快照重要文件，可能导致库文件缺失引起的ssh无法连接，编译时长30min以上，make参数采用-j𝑛(通常为处理器数目两倍)可以加速。</p><p>以下是另一个博主的详细介绍，可以参考一下，笔者在更新GLIBC时也是参考的这篇blog</p><p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81NTk3OTE0NTA/c3BtPWEyYzZoLjEyODczNjM5LmFydGljbGUtZGV0YWlsLjcuNzEzNzY1ZmFadXZTd2g=">OSError: /lib64/libm.so.6: version `GLIBC_2.27’ not found (required by xxx.so) ——升级GLIBC并解决系统错误 - 知乎 (zhihu.com)<i class="fa fa-external-link-alt"></i></span></p><p>在make过程中通常涉及</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ld-linux-x86-64.so.2\libc.so.6</span><br></pre></td></tr></table></figure><p>两个软连接的更改，在更改时会中断make程序并导致系统异常，需要重新手动连接软连接（如果你make时出错并且系统无法ls的情况下）<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81NTk3OTE0NTA/c3BtPWEyYzZoLjEyODczNjM5LmFydGljbGUtZGV0YWlsLjcuNzEzNzY1ZmFadXZTd2g=">https://zhuanlan.zhihu.com/p/559791450?spm=a2c6h.12873639.article-detail.7.713765faZuvSwh<i class="fa fa-external-link-alt"></i></span>)</p><p>最后记得设置环境变量，切勿随意删除系统gcc文件。</p><blockquote><p> 许多blog在configure中设置—profix=/usr，需要自定义的用户请注意，这样会导致文件混乱。个人常用（/usr/local/soft-name）</p></blockquote><p>安装NodeJS详细步骤建议参考官方：<span class="exturl" data-url="aHR0cHM6Ly9ub2RlanMub3JnL2VuL2Rvd25sb2FkL3BhY2thZ2UtbWFuYWdlcg==">Node.js — Download Node.js® (nodejs.org)<i class="fa fa-external-link-alt"></i></span></p><p>注意前面提到的依赖项，以及官网的curlpost请求不到可能是网络因素</p><h3 id="NodeJS验证"><a href="#NodeJS验证" class="headerlink" title="NodeJS验证"></a>NodeJS验证</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure><p>两条指令均正常即说明程序成功安装</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;NodeJS&quot;&gt;&lt;a href=&quot;#NodeJS&quot; class=&quot;headerlink&quot; title=&quot;NodeJS&quot;&gt;&lt;/a&gt;NodeJS&lt;/h2&gt;&lt;h3 id=&quot;什么是Nodejs&quot;&gt;&lt;a href=&quot;#什么是Nodejs&quot; class=&quot;headerlink&quot; title=&quot;什么是Nodejs&quot;&gt;&lt;/a&gt;什么是Nodejs&lt;/h3&gt;&lt;p&gt;&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly9ub2RlanMub3JnLw==&quot;&gt;Node.js — Run JavaScript Everywhere&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;这是NodeJS的官网标题，很简单的概括，他就是在任何地方都可以运行javascript。&lt;/p&gt;
&lt;p&gt;具体的讲，如下。。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; Node.js 就是运行在服务端的 JavaScript。 Node.js 是一个基于 Chrome JavaScript 运行时建立的一个平台。 Node.js 是一个事件驱动 I/O 服务端 JavaScript 环境，基于 Google 的 V8 引擎，V8 引擎执行 Javascript 的速度非常快，性能非常好。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="软件" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="经典库" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/%E7%BB%8F%E5%85%B8%E5%BA%93/"/>
    
    <category term="前端" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/%E7%BB%8F%E5%85%B8%E5%BA%93/%E5%89%8D%E7%AB%AF/"/>
    
    <category term="node" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/%E7%BB%8F%E5%85%B8%E5%BA%93/%E5%89%8D%E7%AB%AF/node/"/>
    
    
    <category term="nodejs" scheme="https://deepcity.github.io/tags/nodejs/"/>
    
    <category term="gcc" scheme="https://deepcity.github.io/tags/gcc/"/>
    
    <category term="linux" scheme="https://deepcity.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Miracl的配置ForCentos7</title>
    <link href="https://deepcity.github.io/2024/Miracl%E7%9A%84%E9%85%8D%E7%BD%AEForCentos7/article.html"/>
    <id>https://deepcity.github.io/2024/Miracl%E7%9A%84%E9%85%8D%E7%BD%AEForCentos7/article.html</id>
    <published>2024-08-14T11:55:03.000Z</published>
    <updated>2024-08-26T03:16:10.240Z</updated>
    
    <content type="html"><![CDATA[<p>Miracl is Multiprecision Integer and Rational Arithmetic Cryptographic Library – the MIRACL Crypto SDK – is a C software library that is widely regarded by developers as the gold standard open source SDK for elliptic curve cryptography (ECC).</p><p>Miracl 是多精度整数和有理数算术加密库（MIRACL Crypto SDK），是一个 C 软件库，被开发人员广泛视为椭圆曲线加密 (ECC) 的黄金标准开源 SDK。也可在c++环境下通过对c库的</p><span id="more"></span><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span></span><br><span class="line">&#123;</span><br><span class="line">     <span class="meta">#<span class="keyword">include</span> <span class="string">&quot;miracl.h&quot;</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现兼容。</p><p>下面是对miracl在c++环境下部署的简单步骤</p><p>第一步、联网状态下通过该命令获取压缩包，也可离线通过ftp传输</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/miracl/MIRACL/archive/master.zip</span><br></pre></td></tr></table></figure><p>第二步、创建一个文件夹用来存放解压文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir miracl</span><br></pre></td></tr></table></figure><p>第三步、复制并解压</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cp master.zip ./miracl</span><br><span class="line">cd miracl/</span><br><span class="line">unzip -j -aa -L master.zip</span><br></pre></td></tr></table></figure><p>第四步、验证解压并运行linux64（若32位运行linux）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls</span><br><span class="line">bash linux64</span><br><span class="line">ll | grep miracl.a</span><br></pre></td></tr></table></figure><p>第五步、运行官方程序</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./pk-demo</span><br></pre></td></tr></table></figure><p>第六步、一般情况下、复制一下文件到你的源代码目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cp ../miracl/miracl.a miracl.a</span><br><span class="line">cp ../miracl/miracl.h miracl.h</span><br><span class="line">cp ../miracl/mirdef.h mirdef.h</span><br></pre></td></tr></table></figure><p>完成，注意在linux部署十分简单，但在windows环境下按照网络上的教程会爆出各种各样奇怪的错误，读者若要尝试，建议多参考官方文档，准备好比linux环境下部署多耗费许多心神的准备（ps:做好了发个blog）笔者虽然也已经配好了，静态库如下，但在一些程序内还是会报错，个人觉得是静态库制作过程中少了一些源文件并未制作，如下：</p><p><span class="exturl" data-url="aHR0cHM6Ly8xZHJ2Lm1zL2YvcyFBcC1lblk3Y2tMQU5nb05NSVF5c1hSVlM4TGRHeVE=">静态库文件<i class="fa fa-external-link-alt"></i></span></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Miracl is Multiprecision Integer and Rational Arithmetic Cryptographic Library – the MIRACL Crypto SDK – is a C software library that is widely regarded by developers as the gold standard open source SDK for elliptic curve cryptography (ECC).&lt;/p&gt;
&lt;p&gt;Miracl 是多精度整数和有理数算术加密库（MIRACL Crypto SDK），是一个 C 软件库，被开发人员广泛视为椭圆曲线加密 (ECC) 的黄金标准开源 SDK。也可在c++环境下通过对c库的&lt;/p&gt;</summary>
    
    
    
    <category term="软件" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="经典库" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/%E7%BB%8F%E5%85%B8%E5%BA%93/"/>
    
    <category term="信息安全" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/%E7%BB%8F%E5%85%B8%E5%BA%93/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"/>
    
    <category term="Miracl" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/%E7%BB%8F%E5%85%B8%E5%BA%93/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/Miracl/"/>
    
    
    <category term="信息安全" scheme="https://deepcity.github.io/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"/>
    
    <category term="软件" scheme="https://deepcity.github.io/tags/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="Miracl" scheme="https://deepcity.github.io/tags/Miracl/"/>
    
  </entry>
  
  <entry>
    <title>RSA涉及算法与数论知识</title>
    <link href="https://deepcity.github.io/2024/RSA%E6%B6%89%E5%8F%8A%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E8%AE%BA%E7%9F%A5%E8%AF%86/article.html"/>
    <id>https://deepcity.github.io/2024/RSA%E6%B6%89%E5%8F%8A%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E8%AE%BA%E7%9F%A5%E8%AF%86/article.html</id>
    <published>2024-08-14T11:51:58.000Z</published>
    <updated>2024-08-27T08:23:26.277Z</updated>
    
    <content type="html"><![CDATA[<p><strong>RSA</strong> (<strong>Rivest–Shamir–Adleman</strong>) is a <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvUHVibGljLWtleV9jcnlwdG9ncmFwaHk=">public-keycryptosystem<i class="fa fa-external-link-alt"></i></span>, one of the oldest widely used for secure datatransmission.</p><p>RSA（Rivest–Shamir–Adleman）是一种公钥密码系统，是最古老且广泛用于安全数据传输的系统之一。它是一种非对称公钥-私钥密码系统。</p><span id="more"></span><h2 id="基础数论知识纲要">基础数论知识纲要</h2><p>传送门：<span class="exturl" data-url="aHR0cHM6Ly93d3cuc3R1ZG9jdS5jb20vc2cvY291cnNlL25hbnlhbmctdGVjaG5vbG9naWNhbC11bml2ZXJzaXR5L251bWJlci10aGVvcnkvMzAzMTkzNA==">MH3210- NTU - Number Theory - Studocu<i class="fa fa-external-link-alt"></i></span></p><p>知乎blog：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82MzUzMzI2NTg=">基础数论学习笔记（1）-Divisibility 整除 - 知乎 (zhihu.com)<i class="fa fa-external-link-alt"></i></span></p><p>讲义：<span class="exturl" data-url="aHR0cHM6Ly8xZHJ2Lm1zL2YvcyFBcC1lblk3Y2tMQU5nb05Ib3R6cTNTUlRhZnA0cGc=">NanYangTechnological University MH1300ANDMH3210<i class="fa fa-external-link-alt"></i></span></p><h2 id="概念定义">概念定义</h2><p><strong>费马小定理</strong>：选一个<strong>素数p</strong>，再选一个和p不成倍数关系的整数β，必然满足<strong>β的p次幂</strong>和<strong>β</strong>对p同余。公式如下。<span class="math display">\[\beta^p \equiv \beta (modp)\]</span> <strong>二次剩余</strong>： 取定 <spanclass="math display">\[𝑎\perp 𝑝\]</span>, 假若存在着 <spanclass="math inline">\(x\)</span>使得 <span class="math display">\[x^2 \equiv a (modp)\]</span></p><p>则称<span class="math display">\[a\]</span>是<spanclass="math display">\[modp\]</span>的特殊剩余，否则则是<spanclass="math display">\[modp\]</span>的二次非剩余</p><p><strong>欧拉准则</strong>：元素β是<strong>模奇素数p</strong>的平方剩余的充要条件是，β的(p-1)/2次幂和1对p同余。即以下公式<span class="math display">\[\beta ^ {(p-1)/2} \equiv 1 (mod p) | p \equiv 1 (mod2)\]</span></p><blockquote><p>欧拉准则证明： 设<span class="math display">\[r^2 =\beta\]</span>则有 <span class="math display">\[r^{p-1} \equiv 1(modp)\]</span>,利用费马小定理即可得证。</p></blockquote><p><strong>勒让德符号</strong>：<spanclass="math inline">\((\frac{a}{p})\)</span> 若<spanclass="math inline">\(a\)</span> 是<spanclass="math inline">\(modp\)</span>的平方剩余 则 <spanclass="math inline">\((\frac{a}{p}) = 1\)</span> ，若不是，则<spanclass="math inline">\((\frac{a}{p})= -1\)</span>，<spanclass="math inline">\(a\)</span><spanclass="math inline">\(和\)</span><spanclass="math inline">\(p\)</span>是整除关系则<spanclass="math inline">\((\frac{a}{p})=0\)</span> ,如下列公式 <spanclass="math display">\[(\frac{a}{p}) =\begin{cases}1,\quad x^2 \equiv a(modp)\\0, \quad a \equiv 0 (modp) \\-1, \quad x^2 \not\equiv a(modp)\end{cases}\tag{1}\]</span> Solovay-Strassen算法：若n是一个素数，那么勒让德符号<spanclass="math inline">\((\frac{β}{n})\equiv β^{(n-1)/2}modn\)</span>。</p><blockquote><p>Strassen算法证明：根据欧拉准则<strong>β的(n-1)/2次方和1对n不同余</strong>，根据费马小定理，<strong>β的n-1次方</strong>和1对n同余，根据平方差公式，<spanclass="math inline">\(β^{n-1}-1=(β^{(n-1)/2}-1)(β^{(n-1)/2}+1)\)</span>。由于<span class="math inline">\(（β^{(n-1)/2}-1）\)</span>无法被n整除，所以<span class="math inline">\(（β^{(n-1)/2}+1）\)</span>必然能被n整除，进而得到<spanclass="math inline">\(β^{(n-1)/2}\equiv-1  (mod n)\)</span>。</p></blockquote><p><strong>该命题的逆命题是不成立的</strong></p><p><strong>二次互反律</strong>：<span class="math inline">\(\mathbbZ_p^\times\to\mathbb Z_2\)</span></p><p><strong>Miller-Rabin算法</strong>：</p><p>输入待测试大数<span class="math display">\[n\]</span>，对<spanclass="math display">\[n-1\]</span>不断地进行除<spanclass="math display">\[2\]</span>操作，直到得到一个<strong>奇数t</strong>。</p><p>于是这可以写成 <span class="math inline">\(n-1 = 2^s \cdot t\)</span>。显然的，待测试大数<spanclass="math inline">\(n\)</span>肯定是个奇数（废话，是偶数还测个锤子了），那么<spanclass="math display">\[n-1\]</span>肯定是个偶数，故<spanclass="math inline">\(s\not=0\)</span>。</p><p>选择<strong>随机种子<spanclass="math inline">\(a\)</span></strong>，<spanclass="math inline">\(a＜n\)</span>且与<spanclass="math inline">\(n\)</span>互素。（这个也很容易做到，如果随便一下子就测出来不互素，那就不用测了）</p><p>先设<span class="math inline">\(m=t\)</span>。计算 <spanclass="math inline">\(b \equiv a^t(modn)\)</span> ：</p><ul><li><p>情况①：当 <span class="math inline">\(m=2^s \cdot t = n-1\)</span>时，停机，输出“n是一个合数”。</p></li><li><p>情况②：当 <span class="math inline">\(b \equiv -1 (modn)\)</span>时，停机，换一个随机种子<spanclass="math inline">\(a\)</span>再次进行测试。</p></li><li><p>情况③：当<span class="math inline">\(b \equiv-1(modn)\)</span>不成立时，重新设<spanclass="math inline">\(b\)</span>为<span class="math inline">\(b²(modn)\)</span>，<span class="math inline">\(m\)</span>为<spanclass="math inline">\(2m\)</span>​；继续循环，直到得到情况①或情况②为止。</p></li></ul><h2 id="计算方法">计算方法</h2><p><strong>快速幂</strong>：通过二进制的快速幂优化</p><p><strong>计算勒让德符号<spanclass="math inline">\((\frac{\beta}{n})\)</span>​</strong> ：二次互反</p><p><strong>大整数除法中对小除数的优化</strong>：移位计算小除数的商</p><p><strong>大整数除法中对大除数的优化</strong>：二分查找对每次计算试商的优化</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;RSA&lt;/strong&gt; (&lt;strong&gt;Rivest–Shamir–Adleman&lt;/strong&gt;) is a &lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvUHVibGljLWtleV9jcnlwdG9ncmFwaHk=&quot;&gt;public-key
cryptosystem&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;, one of the oldest widely used for secure data
transmission.&lt;/p&gt;
&lt;p&gt;RSA（Rivest–Shamir–Adleman）是一种公钥密码系统，是最古老且广泛用于安全数据传输的系统之一。它是一种非对称公钥-私钥密码系统。&lt;/p&gt;</summary>
    
    
    
    <category term="信息安全" scheme="https://deepcity.github.io/categories/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"/>
    
    <category term="加密算法" scheme="https://deepcity.github.io/categories/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"/>
    
    <category term="数学" scheme="https://deepcity.github.io/categories/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/%E6%95%B0%E5%AD%A6/"/>
    
    
    <category term="信息安全" scheme="https://deepcity.github.io/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"/>
    
    <category term="数学" scheme="https://deepcity.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Latex宏包pgfplots做矩形函数图像</title>
    <link href="https://deepcity.github.io/2024/Latex%E5%AE%8F%E5%8C%85pgfplots%E5%81%9A%E7%9F%A9%E5%BD%A2%E5%87%BD%E6%95%B0%E5%9B%BE%E5%83%8F/article.html"/>
    <id>https://deepcity.github.io/2024/Latex%E5%AE%8F%E5%8C%85pgfplots%E5%81%9A%E7%9F%A9%E5%BD%A2%E5%87%BD%E6%95%B0%E5%9B%BE%E5%83%8F/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-26T03:36:42.995Z</updated>
    
    <content type="html"><![CDATA[<p>持续更新遇到的问题，完结或不再使用该包将删除这句话</p><h2 id="pgfplots"><a href="#pgfplots" class="headerlink" title="pgfplots"></a>pgfplots</h2><p>Pgfplots是一种可视化工具，可简化在文档中包含绘图的过程。基本思想是，用户提供输入数据/公式，然后pgfplots 宏包会帮助用户绘制响应的图像。</p><span id="more"></span><h3 id="实例一、通过函数方程绘制函数图像"><a href="#实例一、通过函数方程绘制函数图像" class="headerlink" title="实例一、通过函数方程绘制函数图像"></a>实例一、通过函数方程绘制函数图像</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%Ex1:f(x)=exp(x)</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;tikzpicture&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;axis&#125;</span><br><span class="line"><span class="keyword">\addplot</span>[color=red]&#123;exp(x)&#125;;</span><br><span class="line"><span class="keyword">\end</span>&#123;axis&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;tikzpicture&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/05/07/iPmhCOxRgzZGYVy.png" alt="test-1-crop-1"></p><p>其中绘制图像的语法如下：</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\addplot</span>[option] &#123;expression of 2D function&#125;;</span><br></pre></td></tr></table></figure><p>在方括号内可以传递一些选项，比如我们可以像Ex1一样，将函数图像的颜色设置为红色。我方括号是必需的，如果没有传递任何选项，则方括号之间留有空白即可。在花括号内，我们要填写的2D 函数的表达式，比如在Ex1中，我们所写的表达式是 exp⁡(𝑥) 。最后最重要的是该命令必须以分号 <strong>;</strong> 结尾。</p><h3 id="实例二、坐标系的绘制以及3d函数图像"><a href="#实例二、坐标系的绘制以及3d函数图像" class="headerlink" title="实例二、坐标系的绘制以及3d函数图像"></a>实例二、坐标系的绘制以及3d函数图像</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\documentclass</span>&#123;ctexart&#125;</span><br><span class="line"><span class="keyword">\pagestyle</span>&#123;empty&#125;</span><br><span class="line"><span class="keyword">\usepackage</span>&#123;pgfplots&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;document&#125;</span><br><span class="line"><span class="comment">%Ex2: put the 2D plot and the 3D plot together</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;tikzpicture&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;axis&#125;</span><br><span class="line"><span class="keyword">\addplot</span>[color=red]&#123;exp(x)&#125;;</span><br><span class="line"><span class="keyword">\end</span>&#123;axis&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;tikzpicture&#125;</span><br><span class="line"><span class="comment">%Here ends the furst 2D plot</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">\hskip</span> 10pt</span><br><span class="line"></span><br><span class="line"><span class="comment">%Here begins the 3d plot</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;tikzpicture&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;axis&#125;</span><br><span class="line"><span class="keyword">\addplot</span>3[</span><br><span class="line">surf,</span><br><span class="line">]</span><br><span class="line">&#123;exp(-x<span class="built_in">^</span>2-y<span class="built_in">^</span>2)*x&#125;;</span><br><span class="line"><span class="keyword">\end</span>&#123;axis&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;tikzpicture&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;document&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/05/07/d7OUNVRI3LWthxK.png" alt="test-1-crop-1"></p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\addplot</span>3[</span><br><span class="line">    surf,</span><br><span class="line">]</span><br><span class="line">&#123;exp(-x<span class="built_in">^</span>2-y<span class="built_in">^</span>2)*x&#125;;</span><br></pre></td></tr></table></figure><p>注意到这里只是将2d图像的命令后面加了一个3，读者可以多修改一下option中的参数，这里的surf指surface，声明这是一个曲面图，并表面着色。</p><p>可以看到对多个图像只需要设定多个tikzpicture作用域即可</p><h4 id="坐标系图像中的常用命令、参数与特性"><a href="#坐标系图像中的常用命令、参数与特性" class="headerlink" title="坐标系图像中的常用命令、参数与特性"></a>坐标系图像中的常用命令、参数与特性</h4><ul><li>xlabel、ylabel：设定x,y坐标轴上的标志。</li><li>多个addplot可在同一个图中多次作图</li><li><script type="math/tex">\tt{domian = a:b}</script>设置 𝑥 的范围为 [𝑎,𝑏] 。即只绘制函数在 𝑥∈[𝑎,𝑏] 之间的图像；</li><li><script type="math/tex">\tt{axis\,\, lines = left}</script>这个命令会仅在图的左侧和底部设置轴，即我们的平面直角坐标系，而不是像我们在图片3中看到的那种默认框；</li><li>\addlegendentry{$function（x)$​} 添加函数标签 </li><li>\legend 按顺序批量谭家函数标签</li><li>title在axis中为图像添加标题</li></ul><h3 id="实例三、数据图"><a href="#实例三、数据图" class="headerlink" title="实例三、数据图"></a>实例三、数据图</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%Ex6:plot from data</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;tikzpicture&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;axis&#125;[</span><br><span class="line">title=&#123;Temperature dependence of CuSO<span class="built_in">$</span><span class="built_in">_</span>4<span class="keyword">\cdot</span><span class="built_in">$</span>5H<span class="built_in">$</span><span class="built_in">_</span>2<span class="built_in">$</span>O solubility&#125;,</span><br><span class="line">xlabel=&#123;Temperature [<span class="keyword">\textcelsius</span>]&#125;,</span><br><span class="line">ylabel=&#123;Solubility [g per 100 g water]&#125;,</span><br><span class="line">xmin=0, xmax=100,</span><br><span class="line">ymin=0, ymax=120,</span><br><span class="line">xtick=&#123;0,20,40,60,80,100&#125;,</span><br><span class="line">ytick=&#123;0,20,40,60,80,100,120&#125;,</span><br><span class="line">legend pos=north west,</span><br><span class="line">ymajorgrids=true,</span><br><span class="line">grid style=dashed,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">\addplot</span>[</span><br><span class="line">color=blue,</span><br><span class="line">mark=square,</span><br><span class="line">]</span><br><span class="line">coordinates &#123;</span><br><span class="line">(0,23.1)</span><br><span class="line">(10,27.5)</span><br><span class="line">(20,32)</span><br><span class="line">(30,37.8)</span><br><span class="line">(40,44.6)</span><br><span class="line">(60,61.8)</span><br><span class="line">(80,83.8)</span><br><span class="line">(100,114)</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">\legend</span>&#123;CuSO<span class="built_in">$</span><span class="built_in">_</span>4<span class="keyword">\cdot</span><span class="built_in">$</span>5H<span class="built_in">$</span><span class="built_in">_</span>2<span class="built_in">$</span>O&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">\end</span>&#123;axis&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;tikzpicture&#125;</span><br></pre></td></tr></table></figure><h4 id="数据图像中的常用命令、参数与特性"><a href="#数据图像中的常用命令、参数与特性" class="headerlink" title="数据图像中的常用命令、参数与特性"></a>数据图像中的常用命令、参数与特性<img src="https://s2.loli.net/2024/05/08/NzwV7TsPHLWjbJB.png" alt="test-1-crop-1"></h4><ul><li>mark：设定图像点的形状；如square、triangle、x等</li><li><script type="math/tex">\tt{ymajorgrids=true/false\,,xmajorgrids=true/false}</script>​启用/禁用 𝑦,𝑥 轴上<strong>刻度线位置上</strong>的网格线；</li><li><script type="math/tex">\tt{xmin=a, xmax=b, ymin=c, ymax=d}</script>​设置 𝑥 的最小值为 𝑎 ，最大值为 𝑏 ；设置 𝑦 的最小值为 𝑐 ，最大值为 𝑑 ；</li><li><script type="math/tex">\tt{coordinates \{\}}</script>​设定坐标点画折线图</li><li>\addplot[option] table {file_with_the_data.dat},使用该命令可直接通过dat数据画图</li></ul><h3 id="其他图像"><a href="#其他图像" class="headerlink" title="其他图像"></a>其他图像</h3><p>pgfplots还支持散点图，直方图，3d图等图像。由于笔者暂时没用到，对这些图不甚了解，就不做阐述了。值得注意的是，在这些图像中使用dat数据格式的数据较多。</p><h3 id="导言区的一些设定"><a href="#导言区的一些设定" class="headerlink" title="导言区的一些设定"></a>导言区的一些设定</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\pgfplotsset</span>&#123;width=10cm&#125;</span><br></pre></td></tr></table></figure><p>这里指定了每一张图的宽度为10cm</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\usepgfplotslibrary</span>&#123;external&#125;</span><br><span class="line"><span class="keyword">\tikzexternalize</span> </span><br></pre></td></tr></table></figure><p>由于<script type="math/tex">LATEX</script> 诞生初期并未考虑使其具备绘图功能，因此当文档中有多个pgfplot图形或它们非常复杂时，渲染它们将花费大量时间。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;持续更新遇到的问题，完结或不再使用该包将删除这句话&lt;/p&gt;
&lt;h2 id=&quot;pgfplots&quot;&gt;&lt;a href=&quot;#pgfplots&quot; class=&quot;headerlink&quot; title=&quot;pgfplots&quot;&gt;&lt;/a&gt;pgfplots&lt;/h2&gt;&lt;p&gt;Pgfplots是一种可视化工具，可简化在文档中包含绘图的过程。基本思想是，用户提供输入数据/公式，然后pgfplots 宏包会帮助用户绘制响应的图像。&lt;/p&gt;</summary>
    
    
    
    <category term="软件" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/"/>
    
    <category term="latex" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/latex/"/>
    
    <category term="package" scheme="https://deepcity.github.io/categories/%E8%BD%AF%E4%BB%B6/latex/package/"/>
    
    
    <category term="Latex" scheme="https://deepcity.github.io/tags/Latex/"/>
    
    <category term="图像处理" scheme="https://deepcity.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>MindSpore专题</title>
    <link href="https://deepcity.github.io/2024/special_subject/MindSpore/MindSpore%E5%AD%A6%E4%B9%A0%E7%9B%AE%E5%BD%95/article.html"/>
    <id>https://deepcity.github.io/2024/special_subject/MindSpore/MindSpore%E5%AD%A6%E4%B9%A0%E7%9B%AE%E5%BD%95/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-17T07:58:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MindSpore-Studying-By-Windows-And-Ubuntu"><a href="#MindSpore-Studying-By-Windows-And-Ubuntu" class="headerlink" title="MindSpore Studying By Windows And Ubuntu"></a>MindSpore Studying By Windows And Ubuntu</h1><p>文档编写采用Typora，须获得更好观看体验请自行clone本仓库</p><h2 id="初级教程"><a href="#初级教程" class="headerlink" title="初级教程"></a>初级教程</h2><p><a href="../Chapters/Concept/article.html">前置数学</a></p><span id="more"></span><p><a href="../Chapters/First_Install/article.html">第一章 Ubuntu以及Windows安装MindSpore</a></p><p><a href="../Chapters/Second_TryMindSpore/article.html">第二章 尝试使用MindSpore</a></p><p><a href="../Chapters/Third_Tensor/article.html">第三章 张量</a></p><p><a href="../Chapters/Fourth_DataSet/article.html">第四章 数据集</a></p><p><a href="../Chapters/Fivth_ConstructNetwork/article.html">第五章 网格构建</a></p><p><a href="../Chapters/Sixth_FunctionAutoDifferentalCalc/article.html">第六章 函数式自动微分</a></p><p><a href="../Chapters/Seven_ModelTrain/article.html">第七章 模型训练</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;MindSpore-Studying-By-Windows-And-Ubuntu&quot;&gt;&lt;a href=&quot;#MindSpore-Studying-By-Windows-And-Ubuntu&quot; class=&quot;headerlink&quot; title=&quot;MindSpore Studying By Windows And Ubuntu&quot;&gt;&lt;/a&gt;MindSpore Studying By Windows And Ubuntu&lt;/h1&gt;&lt;p&gt;文档编写采用Typora，须获得更好观看体验请自行clone本仓库&lt;/p&gt;
&lt;h2 id=&quot;初级教程&quot;&gt;&lt;a href=&quot;#初级教程&quot; class=&quot;headerlink&quot; title=&quot;初级教程&quot;&gt;&lt;/a&gt;初级教程&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;../Chapters/Concept/article.html&quot;&gt;前置数学&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="专题" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/"/>
    
    <category term="机器学习" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Mindspore" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/"/>
    
    <category term="基本概念" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
    
    <category term="机器学习" scheme="https://deepcity.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="MindSpore" scheme="https://deepcity.github.io/tags/MindSpore/"/>
    
    <category term="目录" scheme="https://deepcity.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>MindSpore专题——第〇章、概念</title>
    <link href="https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Concept/article.html"/>
    <id>https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Concept/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-29T11:27:04.971Z</updated>
    
    <content type="html"><![CDATA[<h1 id="初等概念名词解释">初等概念名词解释</h1><p>在接近学完初级的机器学习后，我意识到单纯的看MindSpore文档以及看Youtube视频是远远不够的，我必须系统的学习一些概念知识以避免在后面的学习中云里雾里，故就有了这一章，在这一章中几乎全是对概念的解释，他们的来源广泛，传送门我都会贴在此处，供查阅：</p><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly93d3cucnVhbnlpZmVuZy5jb20vYmxvZy8yMDE3LzA3L25ldXJhbC1uZXR3b3JrLmh0bWw=">神经网络入门- 阮一峰的网络日志 (ruanyifeng.com)<i class="fa fa-external-link-alt"></i></span></p><p>https://github.com/exacity/deeplearningbook-chinese</p></blockquote><span id="more"></span><h2 id="感知机perceptron">感知机（Perceptron）</h2><figure><img src="https://s2.loli.net/2024/06/10/bkVr3Lymea1OAnw.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>​上图的圆圈就代表一个感知器。它接受多个输入（x1，x2，x3...），产生一个输出（output），好比神经末梢感受各种外部环境的变化，最后产生电信号。</p><p>​ 感知机是输出传入参数的一个函数变换，大多数情况下他是(最初涉及) <spanclass="math display">\[output = \sigma(w_1*a_1 +\cdots +w_n*a_n + b)\]</span> 其中<span class="math display">\[\sigma\]</span>​函数表达式如下 <span class="math display">\[σ(z) = 1 / (1 + e^{-z})\]</span></p><h2 id="表示学习representation-learning">表示学习（RepresentationLearning）</h2><p>使用机器学习来发掘表示本身，而不仅仅把表示映射到输出,学习到的表示往往比手动设计的表示表现得更好。并且不需要人工干预就能迅速适应新的任务。</p><h2 id="变差因素">变差因素</h2><p>在此背景下，‘‘因素’’这个词仅指代影响的不同来源；因素通常不是乘性组合。这些因素通常是不能被直接观察到的量。相反，它们可能是现实世界中观察不到的物体或者不可观测的力，但会影响可观测的量。为了对观察到的数据提供有用的简化解释或推断其原因，它们还可能以概念的形式存在于人类的思维中。</p><p>它们可以被看作数据的概念或者抽象，帮助我们了解这些数据的丰富多样性。</p><h2 id="可见层">可见层</h2><p>也就是神经网路的输入层，这样命名的原因是因为它包含我们能观察到的变量。</p><h2 id="隐藏层">隐藏层</h2><p>也就是神经网路的中间层。因为它们的值不在数据中给出，所以将这些层称为‘‘隐藏”;模型必须确定哪些概念有利于解释观察数据中的关系。这里的图像是每个隐藏单元表示的特征的可视化。这里也是分形的思想运用的层次。</p><h2 id="输出层">输出层</h2><p>输出神经网路的判断也称Object Identify</p><h2 id="前馈深度网络">前馈深度网络</h2><h3 id="多层感知机multilayer-perceptron">多层感知机（MultilayerPerceptron）</h3><p>多层感知机仅仅是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成。我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。</p><h2 id="为什么需要使用非线性函数">为什么需要使用非线性函数</h2><p>这是由于线性模型的局限性，一个很经典的例子是，线性模型是无法学习异或函数的。</p><h2 id="分布式表示">分布式表示</h2><p>其思想是：系统的每一个输入都应该由多个特征表示，并且每一个特征都应该参与到多个可能输入的表示。这显然也与神经网络每一层layer与layer之间的dense有关联</p><h2 id="激活函数">激活函数</h2><p>激活函数是神经网络中的一个重要组件，用于对输入信号进行非线性变换，他决定了一个神经元是否被激活，或者说神经元的输出是什么。</p><p>激活函数在数学上表示为一个非线性的函数。下面是一些常见的激活函数</p><h3 id="sigmoid函数">Sigmoid函数</h3><p><span class="math display">\[σ(x) = 1 / (1 + e^{-x})\]</span>输出介于0到1之间，常用于二分类任务，但容易在深层网络中造成梯度消失的问题</p><figure><img src="https://s2.loli.net/2024/08/26/DxICv7oeaSA5hrz.png"alt="Sigmoid" /><figcaption aria-hidden="true">Sigmoid</figcaption></figure><h3 id="tanh函数">Tanh函数</h3><p>输出值在-1到1之间，相对于Sigmoid函数，其输出均值为0，但同样存在梯度消失的问题。</p><p><span class="math display">\[tanh(x) =  (e^x - e^{-x}) / (e^x +e^{-x})\]</span></p><figure><img src="https://s2.loli.net/2024/08/26/fs2bXCkaleBDYQS.png"alt="Tanh" /><figcaption aria-hidden="true">Tanh</figcaption></figure><h3 id="relu-rectified-linear-unit函数">ReLU (Rectified LinearUnit函数)</h3><p>最常见的激活函数之一</p><p>输出非负值，计算简单，能够缓解梯度消失问题，但可能存在“死亡ReLU”现象（即某些神经元在训练过程中永远不被激活）</p><p><span class="math display">\[ReLU(x) = max(0 ,x)\]</span></p><h3 id="leaky-relu函数">Leaky ReLU函数</h3><p>ReLU的改进版本，允许负值以一个小的斜率通过，减少死亡ReLU中的死亡现象。</p><p><span class="math display">\[Leaky\ ReLU(x) = max(\alpha x,x)\]</span></p><p>其中<span class="math inline">\(\alpha\)</span> 是一个较小的常数</p><h3 id="softmax函数">Softmax函数</h3><p>通常用于多分类问题的输出层，将神经元的输出转换为概率分布，输出值的总和为1。</p><p><span class="math display">\[Softmax(x_i) = e^{x_i} / \sume^{x_j}\]</span></p><h2 id="损失函数">损失函数</h2><p>用于量化真实值与预测值之间的差距的函数，它量化了模型预测的错误程度，数值越小表示模型的预测越接近真实值，反之则说明预测误差较大。</p><h3id="回归问题中的损失函数">1<strong>回归问题中的损失函数</strong></h3><ul><li><p>均方误差（Mean Squared Error,MSE）：计算预测值与真实值之间差值的平方和的平均值。MSE是回归问题中最常用的损失函数。</p><ul><li>公式：<span class="math inline">\(MSE = (1/n) * Σ (y_{pred} -y_{true})^2\)</span></li></ul></li><li><p>平均绝对误差（Mean Absolute Error, MAE）</p><p>：计算预测值与真实值之间绝对差值的平均值。</p><ul><li>公式：<span class="math inline">\(MAE = (1/n) * Σ |y_{pred} -y_{true}|\)</span></li></ul></li></ul><h3 id="分类问题中的损失函数">2.<strong>分类问题中的损失函数</strong></h3><ul><li><p>交叉熵损失（Cross-Entropy Loss）</p><p>：用于分类任务，特别是在多分类问题中常用。它衡量模型输出的概率分布与真实分布之间的差异。</p><ul><li><p>对于二分类问题，二元交叉熵损失的公式为：</p><ul><li><p>公式：</p></li><li><p><span class="math display">\[Binary\ Cross-Entropy\ Loss = - (y_{true} * log(y_{pred}) + (1 -y_{true}) * log(1 - y_{pred}))\]</span></p></li></ul></li><li><p>对于多分类问题，使用Softmax和交叉熵损失的组合：</p><ul><li><p>公式：</p></li><li><p><span class="math display">\[Categorical\ Cross-Entropy\ Loss = - \sum y_{true} * log(y_{pred})\]</span></p></li></ul></li></ul></li></ul><h3 id="对比损失hinge-loss">3. <strong>对比损失（HingeLoss）</strong></h3><ul><li>主要用于支持向量机（SVM）等模型，目的是最大化分类边界。HingeLoss通过惩罚错误分类点来优化分类模型。</li><li>公式：<span class="math display">\[Hinge Loss = max(0, 1 - y_{true}* y_{pred})\]</span></li></ul><h3 id="自定义损失函数">4. <strong>自定义损失函数</strong></h3><ul><li>在某些复杂场景中，标准的损失函数可能无法满足需求。此时，研究人员可以根据具体需求定义自适应的损失函数。</li></ul><p>通过最小化损失函数的值，模型可以逐渐提高其在数据上的表现。损失函数的选择应与任务类型及目标密切相关，从而能够准确反映模型性能。</p><h2 id="梯度下降">梯度下降</h2><h2 id="正则化">正则化</h2><h2 id="过拟合">过拟合</h2><h2 id="线性代数">线性代数</h2><h3 id="主对角线">主对角线</h3><p>即满足<span class="math display">\[a =\{a_{i,j}|i=j\}\]</span>的元素构成的线，特殊的<spanclass="math display">\[n\not =m\]</span></p><figure><img src="https://s2.loli.net/2024/06/10/7WA9zDuB2UYrlKF.png"alt="image-20240609143044969" /><figcaption aria-hidden="true">image-20240609143044969</figcaption></figure><h3 id="转置">转置</h3><p>即矩阵对主对角线的镜像，特俗的有<span class="math display">\[n\not =m\]</span></p><figure><img src="https://s2.loli.net/2024/06/10/vtux96qNrkAH8jZ.png"alt="image-20240609143213322" /><figcaption aria-hidden="true">image-20240609143213322</figcaption></figure><h3 id="元素对应乘积hadamard-乘积">元素对应乘积（Hadamard 乘积）</h3><p>记为<span class="math display">\[A\odot B\]</span></p><h3 id="点积">点积</h3><p>两个相同维数的向量x和y的点积（dot product）可看作是矩阵乘积<spanclass="math display">\[A^\topB\]</span>​。我们可以把矩阵乘积C=AB中计算Cij的步骤看作是A的第i行和B的第j列之间的点积。</p><p>矩阵的乘法是不满足交换律的，但是矩阵的点积是满足的。 <spanclass="math display">\[x^\top y = y^\top x\]</span></p><p>矩阵乘积转置的简单形式 <span class="math display">\[(AB)^\top = B^\top A^\top\]</span> 注意顺序是不能更改的因为矩阵乘法不满足交换律</p><h3 id="单位矩阵">单位矩阵</h3><p>单位矩阵指主对角线上的值都为1，其他地方都为零的矩阵。</p><p>我们将保持n维向量不变的单位矩阵记作<spanclass="math display">\[I_n\]</span>。</p><h3 id="逆矩阵">逆矩阵</h3><p>很朴素的定义，需要注意的是由于矩阵乘法不满足交换律，因此我们再说一个矩阵的逆的时候通常是说矩阵的左逆。</p><p>对于方阵而言，它的左逆和右逆是相等的</p><h3 id="线性相关与生成子空间">线性相关与生成子空间</h3><p>如果逆矩阵<spanclass="math display">\[A^{-1}\]</span>​存在。那么式(2.11)肯定对于每一个向量b恰好存在一个解。但是，对于方程组而言，对于向量b的某些值，有可能不存在解，或者存在无限多个解。存在多于一个解但是少于无限多个解的情况是不可能发生的；因为如果x和y都是某方程组的解，则x,y则构成了一个张成空间。</p><p>为了分析方程有多少个解，我们可以将A的列向量看作从原点（origin）（元素都是零的向量）出发的不同方向，确定有多少种方法可以到达向量b。在这个观点下，向量x中的每个元素表示我们应该沿着这些方向走多远，即xi表示我们需要沿着第i个向量的方向走多远：<span class="math display">\[Ax = \sum _i x_i A_{:,i}\]</span>这样的操作我们称为线性组合。形式上，一组向量的线性组合是指每个向量乘以对应标量系数之后的和，即：<span class="math display">\[\sum _i c_i v^{(i)}\]</span>一组向量的生成子空间（span）是原始向量线性组合后所能抵达的点的集合。</p><p>确定Ax=b是否有解相当于确定向量b是否在A列向量的生成子空间中。这个特殊的生成子空间被称为A的列空间（columnspace）或者A的值域（range）。</p><p>为了使方程Ax=b对于任意向量<span class="math display">\[b\in\mathbb{R}^m\]</span>都存在解，我们要求A的列空间构成整个<spanclass="math display">\[\mathbb{R}^m\]</span>。如果<spanclass="math display">\[\mathbb{R}^m\]</span>中的某个点不在A的列空间中，那么该点对应的b会使得该方程没有解。矩阵A的列空间是整个<spanclass="math display">\[\mathbb{R}^m\]</span>的要求，意味着A至少有m列，即n&gt;=m。否则，A列空间的维数会小于m。例如，假设A是一个<spanclass="math display">\[3\times2\]</span>的矩阵。目标b是3维的，但是x只有2维。所以无论如何修改x的值，也只能描绘出<spanclass="math display">\[\mathbb{R}^3\]</span>空间中的二维平面。当且仅当向量b在该二维平面中时，该方程有解。</p><p>不等式n&gt;=m仅是方程对每一点都有解的必要条件。这不是一个充分条件，因为有些列向量可能是冗余的。假设有一个<spanclass="math display">\[\mathbb{R}^{2\times2}\]</span>中的矩阵，它的两个列向量是相同的。那么它的列空间和它的一个列向量作为矩阵的列空间是一样的。换言之，虽然该矩阵有2列，但是它的列空间仍然只是一条线，不能涵盖整个<spanclass="math display">\[\mathbb{R}^2\]</span>空间。</p><p>正式地说，这种冗余被称为线性相关（lineardependence）。如果一组向量中的任意一个向量都不能表示成其他向量的线性组合，那么这组向量称为线性无关（linearlyindependent）。如果某个向量是一组向量中某些向量的线性组合，那么我们将这个向量加入这组向量后不会增加这组向量的生成子空间。这意味着，如果一个矩阵的列空间涵盖整个<spanclass="math display">\[\mathbb{R}^m\]</span>，那么该矩阵必须包含至少一组m个线性无关的向量。这是对于每一个向量b的取值都有解的充分必要条件。值得注意的是，这个条件是说该向量集恰好有m个线性无关的列向量，而不是至少m个。不存在一个m维向量的集合具有多于m个彼此线性不相关的列向量，但是一个有多于m个列向量的矩阵有可能拥有不止一个大小为m的线性无关向量集。</p><p>要想使矩阵可逆，我们还需要保证对于每一个b值至多有一个解。为此，我们需要确保该矩阵至多有m个列向量。否则，该方程会有不止一个解。</p><h3 id="奇异矩阵singular-square">奇异矩阵（singular square）</h3><p>该矩阵必须是一个方阵（square），即m=n，并且所有列向量都是线性无关的。一个列向量线性相关的方阵被称为奇异的（singular）。</p><h3 id="矩阵右乘">矩阵右乘</h3><p><span class="math display">\[AA^{-1}=I\]</span></p><h3 id="范数norm">范数（norm）</h3><p>用来衡量一个向量的大小。机器学习中常用范数衡量向量大小。形式上<spanclass="math display">\[L^p\]</span>定义如下 <spanclass="math display">\[||x||_p = \left( \sum _i |x_i|^p \right) ^{\frac{1}{p}}\]</span> 范数（包括Lp范数）是将向量映射到非负值的函数</p><p>严格的讲，范数是满足以下性质的函数</p><ul><li>f(x) = 0 =&gt; x=0</li><li>f(x+y) &lt;=f(x) + f(y) （三角不等式）</li><li>对<span class="math display">\[\forall \alpha \in\mathbb{R},f(\alpha x) = |\alpha|f(x)\]</span></li></ul><p>当p= 2时，<spanclass="math display">\[L^2\]</span>范数被称为欧几里得范数（Euclideannorm）。它表示从原点出发到向量x确定的点的欧几里得距离。<spanclass="math display">\[L^2\]</span>范数在机器学习中出现地十分频繁，经常简化表示为∥x∥，略去了下标2。平方<spanclass="math display">\[L^2\]</span>范数也经常用来衡量向量的大小，可以简单地通过点积<spanclass="math display">\[x ^\top x\]</span>计算。</p><p>但是在很多情况下，平方<spanclass="math display">\[L^2\]</span>范数也可能不受欢迎，因为它在原点附近增长得十分缓慢。在某些机器学习应用中，区分恰好是零的元素和非零但值很小的元素是很重要的。在这些情况下，我们转而使用在各个位置斜率相同，同时保持简单的数学形式的函数：<spanclass="math display">\[L^1\]</span>范数。<spanclass="math display">\[L^1\]</span>范数可以简化如下： <spanclass="math display">\[||x||_1 = \sum _i |x_i|\]</span>有时候我们会统计向量中非零元素的个数来衡量向量的大小。有些作者将这种函数称为“<spanclass="math display">\[L^0\]</span>范数’’，但是这个术语在数学意义上是不对的</p><p>另外一个经常在机器学习中出现的范数是<spanclass="math display">\[L^\inf\]</span>范数，也被称为最大范数（maxnorm）。这个范数表示向量中具有最大幅值的元素的绝对值：<span class="math display">\[||x||_1 = \max _i |x_i|\]</span>有时候我们可能也希望衡量矩阵的大小。在深度学习中，最常见的做法是使用Frobenius范数（Frobeniusnorm）， <span class="math display">\[||A||_F = \sqrt{\sum _{i,j} A^2_{i,j}}\]</span> 两个向量的点集可以用范数来表示，具体的 <spanclass="math display">\[x^\top y = ||x||_2 ||y||_2 cos\theta\]</span> <spanclass="math display">\[\theta\]</span>表示x,y之间的夹角</p><h3 id="对角矩阵">对角矩阵</h3><p>只在主对角线上含有非零元素，，其他位置都是零。用diag(<spanclass="math display">\[v\]</span>)表示一个对角矩阵。</p><p>计算乘法diag(v)x，我们只需要将x中的每个元素xi放大vi倍。换言之，diag(v)x=v⊙x</p><p>对角方阵的逆矩阵存在，当且仅当对角元素都是非零值，在这种情况下，diag(v)1=diag([1/v1;....;1/vn]⊤)。</p><p>非方阵的对角矩阵没有逆矩阵</p><h3 id="对称矩阵">对称矩阵</h3><p>对称矩阵是矩阵的转置和自己相等的矩阵 <span class="math display">\[A = A ^\top\]</span></p><h3 id="单位矩阵-1">单位矩阵</h3><p>具有单位范数的矩阵</p><p>如果<span class="math display">\[x^\topy=0\]</span>，那么向量x和向量y互相正交（orthogonal）。如果两个向量都有非零范数，那么这两个向量之间的夹角是90度。在Rn中，至多有n个范数非零向量互相正交。如果这些向量不仅互相正交，并且范数都为1，那么我们称它们是标准正交（orthonormal）。</p><p>正交矩阵（orthogonalmatrix）是指行向量和列向量是分别标准正交的方阵，更具体的，他们是满足以下条件的矩阵<span class="math display">\[A^\top A = A ^\top A = I.\]</span> 这样意味着 <span class="math display">\[A^{-1} = A^\top\]</span></p><h3 id="特征分解">特征分解</h3><p>特征分解（eigendecomposition）是使用最广的矩阵分解之一，即我们将矩阵分解成一组特征向量和特征值。</p><p>方阵A的特征向量（eigenvector）是指与A相乘后相当于对该向量进行缩放的非零向量v：<span class="math display">\[A v = \lambda v\]</span> 标量<spanclass="math inline">\(\lambda\)</span>被称为这个特征向量对应的特征值（eigenvalue）。</p><p>（类似地，我们也可以定义左特征向量（left eigenvector）<spanclass="math display">\[v^⊤A=\lambdav^⊤\]</span>，但是通常我们更关注右特征向量（right eigenvector））。</p><p>所有特征值都是正数的矩阵被称为正定（positivedefinite）；所有特征值都是非负数的矩阵被称为半正定（positivesemidefinite）。同样地，所有特征值都是负数的矩阵被称为负定（negativedefinite）；所有特征值都是非正数的矩阵被称为半负定（negativesemidefinite）。</p><p>然而，我们也常常希望将矩阵分解（decompose）成特征值和特征向量。这样可以帮助我们分析矩阵的特定性质，就像质因数分解有助于我们理解整数。</p><p>矩阵A的特征分解可以记作 <span class="math display">\[A = V diag(\lambda) V^{-1}\]</span>不是每一个矩阵都可以分解成特征值和特征向量。在某些情况下，特征分解存在，但是会涉及复数而非实数。</p><p>其中Q是A的特征向量组成的正交矩阵，是对角矩阵。特征值<spanclass="math display">\[\lambda_{i;i}\]</span>对应的特征向量是矩阵Q的第i列，记作Q:;i。因为Q是正交矩阵，我们可以将A看作沿方向v(i)延展i倍的空间</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;初等概念名词解释&quot;&gt;初等概念名词解释&lt;/h1&gt;
&lt;p&gt;在接近学完初级的机器学习后，我意识到单纯的看MindSpore文档以及看Youtube视频是远远不够的，我必须系统的学习一些概念知识以避免在后面的学习中云里雾里，故就有了这一章，在这一章中几乎全是对概念的解释，他们的来源广泛，传送门我都会贴在此处，供查阅：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly93d3cucnVhbnlpZmVuZy5jb20vYmxvZy8yMDE3LzA3L25ldXJhbC1uZXR3b3JrLmh0bWw=&quot;&gt;神经网络入门
- 阮一峰的网络日志 (ruanyifeng.com)&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;https://github.com/exacity/deeplearningbook-chinese&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="专题" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/"/>
    
    <category term="机器学习" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Mindspore" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/"/>
    
    <category term="基本概念" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
    
    <category term="机器学习" scheme="https://deepcity.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="MindSpore" scheme="https://deepcity.github.io/tags/MindSpore/"/>
    
    <category term="目录" scheme="https://deepcity.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>MindSpore专题——第一章、安装</title>
    <link href="https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/First_Install/article.html"/>
    <id>https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/First_Install/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-16T08:58:49.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ubuntu系统安装"><a href="#Ubuntu系统安装" class="headerlink" title="Ubuntu系统安装"></a>Ubuntu系统安装</h2><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><p> VMware Workstation 17Pro</p><ol><li>原有的系统为Ubuntu22.04因此下载Ubuntu18.04 镜像光盘文件<ul><li>通过cat /proc/version文件查看当前的系统版本</li></ul></li></ol><span id="more"></span><p><img src="https://s2.loli.net/2024/06/04/9tNsqxUkrJFHQOc.png" alt="image-20240604174857507"></p><ol><li><p>下载Ubuntu18.04系统光盘<span class="exturl" data-url="aHR0cHM6Ly9yZWxlYXNlcy51YnVudHUuY29tLzE4LjA0L3VidW50dS0xOC4wNC42LWRlc2t0b3AtYW1kNjQuaXNv">https://releases.ubuntu.com/18.04/ubuntu-18.04.6-desktop-amd64.iso<i class="fa fa-external-link-alt"></i></span></p></li><li><p>VMware简易安装后对18旧版本遇到的问题的解决方案</p><ol><li>旧版本屏幕无法适应屏幕，想到vmwaretools的问题，检查该部分发现并未自动安装</li></ol></li></ol><p>通过重新启动挂载\VMware\VMware Workstation目录下linux.iso文件出现</p><p><img src="https://s2.loli.net/2024/06/06/IWioHYeLj9JgMtb.png" alt="image-20240604182654391"></p><p>安装该软件</p><p><img src="https://s2.loli.net/2024/06/04/vIXUHlWVx2sb1co.png" alt="image-20240604182901358"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo perl vmware-install.pl</span><br></pre></td></tr></table></figure><p>通过在解压的目录下运行该脚本文件安装vmware-tools</p><p><img src="https://s2.loli.net/2024/06/04/pJI4WAgKdYmvPES.png" alt="image-20240604183315457"></p><p>在经过一系列configure后安装完成</p><p>由此问题解决</p><pre><code> 2. update apt-get</code></pre><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update apt-get</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/06/04/9cXhEq3V2DMiWNx.png" alt="image-20240604184437693"></p><ol><li>修复vmware剪贴板不共享的问题</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install open-vm-tools-desktop</span><br></pre></td></tr></table></figure><p>​    安装该软件一路回车即可</p><h2 id="尝试自动脚本安装"><a href="#尝试自动脚本安装" class="headerlink" title="尝试自动脚本安装"></a>尝试自动脚本安装</h2><p>由于vmware对nvdia的支持补全，此处采用版本如下</p><p><img src="https://s2.loli.net/2024/06/04/5e3IG9tuAPdfjKr.png" alt="image-20240604183528425"></p><p>进入默认源码目录进行操作</p><p><img src="https://s2.loli.net/2024/06/04/K8tqnFmeQuOMiZc.png" alt="image-20240604183616489"></p><p><img src="https://s2.loli.net/2024/06/04/d1YgnqUjbWJfXLH.png" alt="image-20240604185144770"></p><p>由于系统全新，设定一下系统密码并切换到root用户</p><p><img src="https://s2.loli.net/2024/06/04/KQiWzJtOUsS2mnT.png" alt="image-20240604185341858"></p><p>根据官网下载</p><p><img src="https://s2.loli.net/2024/06/04/g3BCMVGQHDzjAUL.png" alt="image-20240604185417980"></p><p>根据官网命令执行脚本</p><p><img src="https://s2.loli.net/2024/06/05/xBlJgjPwU3krsqa.png" alt="MindSpore安装成功"></p><p>可见安装成功</p><h2 id="Windows中安装MindSpore以及杂项"><a href="#Windows中安装MindSpore以及杂项" class="headerlink" title="Windows中安装MindSpore以及杂项"></a>Windows中安装MindSpore以及杂项</h2><ol><li>相似的安装程序，记得更改选定的官方安装脚本</li><li>Windows一般位于C:\Users\%USERNAME%\pip 目录下存在配置文件，可通过更改该配置文件修改镜像，在使用镜像中启用代理可能会导致满屏的飘红报错</li><li>对于MindSpore的前置软件安装而言，最重要易错的为Python的版本，建议多通过</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python --version</span><br></pre></td></tr></table></figure><ol><li>查看当前版本，及时正确配置环境变量</li></ol>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;Ubuntu系统安装&quot;&gt;&lt;a href=&quot;#Ubuntu系统安装&quot; class=&quot;headerlink&quot; title=&quot;Ubuntu系统安装&quot;&gt;&lt;/a&gt;Ubuntu系统安装&lt;/h2&gt;&lt;h3 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h3&gt;&lt;p&gt; VMware Workstation 17Pro&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;原有的系统为Ubuntu22.04因此下载Ubuntu18.04 镜像光盘文件&lt;ul&gt;
&lt;li&gt;通过cat /proc/version文件查看当前的系统版本&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="专题" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/"/>
    
    <category term="机器学习" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Mindspore" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/"/>
    
    <category term="基本概念" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
    
    <category term="机器学习" scheme="https://deepcity.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="MindSpore" scheme="https://deepcity.github.io/tags/MindSpore/"/>
    
    <category term="目录" scheme="https://deepcity.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>MindSpore专题——第五章、网络构建</title>
    <link href="https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Fivth_ConstructNetwork/article.html"/>
    <id>https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Fivth_ConstructNetwork/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-16T08:58:53.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="网格构建"><a href="#网格构建" class="headerlink" title="网格构建"></a>网格构建</h2><p>神经网络模型是由神经网络层和Tensor操作构成的，<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL21pbmRzcG9yZS5ubi5odG1s">mindspore.nn<i class="fa fa-external-link-alt"></i></span>提供了常见神经网络层的实现，在MindSpore中，<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL25uL21pbmRzcG9yZS5ubi5DZWxsLmh0bWw=">Cell<i class="fa fa-external-link-alt"></i></span>类是构建所有网络的基类，也是网络的基本单元。一个神经网络模型表示为一个<code>Cell</code>，它由不同的子<code>Cell</code>构成。使用这样的嵌套结构，可以简单地使用面向对象编程的思维，对神经网络结构进行构建和管理。</p><p>下面我们将构建一个用于Mnist数据集分类的神经网络模型。</p><span id="more"></span><h3 id="定义模型类"><a href="#定义模型类" class="headerlink" title="定义模型类"></a>定义模型类</h3><p>当我们定义神经网络时，可以继承<code>nn.Cell</code>类，在<code>__init__</code>方法中进行子Cell的实例化和状态管理，在<code>construct</code>方法中实现Tensor操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Network</span>(nn.Cell):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.flatten = nn.Flatten()</span><br><span class="line">        <span class="variable language_">self</span>.dense_relu_sequential = nn.SequentialCell(</span><br><span class="line">            nn.Dense(<span class="number">28</span>*<span class="number">28</span>, <span class="number">512</span>, weight_init=<span class="string">&quot;normal&quot;</span>, bias_init=<span class="string">&quot;zeros&quot;</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dense(<span class="number">512</span>, <span class="number">512</span>, weight_init=<span class="string">&quot;normal&quot;</span>, bias_init=<span class="string">&quot;zeros&quot;</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dense(<span class="number">512</span>, <span class="number">10</span>, weight_init=<span class="string">&quot;normal&quot;</span>, bias_init=<span class="string">&quot;zeros&quot;</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.flatten(x)</span><br><span class="line">        logits = <span class="variable language_">self</span>.dense_relu_sequential(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Network()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Network&lt;</span><br><span class="line">  (flatten): Flatten&lt;&gt;</span><br><span class="line">  (dense_relu_sequential): SequentialCell&lt;</span><br><span class="line">    (0): Dense&lt;input_channels=784, output_channels=512, has_bias=True&gt;</span><br><span class="line">    (1): ReLU&lt;&gt;</span><br><span class="line">    (2): Dense&lt;input_channels=512, output_channels=512, has_bias=True&gt;</span><br><span class="line">    (3): ReLU&lt;&gt;</span><br><span class="line">    (4): Dense&lt;input_channels=512, output_channels=10, has_bias=True&gt;</span><br><span class="line">    &gt;</span><br><span class="line">  &gt;</span><br></pre></td></tr></table></figure></blockquote><p>我们构造一个输入数据，直接调用模型，可以获得一个十维的Tensor输出，其包含每个类别的原始预测值。</p><p><strong><code>model.construct()</code>方法不可直接调用。</strong></p><p>这里出现了很多很抽象的概念好像一下子让机器学习变成了一个黑盒子，实际上，我们观察上面的代码，很容易可以从中看出一些结构来，下面记录一下我这个初学者的理解。</p><p>首先搬出一幅经典的图像</p><p><img src="https://s2.loli.net/2024/06/07/n358NwDPeSg1LsZ.jpg" alt="神经网络入门 - 阮一峰的网络日志"></p><p>这幅图形象的描述了上面的过程。其中</p><p><img src="https://s2.loli.net/2024/06/07/KgVFjZ6LTY54r1s.png" alt="image-20240607140358272"></p><p>这里开始的inputLayer就是我们的输入数据，中间连的密密麻麻的线就是上面结构输出中的Dense，可以观察到我们分别有<script type="math/tex">784\rightarrow 512\rightarrow512\rightarrow10</script>​四层这样的全连接。最初的784也和28*28对应了起来。即我们每一个像素点都是一个参数，为最初输入的一个点，最后输出的则是代表数字概率的10个参数，最终我们会选择一个最接近的参数。这里的变量名用logits（不确定是否标准，但这里是这么用的）</p><p>下面是一些展示调用的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = ops.ones((<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), mindspore.float32)</span><br><span class="line">logits = model(X)</span><br><span class="line"><span class="comment"># print logits</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(Tensor(logits))</span><br><span class="line">pred_probab = nn.Softmax(axis=<span class="number">1</span>)(logits)</span><br><span class="line">y_pred = pred_probab.argmax(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Predicted class: <span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>读者可以试着运行几次，由于给出数据全是1，代表全黑或全白。因此输出是杂乱的。但可以观察到，我们最终的预测值为最大的值的标签。</p><p>下面官网上给出了一些模型层次的解释，来看看。</p><h3 id="模型层"><a href="#模型层" class="headerlink" title="模型层"></a>模型层</h3><blockquote><p> 本节中我们分解上节构造的神经网络模型中的每一层。首先我们构造一个shape为(3, 28, 28)的随机数据（3个28x28的图像），依次通过每一个神经网络层来观察其效果。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input_image = ops.ones((3, 28, 28), mindspore.float32)</span><br><span class="line">print(input_image.shape)</span><br></pre></td></tr></table></figure><blockquote><p>(3, 28, 28)</p></blockquote><h3 id="nn-Flatten"><a href="#nn-Flatten" class="headerlink" title="nn.Flatten"></a>nn.Flatten</h3><blockquote><p> 实例化<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL25uL21pbmRzcG9yZS5ubi5GbGF0dGVuLmh0bWw=">nn.Flatten<i class="fa fa-external-link-alt"></i></span>层，将28x28的2D张量转换为784大小的连续数组。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flatten = nn.Flatten()</span><br><span class="line">flat_image = flatten(input_image)</span><br><span class="line"><span class="built_in">print</span>(flat_image.shape)</span><br></pre></td></tr></table></figure><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(3, 784)</span><br></pre></td></tr></table></figure></blockquote><p>这里可见flatten打平只是打平第一维以外即输入数据样例外的维度，如果说初始数据是一个结构体数组，那Flatten的作用就是将其变为一个一维数组的数组。</p><h3 id="nn-Dense"><a href="#nn-Dense" class="headerlink" title="nn.Dense"></a>nn.Dense</h3><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL25uL21pbmRzcG9yZS5ubi5EZW5zZS5odG1s">nn.Dense<i class="fa fa-external-link-alt"></i></span>为全连接层，其使用权重和偏差对输入进行线性变换。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">layer1 = nn.Dense(in_channels=28*28, out_channels=20)</span><br><span class="line">hidden1 = layer1(flat_image)</span><br><span class="line">print(hidden1.shape)</span><br></pre></td></tr></table></figure><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(3, 20)</span><br></pre></td></tr></table></figure></blockquote><p>这里注意到有两个额外的参数即权重和偏差。也就是说下面每一层的节点就是上一层节点的带权和加上一个常数。</p><h3 id="nn-ReLU"><a href="#nn-ReLU" class="headerlink" title="nn.ReLU"></a>nn.ReLU</h3><blockquote><p> <span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL25uL21pbmRzcG9yZS5ubi5SZUxVLmh0bWw=">nn.ReLU<i class="fa fa-external-link-alt"></i></span>层给网络中加入非线性的激活函数，帮助神经网络学习各种复杂的特征。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Before ReLU: <span class="subst">&#123;hidden1&#125;</span>\n\n&quot;</span>)</span><br><span class="line">hidden1 = nn.ReLU()(hidden1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;After ReLU: <span class="subst">&#123;hidden1&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Before ReLU: [[-0.04736331  0.2939465  -0.02713677 -0.30988005 -0.11504349 -0.11661264</span><br><span class="line">   0.18007928  0.43213072  0.12091967 -0.17465964  0.53133243  0.12605792</span><br><span class="line">   0.01825903  0.01287796  0.17238477 -0.1621131  -0.0080034  -0.24523425</span><br><span class="line">  -0.10083733  0.05171938]</span><br><span class="line"> [-0.04736331  0.2939465  -0.02713677 -0.30988005 -0.11504349 -0.11661264</span><br><span class="line">   0.18007928  0.43213072  0.12091967 -0.17465964  0.53133243  0.12605792</span><br><span class="line">   0.01825903  0.01287796  0.17238477 -0.1621131  -0.0080034  -0.24523425</span><br><span class="line">  -0.10083733  0.05171938]</span><br><span class="line"> [-0.04736331  0.2939465  -0.02713677 -0.30988005 -0.11504349 -0.11661264</span><br><span class="line">   0.18007928  0.43213072  0.12091967 -0.17465964  0.53133243  0.12605792</span><br><span class="line">   0.01825903  0.01287796  0.17238477 -0.1621131  -0.0080034  -0.24523425</span><br><span class="line">  -0.10083733  0.05171938]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">After ReLU: [[0.         0.2939465  0.         0.         0.         0.</span><br><span class="line">  0.18007928 0.43213072 0.12091967 0.         0.53133243 0.12605792</span><br><span class="line">  0.01825903 0.01287796 0.17238477 0.         0.         0.</span><br><span class="line">  0.         0.05171938]</span><br><span class="line"> [0.         0.2939465  0.         0.         0.         0.</span><br><span class="line">  0.18007928 0.43213072 0.12091967 0.         0.53133243 0.12605792</span><br><span class="line">  0.01825903 0.01287796 0.17238477 0.         0.         0.</span><br><span class="line">  0.         0.05171938]</span><br><span class="line"> [0.         0.2939465  0.         0.         0.         0.</span><br><span class="line">  0.18007928 0.43213072 0.12091967 0.         0.53133243 0.12605792</span><br><span class="line">  0.01825903 0.01287796 0.17238477 0.         0.         0.</span><br><span class="line">  0.         0.05171938]]</span><br></pre></td></tr></table></figure></blockquote><p>注意到，这里首次提出非线性运算的概念，也就是说，在这之前，运算都是线性的，这一步显然比较复杂，也不谈论。</p><h3 id="nn-SequentialCell"><a href="#nn-SequentialCell" class="headerlink" title="nn.SequentialCell"></a>nn.SequentialCell</h3><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL25uL21pbmRzcG9yZS5ubi5TZXF1ZW50aWFsQ2VsbC5odG1s">nn.SequentialCell<i class="fa fa-external-link-alt"></i></span>是一个有序的Cell容器。输入Tensor将按照定义的顺序通过所有Cell。我们可以使用<code>SequentialCell</code>来快速组合构造一个神经网络模型。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">seq_modules = nn.SequentialCell(</span><br><span class="line">    flatten,</span><br><span class="line">    layer1,</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Dense(<span class="number">20</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">logits = seq_modules(input_image)</span><br><span class="line"><span class="built_in">print</span>(logits.shape)</span><br></pre></td></tr></table></figure><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(3, 10)</span><br></pre></td></tr></table></figure></blockquote><p>注意看代码，对于这里的代码最好都不要跳过，也不要深究实现原理（新手），可见这里依次调用了上面的所有步骤，是对这一流程的封装。</p><h3 id="nn-Softmax"><a href="#nn-Softmax" class="headerlink" title="nn.Softmax"></a>nn.Softmax</h3><blockquote><p> 最后使用<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL25uL21pbmRzcG9yZS5ubi5Tb2Z0bWF4Lmh0bWw=">nn.Softmax<i class="fa fa-external-link-alt"></i></span>将神经网络最后一个全连接层返回的logits的值缩放为[0, 1]，表示每个类别的预测概率。<code>axis</code>指定的维度数值和为1。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">softmax = nn.Softmax(axis=1)</span><br><span class="line">pred_probab = softmax(logits)</span><br></pre></td></tr></table></figure><p>官网文档已经非常清楚了。还有不懂可以跑跑代码</p><h2 id="模型参数"><a href="#模型参数" class="headerlink" title="模型参数"></a>模型参数</h2><blockquote><p>网络内部神经网络层具有权重参数和偏置参数（如<code>nn.Dense</code>），这些参数会在训练过程中不断进行优化，可通过 <code>model.parameters_and_names()</code> 来获取参数名及对应的参数详情。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Model structure: <span class="subst">&#123;model&#125;</span>\n\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.parameters_and_names():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Layer: <span class="subst">&#123;name&#125;</span>\nSize: <span class="subst">&#123;param.shape&#125;</span>\nValues : <span class="subst">&#123;param[:<span class="number">2</span>]&#125;</span> \n&quot;</span>)</span><br></pre></td></tr></table></figure><p>通过这一代码可以查看权重参数和偏置参数，这一代码应该是十分常见并且常用的。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;网格构建&quot;&gt;&lt;a href=&quot;#网格构建&quot; class=&quot;headerlink&quot; title=&quot;网格构建&quot;&gt;&lt;/a&gt;网格构建&lt;/h2&gt;&lt;p&gt;神经网络模型是由神经网络层和Tensor操作构成的，&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL21pbmRzcG9yZS5ubi5odG1s&quot;&gt;mindspore.nn&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;提供了常见神经网络层的实现，在MindSpore中，&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL25uL21pbmRzcG9yZS5ubi5DZWxsLmh0bWw=&quot;&gt;Cell&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;类是构建所有网络的基类，也是网络的基本单元。一个神经网络模型表示为一个&lt;code&gt;Cell&lt;/code&gt;，它由不同的子&lt;code&gt;Cell&lt;/code&gt;构成。使用这样的嵌套结构，可以简单地使用面向对象编程的思维，对神经网络结构进行构建和管理。&lt;/p&gt;
&lt;p&gt;下面我们将构建一个用于Mnist数据集分类的神经网络模型。&lt;/p&gt;</summary>
    
    
    
    <category term="专题" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/"/>
    
    <category term="机器学习" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Mindspore" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/"/>
    
    <category term="基本概念" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
    
    <category term="机器学习" scheme="https://deepcity.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="MindSpore" scheme="https://deepcity.github.io/tags/MindSpore/"/>
    
    <category term="目录" scheme="https://deepcity.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>MindSpore专题——第四章、数据集</title>
    <link href="https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Fourth_DataSet/article.html"/>
    <id>https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Fourth_DataSet/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-16T08:58:57.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>继续<a href="./Second_TryMindSpore.md">第二章</a>中的Mnist数据库为例，介绍使用mindspore.dataset进行加载的方法。</p><p>详情请见MNIST数据官方网站：<span class="exturl" data-url="aHR0cDovL3lhbm4ubGVjdW4uY29tL2V4ZGIvbW5pc3Qv">MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges<i class="fa fa-external-link-alt"></i></span></p><span id="more"></span><p>下面是简略介绍</p><div class="table-container"><table><thead><tr><th style="text-align:center">数据集</th><th style="text-align:center">MNIST中的文件名</th><th style="text-align:center">下载地址</th><th style="text-align:center">文件大小</th></tr></thead><tbody><tr><td style="text-align:center">训练集图像</td><td style="text-align:center">train-images-idx3-ubyte.gz</td><td style="text-align:center"><span class="exturl" data-url="aHR0cDovL3lhbm4ubGVjdW4uY29tL2V4ZGIvbW5pc3QvdHJhaW4taW1hZ2VzLWlkeDMtdWJ5dGUuZ3o=">http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz<i class="fa fa-external-link-alt"></i></span></td><td style="text-align:center">9912422字节</td></tr><tr><td style="text-align:center">训练集标签</td><td style="text-align:center">train-labels-idx1-ubyte.gz</td><td style="text-align:center"><span class="exturl" data-url="aHR0cDovL3lhbm4ubGVjdW4uY29tL2V4ZGIvbW5pc3QvdHJhaW4tbGFiZWxzLWlkeDEtdWJ5dGUuZ3o=">http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz<i class="fa fa-external-link-alt"></i></span></td><td style="text-align:center">28881字节</td></tr><tr><td style="text-align:center">测试集图像</td><td style="text-align:center">t10k-images-idx3-ubyte.gz</td><td style="text-align:center"><span class="exturl" data-url="aHR0cDovL3lhbm4ubGVjdW4uY29tL2V4ZGIvbW5pc3QvdDEway1pbWFnZXMtaWR4My11Ynl0ZS5neg==">http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz<i class="fa fa-external-link-alt"></i></span></td><td style="text-align:center">1648877字节</td></tr><tr><td style="text-align:center">测试集标签</td><td style="text-align:center">t10k-labels-idx1-ubyte.gz</td><td style="text-align:center"><span class="exturl" data-url="aHR0cDovL3lhbm4ubGVjdW4uY29tL2V4ZGIvbW5pc3QvdDEway1sYWJlbHMtaWR4MS11Ynl0ZS5neg==">http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz<i class="fa fa-external-link-alt"></i></span></td><td style="text-align:center">4542字节</td></tr></tbody></table></div><h3 id="数据库加载"><a href="#数据库加载" class="headerlink" title="数据库加载"></a>数据库加载</h3><p><em>请注意：mindspore.dataset的接口仅支持解压后的数据文件</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = MnistDataset(<span class="string">&quot;MNIST_Data/train&quot;</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(train_dataset))</span><br></pre></td></tr></table></figure><blockquote><class 'mindspore.dataset.engine.datasets_vision.MnistDataset'></blockquote><h3 id="数据库迭代"><a href="#数据库迭代" class="headerlink" title="数据库迭代"></a>数据库迭代</h3><p>数据集加载后，一般以迭代方式获取数据，然后送入神经网络中进行训练。我们可以用<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL2RhdGFzZXQvZGF0YXNldF9tZXRob2QvaXRlcmF0b3IvbWluZHNwb3JlLmRhdGFzZXQuRGF0YXNldC5jcmVhdGVfdHVwbGVfaXRlcmF0b3IuaHRtbA==">create_tuple_iterator<i class="fa fa-external-link-alt"></i></span>或<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL2RhdGFzZXQvZGF0YXNldF9tZXRob2QvaXRlcmF0b3IvbWluZHNwb3JlLmRhdGFzZXQuRGF0YXNldC5jcmVhdGVfZGljdF9pdGVyYXRvci5odG1s">create_dict_iterator<i class="fa fa-external-link-alt"></i></span>接口创建数据迭代器，迭代访问数据。访问的数据类型默认为<code>Tensor</code>；若设置<code>output_numpy=True</code>，访问的数据类型为<code>Numpy</code>。</p><p>下面定义一个可视化函数，迭代9张图片进行展示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">visualize</span>(<span class="params">dataset</span>):</span><br><span class="line">    figure = plt.figure(figsize=(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">    cols, rows = <span class="number">3</span>, <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    plt.subplots_adjust(wspace=<span class="number">0.5</span>, hspace=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx, (image, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataset.create_tuple_iterator()):</span><br><span class="line">        figure.add_subplot(rows, cols, idx + <span class="number">1</span>)</span><br><span class="line">        plt.title(<span class="built_in">int</span>(label))</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">        plt.imshow(image.asnumpy().squeeze(), cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> idx == cols * rows - <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p>在<code>for idx, (image, label) in enumerate(dataset.create_tuple_iterator()):</code>此处的循环中枚举了训练集的前9个图像<code>enumerate()</code>函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p><p>在循环体中使用了plt类画图。</p><p><img src="https://s2.loli.net/2024/06/06/36CU8spH9eSEkxl.png" alt="image-20240606173353887"></p><h3 id="数据集常用操作"><a href="#数据集常用操作" class="headerlink" title="数据集常用操作"></a>数据集常用操作</h3><p>Pipeline的设计理念使得数据集的常用操作采用<code>dataset = dataset.operation()</code>的异步执行方式，执行操作返回新的Dataset，此时不执行具体操作，而是在Pipeline中加入节点，最终进行迭代时，并行执行整个Pipeline。</p><p>下面分别介绍几种常见的数据集操作。</p><h3 id="shuffle"><a href="#shuffle" class="headerlink" title="shuffle"></a>shuffle</h3><p>数据集随机<code>shuffle</code>可以消除数据排列造成的分布不均问题</p><p><img src="https://s2.loli.net/2024/06/06/M54ICySt9dzenva.png" alt="op-shuffle"></p><p><code>mindspore.dataset</code>提供的数据集在加载时可配置<code>shuffle=True</code>，或使用如下操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">64</span>)</span><br><span class="line">visualize(train_dataset)</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/06/06/yB76TmklvtYXIgE.png" alt="image-20240606173414784"></p><h3 id="map"><a href="#map" class="headerlink" title="map"></a>map</h3><p><code>map</code>操作是数据预处理的关键操作，可以针对数据集指定列（column）添加数据变换（Transforms），将数据变换应用于该列数据的每个元素，并返回包含变换后元素的新数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">image, label = <span class="built_in">next</span>(train_dataset.create_tuple_iterator())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;map前：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(image.shape, image.dtype)</span><br><span class="line">train_dataset = train_dataset.<span class="built_in">map</span>(vision.Rescale(<span class="number">1.0</span> / <span class="number">255.0</span>, <span class="number">0</span>), input_columns=<span class="string">&#x27;image&#x27;</span>)</span><br><span class="line">image, label = <span class="built_in">next</span>(train_dataset.create_tuple_iterator())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;map后：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(image.shape, image.dtype)</span><br></pre></td></tr></table></figure><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">map前：</span><br><span class="line">(28, 28, 1) UInt8</span><br><span class="line">map后：</span><br><span class="line">(28, 28, 1) Float32</span><br></pre></td></tr></table></figure></blockquote><h3 id="batch"><a href="#batch" class="headerlink" title="batch"></a>batch</h3><p>将数据集打包为固定大小的<code>batch</code>是在有限硬件资源下使用梯度下降进行模型优化的折中方法，可以保证梯度下降的随机性和优化计算量。分块思想</p><p>一般我们会设置一个固定的batch size，将连续的数据分为若干批（batch）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一般设定固定batchSize</span></span><br><span class="line">train_dataset = train_dataset.batch(batch_size=<span class="number">32</span>)</span><br><span class="line"><span class="comment"># batch后的数据增加一维，大小为batch_size</span></span><br><span class="line">image, label = <span class="built_in">next</span>(train_dataset.create_tuple_iterator())</span><br><span class="line"><span class="built_in">print</span>(image.shape, image.dtype)</span><br></pre></td></tr></table></figure><blockquote><p>(32, 28, 28, 1) Float32</p></blockquote><h3 id="自定义数据集"><a href="#自定义数据集" class="headerlink" title="自定义数据集"></a>自定义数据集</h3><p><code>mindspore.dataset</code>模块提供了一些常用的公开数据集和标准格式数据集的加载API。</p><p>对于MindSpore暂不支持直接加载的数据集，可以构造自定义数据加载类或自定义数据集生成函数的方式来生成数据集，然后通过<code>GeneratorDataset</code>接口实现自定义方式的数据集加载。</p><p><code>GeneratorDataset</code>支持通过可随机访问数据集对象、可迭代数据集对象和生成器(generator)构造自定义数据集，下面分别对其进行介绍。</p><h4 id="可随机访问数据集"><a href="#可随机访问数据集" class="headerlink" title="可随机访问数据集"></a>可随机访问数据集</h4><p>可随机访问数据集是实现了<code>__getitem__</code>和<code>__len__</code>方法的数据集，表示可以通过索引/键直接访问对应位置的数据样本。</p><ol><li>实现了<code>__init__</code>，<code>__getitem__</code> 和<code>__len__</code></li><li>当使用<code>dataset[idx]</code>访问这样的数据集时，可以读取dataset内容中第idx个样本或标签</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Random-accessible object as input source</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RandomAccessDataset</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>._data = np.ones((<span class="number">5</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="variable language_">self</span>._label = np.zeros((<span class="number">5</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._data[index], <span class="variable language_">self</span>._label[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>._data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loader = RandomAccessDataset()</span><br><span class="line">dataset = GeneratorDataset(source=loader, column_names=[<span class="string">&quot;data&quot;</span>, <span class="string">&quot;label&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(data)</span><br><span class="line">    </span><br><span class="line">loader = [np.array(<span class="number">0</span>), np.array(<span class="number">1</span>), np.array(<span class="number">2</span>)]</span><br><span class="line">dataset = GeneratorDataset(source=loader, column_names=[<span class="string">&quot;data&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(data)</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>[Tensor(shape=[2], dtype=Float64, value= [ 1.00000000e+00,  1.00000000e+00]), Tensor(shape=[1], dtype=Float64, value= [ 0.00000000e+00])]<br>[Tensor(shape=[2], dtype=Float64, value= [ 1.00000000e+00,  1.00000000e+00]), Tensor(shape=[1], dtype=Float64, value= [ 0.00000000e+00])]<br>[Tensor(shape=[2], dtype=Float64, value= [ 1.00000000e+00,  1.00000000e+00]), Tensor(shape=[1], dtype=Float64, value= [ 0.00000000e+00])]<br>[Tensor(shape=[2], dtype=Float64, value= [ 1.00000000e+00,  1.00000000e+00]), Tensor(shape=[1], dtype=Float64, value= [ 0.00000000e+00])]<br>[Tensor(shape=[2], dtype=Float64, value= [ 1.00000000e+00,  1.00000000e+00]), Tensor(shape=[1], dtype=Float64, value= [ 0.00000000e+00])]</p></blockquote><p>创建的过程非常简单，通过numpy的数据结构为底层，实现三个方法就好了，更简单的直接使用list，tuple也是可行的。</p><h4 id="可迭代数据集"><a href="#可迭代数据集" class="headerlink" title="可迭代数据集"></a>可迭代数据集</h4><p>可迭代的数据集是实现了<code>__iter__</code>和<code>__next__</code>方法的数据集，表示可以通过迭代的方式逐步获取数据样本。这种类型的数据集特别适用于随机访问成本太高或者不可行的情况。</p><p>例如，当使用<code>iter(dataset)</code>的形式访问数据集时，可以读取从数据库、远程服务器返回的数据流。</p><p>下面构造一个简单迭代器，并将其加载至<code>GeneratorDataset</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Iterator as input source</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IterableDataset</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start, end</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;init the class object to hold the data&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.start = start</span><br><span class="line">        <span class="variable language_">self</span>.end = end</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;iter one data and return&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">next</span>(<span class="variable language_">self</span>.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;reset the iter&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.data = <span class="built_in">iter</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.start, <span class="variable language_">self</span>.end))</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loader = IterableDataset(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">dataset = GeneratorDataset(source=loader, column_names=[<span class="string">&quot;data&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(d)</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>[Tensor(shape=[], dtype=Int32, value= 1)]<br>[Tensor(shape=[], dtype=Int32, value= 2)]<br>[Tensor(shape=[], dtype=Int32, value= 3)]<br>[Tensor(shape=[], dtype=Int32, value= 4)]</p></blockquote><p>同样的，实现方法即可</p><h4 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h4><p>生成器也属于可迭代的数据集类型，其直接依赖Python的生成器类型<code>generator</code>返回数据，直至生成器抛出<code>StopIteration</code>异常。</p><p>下面构造一个生成器，并将其加载至<code>GeneratorDataset</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generator</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_generator</span>(<span class="params">start, end</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start, end):</span><br><span class="line">        <span class="keyword">yield</span> i</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># since a generator instance can be only iterated once, we need to wrap it by lambda to generate multiple instances</span></span><br><span class="line">dataset = GeneratorDataset(source=<span class="keyword">lambda</span>: my_generator(<span class="number">3</span>, <span class="number">6</span>), column_names=[<span class="string">&quot;data&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> dataset:</span><br><span class="line">    <span class="built_in">print</span>(d)</span><br></pre></td></tr></table></figure><blockquote><p>[Tensor(shape=[], dtype=Int32, value= 3)]<br>[Tensor(shape=[], dtype=Int32, value= 4)]<br>[Tensor(shape=[], dtype=Int32, value= 5)]</p></blockquote><p>这个更绝，仅用一个函数即可生成。（此处匿不匿名无关紧要）</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><ol><li>找不到模块 matplotlib</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install matplotlib</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;数据集&quot;&gt;&lt;a href=&quot;#数据集&quot; class=&quot;headerlink&quot; title=&quot;数据集&quot;&gt;&lt;/a&gt;数据集&lt;/h2&gt;&lt;p&gt;继续&lt;a href=&quot;./Second_TryMindSpore.md&quot;&gt;第二章&lt;/a&gt;中的Mnist数据库为例，介绍使用mindspore.dataset进行加载的方法。&lt;/p&gt;
&lt;p&gt;详情请见MNIST数据官方网站：&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cDovL3lhbm4ubGVjdW4uY29tL2V4ZGIvbW5pc3Qv&quot;&gt;MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="专题" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/"/>
    
    <category term="机器学习" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Mindspore" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/"/>
    
    <category term="基本概念" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
    
    <category term="机器学习" scheme="https://deepcity.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="MindSpore" scheme="https://deepcity.github.io/tags/MindSpore/"/>
    
    <category term="目录" scheme="https://deepcity.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>MindSpore专题</title>
    <link href="https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Second_TryMindSpore/article.html"/>
    <id>https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Second_TryMindSpore/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-16T08:59:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL3R1dG9yaWFscy96aC1DTi9yMi4zLjByYzIvYmVnaW5uZXIvcXVpY2tfc3RhcnQuaHRtbA==">MindSpore<i class="fa fa-external-link-alt"></i></span></p><span id="more"></span><h2 id="MindSpore-数据处理"><a href="#MindSpore-数据处理" class="headerlink" title="MindSpore 数据处理"></a>MindSpore 数据处理</h2><h3 id="download"><a href="#download" class="headerlink" title="download"></a>download</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install download</span><br></pre></td></tr></table></figure><p>下载download python模块</p><h3 id="引包并下载所需数据集"><a href="#引包并下载所需数据集" class="headerlink" title="引包并下载所需数据集"></a>引包并下载所需数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mindspore</span><br><span class="line"><span class="keyword">from</span> mindspore <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> mindspore.dataset <span class="keyword">import</span> vision, transforms</span><br><span class="line"><span class="keyword">from</span> mindspore.dataset <span class="keyword">import</span> MnistDataset</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download data from open datasets</span></span><br><span class="line"><span class="keyword">from</span> download <span class="keyword">import</span> download</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/&quot;</span> \</span><br><span class="line">      <span class="string">&quot;notebook/datasets/MNIST_Data.zip&quot;</span></span><br><span class="line">path = download(url, <span class="string">&quot;./&quot;</span>, kind=<span class="string">&quot;zip&quot;</span>, replace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2024/06/05/EuK87I6YUjdAs2v.png" alt="image-20240605204942126"></p><p>下载下来MNIST_Data数据，根据官网这是一份Mnist数据集，结构如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MNIST_Data</span><br><span class="line">└── train</span><br><span class="line">    ├── train-images-idx3-ubyte (60000个训练图片)</span><br><span class="line">    ├── train-labels-idx1-ubyte (60000个训练标签)</span><br><span class="line">└── test</span><br><span class="line">    ├── t10k-images-idx3-ubyte (10000个测试图片)</span><br><span class="line">    ├── t10k-labels-idx1-ubyte (10000个测试标签)</span><br></pre></td></tr></table></figure><h3 id="MindSpore数据处理"><a href="#MindSpore数据处理" class="headerlink" title="MindSpore数据处理"></a>MindSpore数据处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_dataset.get_col_names())</span><br></pre></td></tr></table></figure><p>打印数据集中所包含的数据列名</p><blockquote><p>MindSpore的dataset使用数据处理流水线（Data Processing Pipeline），需指定map、batch、shuffle等操作。这里我们使用map对图像数据及标签进行变换处理，将输入的图像缩放为1/255，根据均值0.1307和标准差值0.3081进行归一化处理，然后将处理好的数据集打包为大小为64的batch。</p></blockquote><p>上面是官网对以下代码的处理。</p><p>其中出现了一个新名词——<a href="#归一化处理">归一化处理</a>，这里使用的是Z-score normalization。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">datapipe</span>(<span class="params">dataset, batch_size</span>):</span><br><span class="line">    image_transforms = [</span><br><span class="line">        vision.Rescale(<span class="number">1.0</span> / <span class="number">255.0</span>, <span class="number">0</span>),</span><br><span class="line">        vision.Normalize(mean=(<span class="number">0.1307</span>,), std=(<span class="number">0.3081</span>,)),</span><br><span class="line">        vision.HWC2CHW()</span><br><span class="line">    ]</span><br><span class="line">    label_transform = transforms.TypeCast(mindspore.int32)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.<span class="built_in">map</span>(image_transforms, <span class="string">&#x27;image&#x27;</span>)</span><br><span class="line">    dataset = dataset.<span class="built_in">map</span>(label_transform, <span class="string">&#x27;label&#x27;</span>)</span><br><span class="line">    dataset = dataset.batch(batch_size)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Map vision transforms and batch dataset</span></span><br><span class="line">train_dataset = datapipe(train_dataset, <span class="number">64</span>)</span><br><span class="line">test_dataset = datapipe(test_dataset, <span class="number">64</span>)</span><br></pre></td></tr></table></figure><hr><p>可使用<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL2RhdGFzZXQvZGF0YXNldF9tZXRob2QvaXRlcmF0b3IvbWluZHNwb3JlLmRhdGFzZXQuRGF0YXNldC5jcmVhdGVfdHVwbGVfaXRlcmF0b3IuaHRtbA==">create_tuple_iterator<i class="fa fa-external-link-alt"></i></span> 或<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL2RhdGFzZXQvZGF0YXNldF9tZXRob2QvaXRlcmF0b3IvbWluZHNwb3JlLmRhdGFzZXQuRGF0YXNldC5jcmVhdGVfZGljdF9pdGVyYXRvci5odG1s">create_dict_iterator<i class="fa fa-external-link-alt"></i></span>对数据集进行迭代访问，查看数据和标签的shape和datatype。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> image, label <span class="keyword">in</span> test_dataset.create_tuple_iterator():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Shape of image [N, C, H, W]: <span class="subst">&#123;image.shape&#125;</span> <span class="subst">&#123;image.dtype&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Shape of label: <span class="subst">&#123;label.shape&#125;</span> <span class="subst">&#123;label.dtype&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><blockquote><p>Shape of image [N, C, H, W]: (64, 1, 28, 28) Float32<br>Shape of label: (64,) Int32</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> test_dataset.create_dict_iterator():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Shape of image [N, C, H, W]: <span class="subst">&#123;data[<span class="string">&#x27;image&#x27;</span>].shape&#125;</span> <span class="subst">&#123;data[<span class="string">&#x27;image&#x27;</span>].dtype&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Shape of label: <span class="subst">&#123;data[<span class="string">&#x27;label&#x27;</span>].shape&#125;</span> <span class="subst">&#123;data[<span class="string">&#x27;label&#x27;</span>].dtype&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><blockquote><p>Shape of image [N, C, H, W]: (64, 1, 28, 28) Float32<br>Shape of label: (64,) Int32</p></blockquote><p>更多细节详见<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL3R1dG9yaWFscy96aC1DTi9yMi4yL2JlZ2lubmVyL2RhdGFzZXQuaHRtbA==">数据集 Dataset<i class="fa fa-external-link-alt"></i></span>与<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL3R1dG9yaWFscy96aC1DTi9yMi4yL2JlZ2lubmVyL3RyYW5zZm9ybXMuaHRtbA==">数据变换 Transforms<i class="fa fa-external-link-alt"></i></span>。</p><h3 id="网络构建"><a href="#网络构建" class="headerlink" title="网络构建"></a>网络构建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Network</span>(nn.Cell):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.flatten = nn.Flatten()</span><br><span class="line">        <span class="variable language_">self</span>.dense_relu_sequential = nn.SequentialCell(</span><br><span class="line">            nn.Dense(<span class="number">28</span>*<span class="number">28</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dense(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dense(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.flatten(x)</span><br><span class="line">        logits = <span class="variable language_">self</span>.dense_relu_sequential(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">model = Network()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure><blockquote><p>Network&lt;<br>  (flatten): Flatten&lt;&gt;<br>  (dense_relu_sequential): SequentialCell&lt;<br>    (0): Dense<input_channels=784, output_channels=512, has_bias=True><br>    (1): ReLU&lt;&gt;<br>    (2): Dense<input_channels=512, output_channels=512, has_bias=True><br>    (3): ReLU&lt;&gt;<br>    (4): Dense<input_channels=512, output_channels=10, has_bias=True><br>    &gt;</p></blockquote><p>以上为网格的构建以及其输出，有以下几点需要注意</p><ol><li>上面重命名过MindSpore中的nn类是构建所有网格的基类，也是网格的基本单元</li><li>当需要自定义网络时可以重写<code>`nn.Cell</code>类重写<code>__init__</code>方法和<code>construct</code>方法</li><li><code>__init__</code>包含所有网络层的定义<code>construct</code>中包含数据（<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL3R1dG9yaWFscy96aC1DTi9yMi4yL2JlZ2lubmVyL3RlbnNvci5odG1s">Tensor<i class="fa fa-external-link-alt"></i></span>）的变换过程</li></ol><blockquote><p><code>mindspore.nn</code>类是构建所有网络的基类，也是网络的基本单元。当用户需要自定义网络时，可以继承<code>nn.Cell</code>类，并重写<code>__init__</code>方法和<code>construct</code>方法。<code>__init__</code>包含所有网络层的定义，<code>construct</code>中包含数据（<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL3R1dG9yaWFscy96aC1DTi9yMi4yL2JlZ2lubmVyL3RlbnNvci5odG1s">Tensor<i class="fa fa-external-link-alt"></i></span>）的变换过程。</p></blockquote><h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>个人菜狗形象的想，实际上这里的网格神经网络对图像的识别类似一种带指向的可变哈希函数（只不过这个函数的实现比较复杂和通用）。他是从大量信息到小量准确抽象的描述过程。下面是<span class="exturl" data-url="aHR0cHM6Ly9vcGVubWxzeXMuZ2l0aHViLmlvL2NoYXB0ZXJfcHJvZ3JhbW1pbmdfaW50ZXJmYWNlL21sX3dvcmtmbG93Lmh0bWw=">3.2. 机器学习工作流 — 机器学习系统：设计和实现 1.0.0 documentation (openmlsys.github.io)<i class="fa fa-external-link-alt"></i></span>手册上的机器学习流程图，这里以求形象的理解</p><p><img src="./../img/img_workflow.svg" alt="img_workflow"></p><blockquote><p>在模型训练中，一个完整的训练过程（step）需要实现以下三步：</p><ol><li><strong>正向计算</strong>：模型预测结果（logits），并与正确标签（label）求预测损失（loss）。</li><li><strong>反向传播</strong>：利用自动微分机制，自动求模型参数（parameters）对于loss的梯度（gradients）。</li><li><strong>参数优化</strong>：将梯度更新到参数上。</li></ol><p>MindSpore使用函数式自动微分机制，因此针对上述步骤需要实现：</p><ol><li>定义正向计算函数。</li><li>使用<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL21pbmRzcG9yZS9taW5kc3BvcmUudmFsdWVfYW5kX2dyYWQuaHRtbA==">value_and_grad<i class="fa fa-external-link-alt"></i></span>通过函数变换获得梯度计算函数。</li><li>定义训练函数，使用<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL25uL21pbmRzcG9yZS5ubi5DZWxsLmh0bWwjbWluZHNwb3JlLm5uLkNlbGwuc2V0X3RyYWlu">set_train<i class="fa fa-external-link-alt"></i></span>设置为训练模式，执行正向计算、反向传播和参数优化。</li></ol></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instantiate loss function and optimizer</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = nn.SGD(model.trainable_params(), <span class="number">1e-2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Define forward function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_fn</span>(<span class="params">data, label</span>):</span><br><span class="line">    logits = model(data)</span><br><span class="line">    loss = loss_fn(logits, label)</span><br><span class="line">    <span class="keyword">return</span> loss, logits</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Get gradient function</span></span><br><span class="line">grad_fn = mindspore.value_and_grad(forward_fn, <span class="literal">None</span>, optimizer.parameters, has_aux=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Define function of one-step training</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">data, label</span>):</span><br><span class="line">    (loss, _), grads = grad_fn(data, label)</span><br><span class="line">    optimizer(grads)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, dataset</span>):</span><br><span class="line">    size = dataset.get_dataset_size()</span><br><span class="line">    model.set_train()</span><br><span class="line">    <span class="keyword">for</span> batch, (data, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataset.create_tuple_iterator()):</span><br><span class="line">        loss = train_step(data, label)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            loss, current = loss.asnumpy(), batch</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;loss: <span class="subst">&#123;loss:&gt;7f&#125;</span>  [<span class="subst">&#123;current:&gt;3d&#125;</span>/<span class="subst">&#123;size:&gt;3d&#125;</span>]&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>除训练外，我们定义测试函数，用来评估模型的性能。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model, dataset, loss_fn</span>):</span><br><span class="line">    num_batches = dataset.get_dataset_size()</span><br><span class="line">    model.set_train(<span class="literal">False</span>)</span><br><span class="line">    total, test_loss, correct = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> dataset.create_tuple_iterator():</span><br><span class="line">        pred = model(data)</span><br><span class="line">        total += <span class="built_in">len</span>(data)</span><br><span class="line">        test_loss += loss_fn(pred, label).asnumpy()</span><br><span class="line">        correct += (pred.argmax(<span class="number">1</span>) == label).asnumpy().<span class="built_in">sum</span>()</span><br><span class="line">    test_loss /= num_batches</span><br><span class="line">    correct /= total</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Test: \n Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.1</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;test_loss:&gt;8f&#125;</span> \n&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>训练过程需多次迭代数据集，一次完整的迭代称为一轮（epoch）。在每一轮，遍历训练集进行训练，结束后使用测试集进行预测。打印每一轮的loss值和预测准确率（Accuracy），可以看到loss在不断下降，Accuracy在不断提高。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;t+<span class="number">1</span>&#125;</span>\n-------------------------------&quot;</span>)</span><br><span class="line">    train(model, train_dataset)</span><br><span class="line">    test(model, test_dataset, loss_fn)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Done!&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&gt;Epoch 1</span><br><span class="line">&gt;-------------------------------</span><br><span class="line">&gt;loss: 2.302088  [  0/938]</span><br><span class="line">&gt;loss: 2.290692  [100/938]</span><br><span class="line">&gt;loss: 2.266338  [200/938]</span><br><span class="line">&gt;loss: 2.205240  [300/938]</span><br><span class="line">&gt;loss: 1.907198  [400/938]</span><br><span class="line">&gt;loss: 1.455603  [500/938]</span><br><span class="line">&gt;loss: 0.861103  [600/938]</span><br><span class="line">&gt;loss: 0.767219  [700/938]</span><br><span class="line">&gt;loss: 0.422253  [800/938]</span><br><span class="line">&gt;loss: 0.513922  [900/938]</span><br><span class="line">&gt;Test:</span><br><span class="line">Accuracy: 83.8%, Avg loss: 0.529534</span><br><span class="line"></span><br><span class="line">&gt;Epoch 2</span><br><span class="line">&gt;-------------------------------</span><br><span class="line">&gt;loss: 0.580867  [  0/938]</span><br><span class="line">&gt;loss: 0.479347  [100/938]</span><br><span class="line">&gt;loss: 0.677991  [200/938]</span><br><span class="line">&gt;loss: 0.550141  [300/938]</span><br><span class="line">&gt;loss: 0.226565  [400/938]</span><br><span class="line">&gt;loss: 0.314738  [500/938]</span><br><span class="line">&gt;loss: 0.298739  [600/938]</span><br><span class="line">&gt;loss: 0.459540  [700/938]</span><br><span class="line">&gt;loss: 0.332978  [800/938]</span><br><span class="line">&gt;loss: 0.406709  [900/938]</span><br><span class="line">&gt;Test:</span><br><span class="line">Accuracy: 90.2%, Avg loss: 0.334828</span><br><span class="line"></span><br><span class="line">&gt;Epoch 3</span><br><span class="line">&gt;-------------------------------</span><br><span class="line">&gt;loss: 0.461890  [  0/938]</span><br><span class="line">&gt;loss: 0.242303  [100/938]</span><br><span class="line">&gt;loss: 0.281414  [200/938]</span><br><span class="line">&gt;loss: 0.207835  [300/938]</span><br><span class="line">&gt;loss: 0.206000  [400/938]</span><br><span class="line">&gt;loss: 0.409646  [500/938]</span><br><span class="line">&gt;loss: 0.193608  [600/938]</span><br><span class="line">&gt;loss: 0.217575  [700/938]</span><br><span class="line">&gt;loss: 0.212817  [800/938]</span><br><span class="line">&gt;loss: 0.202862  [900/938]</span><br><span class="line">&gt;Test:</span><br><span class="line">Accuracy: 91.9%, Avg loss: 0.280962</span><br><span class="line"></span><br><span class="line">&gt;Done!</span><br></pre></td></tr></table></figure><p>训练过程需多次迭代数据集，一次完整的迭代称为一轮（epoch）。在每一轮，遍历训练集进行训练，结束后使用测试集进行预测。打印每一轮的loss值和预测准确率（Accuracy），可以看到loss在不断下降，Accuracy在不断提高。</p></blockquote><h3 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h3><p>模型训练完成后，需要将其参数进行保存。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save checkpoint</span></span><br><span class="line">mindspore.save_checkpoint(model, <span class="string">&quot;model.ckpt&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Saved Model to model.ckpt&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Saved Model to model.ckpt</p></blockquote><h3 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h3><blockquote><p>加载保存的权重分为两步：</p><ol><li>重新实例化模型对象，构造模型。</li><li>加载模型参数，并将其加载至模型上。</li></ol></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instantiate a random initialized model</span></span><br><span class="line">model = Network()</span><br><span class="line"><span class="comment"># Load checkpoint and load parameter to model</span></span><br><span class="line">param_dict = mindspore.load_checkpoint(<span class="string">&quot;model.ckpt&quot;</span>)</span><br><span class="line">param_not_load, _ = mindspore.load_param_into_net(model, param_dict)</span><br><span class="line"><span class="built_in">print</span>(param_not_load)</span><br></pre></td></tr></table></figure><blockquote><p><code>param_not_load未被加载的参数列表，为空时代表所有参数均加载成功。</code></p><p>加载后的模型可以直接用于预测推理。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.set_train(<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">for</span> data, label <span class="keyword">in</span> test_dataset:</span><br><span class="line">    pred = model(data)</span><br><span class="line">    predicted = pred.argmax(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Predicted: &quot;<span class="subst">&#123;predicted[:<span class="number">10</span>]&#125;</span>&quot;, Actual: &quot;<span class="subst">&#123;label[:<span class="number">10</span>]&#125;</span>&quot;&#x27;</span>)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>以上就是一个简单的图像识别机械学习</p><p><strong>注意在加载模型的过程中必须定义模型构建与datapipe</strong></p><h2 id="归一化处理"><a href="#归一化处理" class="headerlink" title="归一化处理"></a>归一化处理</h2><blockquote><p>一些传送门：<br><span class="exturl" data-url="aHR0cHM6Ly9wYWRkbGVwZWRpYS5yZWFkdGhlZG9jcy5pby9lbi9sYXRlc3QvdHV0b3JpYWxzL2RlZXBfbGVhcm5pbmcvbm9ybWFsaXphdGlvbi9iYXNpY19ub3JtYWxpemF0aW9uLmh0bWw=">归一化基础知识点 — PaddleEdu documentation (paddlepedia.readthedocs.io)<i class="fa fa-external-link-alt"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly9nZWVrLWRvY3MuY29tL251bXB5L251bXB5LWFzay1hbnN3ZXIvbm9ybWFsaXplLW51bXB5LWFycmF5X3oxLmh0bWw=">Numpy数组归一化|极客教程 (geek-docs.com)<i class="fa fa-external-link-alt"></i></span></p></blockquote><p>归一化是一种数据处理方式，能将数据经过处理后限制在某个固定范围内。</p><h3 id="归一化处理的两种形式"><a href="#归一化处理的两种形式" class="headerlink" title="归一化处理的两种形式"></a>归一化处理的两种形式</h3><p>归一化存在两种形式</p><ol><li>将数处理为 [0, 1] 之间的小数，其目的是为了在随后的数据处理过程中更便捷，其他情况下，也可将数据处理到 [-1, 1] 之间，或其他的固定范围内。</li></ol><blockquote><p>例如，在图像处理中，就会将图像从 [0, 255] 归一化到 [0, 1]之间，这样既不会改变图像本身的信息储存，又可加速后续的网络处理。</p></blockquote><ol><li>通过归一化将有<a href="#有/无量纲表达式">量纲表达式</a>变成<a href="#有/无量纲表达式">无量纲表达式</a>。</li></ol><h3 id="为什么要进行归一化"><a href="#为什么要进行归一化" class="headerlink" title="为什么要进行归一化"></a>为什么要进行归一化</h3><ol><li>解决数据间的可比性问题</li><li>数据归一化后，寻求最优解的过程会变得平缓，可以更快速的收敛到最优解。<a href="为什么归一化能提高求解最优解的速度">为什么能提高收敛速度</a>.</li></ol><h3 id="归一化类型"><a href="#归一化类型" class="headerlink" title="归一化类型"></a>归一化类型</h3><ol><li>Min-max normalization (Rescaling) 范围为[0,1]:</li></ol><script type="math/tex; mode=display">x^{'} = \frac{x - min(x)}{max(x) - min(x)}</script><ol><li>Mean normalization范围为[-1,1]：</li></ol><script type="math/tex; mode=display">x^{'} = \frac{x - mean(x)}{max(x) - min(x)}</script><blockquote><p>mean(x)：x数据的平均值</p></blockquote><p>​    Min-max归一化和mean归一化适合在最大最小值明确不变的情况下使用，比如图像处理时，灰度值限定在 [0, 255] 的范围内，就可以用min-max归一化将其处理到[0, 1]之间。在最大最小值不明确时，每当有新数据加入，都可能会改变最大或最小值，导致归一化结果不稳定，后续使用效果也不稳定。同时，数据需要相对稳定，如果有过大或过小的异常值存在，min-max归一化和mean归一化的效果也不会很好。如果对处理后的数据范围有严格要求，也应使用min-max归一化或mean归一化。</p><ol><li>Z-score normalization (Standardization)范围为实数集：</li></ol><script type="math/tex; mode=display">x^{'} = \frac{x - \mu}{\sigma}</script><blockquote><p>𝜇、𝜎 分别为样本数据的均值和标准差。</p></blockquote><p>​    Z-score归一化也可称为标准化，经过处理的数据呈均值为0，标准差为1的分布。在数据存在异常值、最大最小值不固定的情况下，可以使用标准化。标准化会改变数据的状态分布，但不会改变分布的种类。特别地，神经网络中经常会使用到z-score归一化，针对这一点，我们将在后续的文章中进行详细的介绍。</p><ol><li>对数归一化：</li></ol><script type="math/tex; mode=display">x^{'} = \frac{\lg x}{\lg max(x)}</script><ol><li>反正切函数归一化：</li></ol><script type="math/tex; mode=display">x^{'} = \arctan(x) * \frac{2}{\pi}</script><ol><li>小数定标标准化（Demical Point Normalization）:</li></ol><script type="math/tex; mode=display">x^{'} = \frac{x}{10^j}</script><p>​    非线性归一化通常被用在数据分化程度较大的场景，有时需要通过一些数学函数对原始值进行映射，如对数、反正切等。</p><h3 id="归一化和标准化的联系与区别"><a href="#归一化和标准化的联系与区别" class="headerlink" title="归一化和标准化的联系与区别"></a>归一化和标准化的联系与区别</h3><p>谈到归一化和标准化可能会存在一些概念的混淆，我们都知道归一化是指normalization，标准化是指standardization，但根据wiki上对feature scaling方法的定义，standardization其实就是z-score normalization，也就是说标准化其实是归一化的一种，而一般情况下，我们会把z-score归一化称为标准化，把min-max归一化简称为归一化。在下文中，我们也是用标准化指代z-score归一化，并使用归一化指代min-max归一化。</p><p>其实，归一化和标准化在本质上都是一种线性变换。在<a href="#归一化类型">归一化类型</a>中，我们提到了归一化和标准化的公式，对于归一化的公式，在数据给定的情况下，可以令𝑎=𝑚𝑎𝑥(𝑥)−𝑚𝑖𝑛(𝑥)、𝑏=𝑚𝑖𝑛(𝑥)，则归一化的公式可变形为：</p><script type="math/tex; mode=display">x^{'} = \frac{x - b}{a} = \frac{x}{a} - \frac{b}{a} = \frac{x}{a} - c</script><p>标准化的公式与变形后的归一化类似，其中的$\mu $和$\sigma$在数据给定的情况下，可以看作常数。因此，标准化的变形与归一化的类似，都可看作对𝑥按比例𝑎进行缩放，再进行𝑐个单位的平移。由此可见，归一化和标准化的本质都是一种线性变换，他们都不会因为对数据的处理而改变数据的原始数值排序。</p><p>那么归一化和标准化又有什么区别呢？</p><ol><li>归一化不会改变数据的状态分布，但标准化会改变数据的状态分布；</li><li>归一化会将数据限定在一个具体的范围内，如 [0, 1]，但标准化不会，标准化只会将数据处理为均值为0，标准差为1。</li></ol><h3 id="为什么归一化能提高求解最优解的速度"><a href="#为什么归一化能提高求解最优解的速度" class="headerlink" title="为什么归一化能提高求解最优解的速度"></a>为什么归一化能提高求解最优解的速度</h3><script type="math/tex; mode=display">\begin{split}\begin{align}y &= \theta_1x_1 + \theta_2x_2 \\J &= (\theta_{1}x_{1} + \theta_{2}x_{2} - y_{label})^2\end{align}\end{split}</script><p>假设自变量只有房子到地铁站的距离<script type="math/tex">𝑥_1</script>和房子内房间的个数<script type="math/tex">𝑥_2</script>，因变量为房价，预测公式和损失函数分别为：</p><script type="math/tex; mode=display">J = (1000\theta_{1}+3\theta_{2} - y_{label})^2</script><p><img src="https://s2.loli.net/2024/06/05/QAonmGKX4FqxUMt.png" alt="normalization"></p><div align="center">图1: 损失函数的等高线，图1（左）为未归一化时，图1（右）为归一化</div><p>​    在图1中，左图的红色椭圆代表归一化前的损失函数等高线，蓝色线段代表梯度的更新，箭头的方向代表梯度更新的方向。寻求最优解的过程就是梯度更新的过程，其更新方向与登高线垂直。由于𝑥1 和 𝑥2 的量级相差过大，损失函数的等高线呈现为一个瘦窄的椭圆。因此如图1（左）所示，瘦窄的椭圆形会使得梯度下降过程呈之字形呈现，导致梯度下降速度缓慢。</p><p>​    当数据经过归一化后，$x<em>{1}^{‘} = \frac{1000-0}{5000-0}=0.2$，$x</em>{2}^{‘} = \frac{3-0}{10-0}=0.3$，那么损失函数的公式可以写为：</p><script type="math/tex; mode=display">J(x) = (0.2\theta_{1} + 0.3\theta_{2} - y_{label})^2</script><p>​    我们可以看到，经过归一化后的数据属于同一量级，损失函数的等高线呈现为一个矮胖的椭圆形（如图1（右）所示），求解最优解过程变得更加迅速且平缓，因此可以在通过梯度下降进行求解时获得更快的收敛。</p><h2 id="有-无量纲表达式"><a href="#有-无量纲表达式" class="headerlink" title="有/无量纲表达式"></a>有/无量纲表达式</h2><p>我们假定数据都是一个个变量（不过提前收集好了）量纲指有些未知数他们是变量存在的一种或几种依赖关系，该变量的值由这些依赖关系的未知数（量纲）决定。</p><blockquote><p> 就像一些函数的y值，理想状态下的房价，他们由x，面积/位置决定。</p></blockquote><p>显然位置差几百米，面积差几百平方米对变量影响差距极大，这种情况下我们称对这些依赖关系式是有量纲的。他们对变量影响的系数存在数量级的不同。</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><ol><li>vscode 出现python解释器的选择错误，这在windows经常有非常多版本的相同软件上经常出现，选定安装MindSpore库的python版本</li></ol><p><img src="https://s2.loli.net/2024/06/05/QSIFMsjBCUAo34y.png" alt="image-20240605210110827"></p><p>​    点击此处python版本即可</p><ol><li><p>注意python的多数语法检查集成已分离为插件，一些在2023.10发布，发布后一些网络上的blog修改linting的将禁用，详情请看<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL21pY3Jvc29mdC92c2NvZGUtcHl0aG9uL3dpa2kvTWlncmF0aW9uLXRvLVB5dGhvbi1Ub29scy1FeHRlbnNpb25z">迁移到 Python 工具扩展 ·microsoft/vscode-python 维基 (github.com)<i class="fa fa-external-link-alt"></i></span></p></li><li><p>解决一些格式上的报错也可以不理会，但根据PEP 8 python规范，一行不能超过80个字符，同时换行需要缩进,如果看不管可以在扩展语法检查中增加args</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--max-line-length=120</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL3R1dG9yaWFscy96aC1DTi9yMi4zLjByYzIvYmVnaW5uZXIvcXVpY2tfc3RhcnQuaHRtbA==&quot;&gt;MindSpore&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="专题" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/"/>
    
    <category term="机器学习" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Mindspore" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/"/>
    
    <category term="基本概念" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
    
    <category term="机器学习" scheme="https://deepcity.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="MindSpore" scheme="https://deepcity.github.io/tags/MindSpore/"/>
    
    <category term="目录" scheme="https://deepcity.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>MindSpore专题——第七章、模型训练</title>
    <link href="https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Seven_ModelTrain/article.html"/>
    <id>https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Seven_ModelTrain/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-16T08:59:02.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>本片涉及大量之前提到概念的定义以及大量引用MindSpore官方文档。原文传送门：</p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL3R1dG9yaWFscy96aC1DTi9yMi4yL2JlZ2lubmVyL3RyYWluLmh0bWw=">MindSpore<i class="fa fa-external-link-alt"></i></span></p><span id="more"></span><h3 id="四个步骤"><a href="#四个步骤" class="headerlink" title="四个步骤"></a>四个步骤</h3><ol><li>构建数据集。</li><li>定义神经网络模型。</li><li>定义超参、损失函数及优化器。</li><li>输入数据集进行训练与评估。</li></ol><p>现在我们有了数据集和模型后，可以进行模型的训练与评估。</p><h3 id="构建数据集"><a href="#构建数据集" class="headerlink" title="构建数据集"></a>构建数据集</h3><p>从dataset加载代码，构建数据集</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def datapipe(path, batch_size):</span><br><span class="line">    image_transforms = [</span><br><span class="line">        vision.Rescale(1.0 / 255.0, 0),</span><br><span class="line">        vision.Normalize(mean=(0.1307,), std=(0.3081,)),</span><br><span class="line">        vision.HWC2CHW()</span><br><span class="line">    ]</span><br><span class="line">    label_transform = transforms.TypeCast(mindspore.int32)</span><br><span class="line"></span><br><span class="line">    dataset = MnistDataset(path)</span><br><span class="line">    dataset = dataset.map(image_transforms, &#x27;image&#x27;)</span><br><span class="line">    dataset = dataset.map(label_transform, &#x27;label&#x27;)</span><br><span class="line">    dataset = dataset.batch(batch_size)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line">train_dataset = datapipe(&#x27;MNIST_Data/train&#x27;, batch_size=64)</span><br><span class="line">test_dataset = datapipe(&#x27;MNIST_Data/test&#x27;, batch_size=64)</span><br></pre></td></tr></table></figure><p><em>class</em>mindspore.dataset.vision.HWC2CHW</p><p>将输入图像的shape从 <H, W, C> 转换为 <C, H, W>。 如果输入图像的shape为 <H, W> ，图像将保持不变。</p><p>异常处理</p><ul><li><strong>RuntimeError</strong> - 如果输入图像的shape不是 <H, W> 或 <H, W, C>。</li></ul><p><em>class</em>mindspore.nn.<strong>ReLU</strong></p><p>逐元素求 max(0,𝑥) 。</p><ul><li><strong>x</strong> (Tensor) - 用于计算<strong>ReLU</strong>的任意维度的Tensor。数据类型为 <span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL21pbmRzcG9yZS9taW5kc3BvcmUuZHR5cGUuaHRtbCNtaW5kc3BvcmUuZHR5cGU=">number<i class="fa fa-external-link-alt"></i></span>。</li></ul><h3 id="定义神经网络模型"><a href="#定义神经网络模型" class="headerlink" title="定义神经网络模型"></a>定义神经网络模型</h3><blockquote><p> 从<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL3R1dG9yaWFscy96aC1DTi9yMi4yL2JlZ2lubmVyL21vZGVsLmh0bWw=">网络构建<i class="fa fa-external-link-alt"></i></span>中加载代码，构建一个神经网络模型。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Network</span>(nn.Cell):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.flatten = nn.Flatten()</span><br><span class="line">        <span class="variable language_">self</span>.dense_relu_sequential = nn.SequentialCell(</span><br><span class="line">            nn.Dense(<span class="number">28</span>*<span class="number">28</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dense(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dense(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.flatten(x)</span><br><span class="line">        logits = <span class="variable language_">self</span>.dense_relu_sequential(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">model = Network()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure><h3 id="定义超参、损失函数和优化器"><a href="#定义超参、损失函数和优化器" class="headerlink" title="定义超参、损失函数和优化器"></a>定义超参、损失函数和优化器</h3><h4 id="超参"><a href="#超参" class="headerlink" title="超参"></a>超参</h4><p>超参（Hyperparameters）是可以调整的参数，可以控制模型训练优化的过程，不同的超参数值可能会影响模型训练和收敛速度。目前深度学习模型多采用批量随机梯度下降算法进行优化，随机梯度下降算法的原理如下：</p><script type="math/tex; mode=display">w_{t+1}=w_{t}-\eta \frac{1}{n} \sum_{x \in \mathcal{B}} \nabla l\left(x, w_{t}\right)</script><p>公式中，𝑛是批量大小（batch size），𝜂是学习率（learning rate）。另外，𝑤𝑡为训练轮次𝑡中的权重参数，∇𝑙为损失函数的导数。除了梯度本身，这两个因子直接决定了模型的权重更新，从优化本身来看，它们是影响模型性能收敛最重要的参数。一般会定义以下超参用于训练：</p><ul><li><strong>训练轮次（epoch）</strong>：训练时遍历数据集的次数。</li><li><strong>批次大小（batch size）</strong>：数据集进行分批读取训练，设定每个批次数据的大小。batch size过小，花费时间多，同时梯度震荡严重，不利于收敛；batch size过大，不同batch的梯度方向没有任何变化，容易陷入局部极小值，因此需要选择合适的batch size，可以有效提高模型精度、全局收敛。</li><li><strong>学习率（learning rate）</strong>：如果学习率偏小，会导致收敛的速度变慢，如果学习率偏大，则可能会导致训练不收敛等不可预测的结果。梯度下降法被广泛应用在最小化模型误差的参数优化算法上。梯度下降法通过多次迭代，并在每一步中最小化损失函数来预估模型的参数。学习率就是在迭代过程中，会控制模型的学习进度。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">3</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br></pre></td></tr></table></figure><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>损失函数（loss function）用于评估模型的预测值（logits）和目标值（targets）之间的误差。训练模型时，随机初始化的神经网络模型开始时会预测出错误的结果。损失函数会评估预测结果与目标值的相异程度，模型训练的目标即为降低损失函数求得的误差。</p><p>常见的损失函数包括用于回归任务的<code>nn.MSELoss</code>（均方误差）和用于分类的<code>nn.NLLLoss</code>（负对数似然）等。 <code>nn.CrossEntropyLoss</code> 结合了<code>nn.LogSoftmax</code>和<code>nn.NLLLoss</code>，可以对logits 进行归一化并计算预测误差。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure><h4 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h4><p>模型优化（Optimization）是在每个训练步骤中调整模型参数以减少模型误差的过程。MindSpore提供多种优化算法的实现，称之为优化器（Optimizer）。优化器内部定义了模型的参数优化过程（即梯度如何更新至模型参数），所有优化逻辑都封装在优化器对象中。在这里，我们使用SGD（Stochastic Gradient Descent）优化器。</p><p>我们通过<code>model.trainable_params()</code>方法获得模型的可训练参数，并传入学习率超参来初始化优化器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = nn.SGD(model.trainable_params(), learning_rate=learning_rate)</span><br></pre></td></tr></table></figure><p><em>class</em>mindspore.experimental.optim.<strong>SGD</strong>(<em>params</em>, <em>lr</em>, <em>momentum=0</em>, <em>dampening=0</em>, <em>weight_decay=0</em>, <em>nesterov=False</em>, <em>**, </em>maximize=False*)</p><p>随机梯度下降算法。</p><script type="math/tex; mode=display">v_{t+1} = u \ast v_{t} + gradient \ast (1-dampening)</script><p>如果nesterov为True：</p><script type="math/tex; mode=display">p_{t+1} = p_{t} - lr \ast (gradient + u \ast v_{t+1})</script><p>如果nesterov为False：</p><script type="math/tex; mode=display">p_{t+1} = p_{t} - lr \ast v_{t+1}</script><p>需要注意的是，对于训练的第一步 𝑣𝑡+1=𝑔𝑟𝑎𝑑𝑖𝑒𝑛𝑡。其中，p、v和u分别表示 parameters、accum 和 momentum。</p><h4 id="训练与评估"><a href="#训练与评估" class="headerlink" title="训练与评估"></a>训练与评估</h4><p>设置了超参、损失函数和优化器后，我们就可以循环输入数据来训练模型。一次数据集的完整迭代循环称为一轮（epoch）。每轮执行训练时包括两个步骤：</p><ol><li>训练：迭代训练数据集，并尝试收敛到最佳参数。</li><li>验证/测试：迭代测试数据集，以检查模型性能是否提升。</li></ol><p>接下来我们定义用于训练的<code>train_loop</code>函数和用于测试的<code>test_loop</code>函数。</p><p>使用函数式自动微分，需先定义正向函数<code>forward_fn</code>，使用<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL21pbmRzcG9yZS9taW5kc3BvcmUudmFsdWVfYW5kX2dyYWQuaHRtbA==">value_and_grad<i class="fa fa-external-link-alt"></i></span>获得微分函数<code>grad_fn</code>。然后，我们将微分函数和优化器的执行封装为<code>train_step</code>函数，接下来循环迭代数据集进行训练即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define forward function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_fn</span>(<span class="params">data, label</span>):</span><br><span class="line">    logits = model(data)</span><br><span class="line">    loss = loss_fn(logits, label)</span><br><span class="line">    <span class="keyword">return</span> loss, logits</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get gradient function</span></span><br><span class="line">grad_fn = mindspore.value_and_grad(forward_fn, <span class="literal">None</span>, optimizer.parameters, has_aux=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define function of one-step training</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">data, label</span>):</span><br><span class="line">    (loss, _), grads = grad_fn(data, label)</span><br><span class="line">    optimizer(grads)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_loop</span>(<span class="params">model, dataset</span>):</span><br><span class="line">    size = dataset.get_dataset_size()</span><br><span class="line">    model.set_train()</span><br><span class="line">    <span class="keyword">for</span> batch, (data, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataset.create_tuple_iterator()):</span><br><span class="line">        loss = train_step(data, label)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            loss, current = loss.asnumpy(), batch</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;loss: <span class="subst">&#123;loss:&gt;7f&#125;</span>  [<span class="subst">&#123;current:&gt;3d&#125;</span>/<span class="subst">&#123;size:&gt;3d&#125;</span>]&quot;</span>)</span><br></pre></td></tr></table></figure><p><code>test_loop</code>函数同样需循环遍历数据集，调用模型计算loss和Accuray并返回最终结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_loop</span>(<span class="params">model, dataset, loss_fn</span>):</span><br><span class="line">    num_batches = dataset.get_dataset_size()</span><br><span class="line">    model.set_train(<span class="literal">False</span>)</span><br><span class="line">    total, test_loss, correct = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> dataset.create_tuple_iterator():</span><br><span class="line">        pred = model(data)</span><br><span class="line">        total += <span class="built_in">len</span>(data)</span><br><span class="line">        test_loss += loss_fn(pred, label).asnumpy()</span><br><span class="line">        correct += (pred.argmax(<span class="number">1</span>) == label).asnumpy().<span class="built_in">sum</span>()</span><br><span class="line">    test_loss /= num_batches</span><br><span class="line">    correct /= total</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Test: \n Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.1</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;test_loss:&gt;8f&#125;</span> \n&quot;</span>)</span><br></pre></td></tr></table></figure><p>我们将实例化的损失函数和优化器传入<code>train_loop</code>和<code>test_loop</code>中。训练3轮并输出loss和Accuracy，查看性能变化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = nn.SGD(model.trainable_params(), learning_rate=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;t+<span class="number">1</span>&#125;</span>\n-------------------------------&quot;</span>)</span><br><span class="line">    train_loop(model, train_dataset)</span><br><span class="line">    test_loop(model, test_dataset, loss_fn)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Done!&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1</span><br><span class="line">-------------------------------</span><br><span class="line">loss: 2.302806  [  0/938]</span><br><span class="line">loss: 2.285086  [100/938]</span><br><span class="line">loss: 2.264712  [200/938]</span><br><span class="line">loss: 2.174010  [300/938]</span><br><span class="line">loss: 1.931853  [400/938]</span><br><span class="line">loss: 1.340721  [500/938]</span><br><span class="line">loss: 0.953515  [600/938]</span><br><span class="line">loss: 0.756860  [700/938]</span><br><span class="line">loss: 0.756263  [800/938]</span><br><span class="line">loss: 0.463846  [900/938]</span><br><span class="line">Test:</span><br><span class="line"> Accuracy: 84.7%, Avg loss: 0.527155</span><br><span class="line"></span><br><span class="line">Epoch 2</span><br><span class="line">-------------------------------</span><br><span class="line">loss: 0.479126  [  0/938]</span><br><span class="line">loss: 0.437443  [100/938]</span><br><span class="line">loss: 0.685504  [200/938]</span><br><span class="line">loss: 0.395121  [300/938]</span><br><span class="line">loss: 0.550566  [400/938]</span><br><span class="line">loss: 0.459457  [500/938]</span><br><span class="line">loss: 0.293049  [600/938]</span><br><span class="line">loss: 0.422102  [700/938]</span><br><span class="line">loss: 0.333153  [800/938]</span><br><span class="line">loss: 0.412182  [900/938]</span><br><span class="line">Test:</span><br><span class="line"> Accuracy: 90.5%, Avg loss: 0.335083</span><br><span class="line"></span><br><span class="line">Epoch 3</span><br><span class="line">-------------------------------</span><br><span class="line">loss: 0.207366  [  0/938]</span><br><span class="line">loss: 0.343559  [100/938]</span><br><span class="line">loss: 0.391145  [200/938]</span><br><span class="line">loss: 0.317566  [300/938]</span><br><span class="line">loss: 0.200746  [400/938]</span><br><span class="line">loss: 0.445798  [500/938]</span><br><span class="line">loss: 0.603720  [600/938]</span><br><span class="line">loss: 0.170811  [700/938]</span><br><span class="line">loss: 0.411954  [800/938]</span><br><span class="line">loss: 0.315902  [900/938]</span><br><span class="line">Test:</span><br><span class="line"> Accuracy: 91.9%, Avg loss: 0.279034</span><br><span class="line"></span><br><span class="line">Done!</span><br></pre></td></tr></table></figure></blockquote><p>读者可以修改参数多跑几边，观察数据的变化，不懂随机梯度下降算法或不懂正向反向传播、学习率乃至超参的概念可以回顾之前文章中提到的视频并重复观看之前的文章，这几个概念应该比较好理解。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;模型训练&quot;&gt;&lt;a href=&quot;#模型训练&quot; class=&quot;headerlink&quot; title=&quot;模型训练&quot;&gt;&lt;/a&gt;模型训练&lt;/h2&gt;&lt;p&gt;本片涉及大量之前提到概念的定义以及大量引用MindSpore官方文档。原文传送门：&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL3R1dG9yaWFscy96aC1DTi9yMi4yL2JlZ2lubmVyL3RyYWluLmh0bWw=&quot;&gt;MindSpore&lt;i class=&quot;fa fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="专题" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/"/>
    
    <category term="机器学习" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Mindspore" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/"/>
    
    <category term="基本概念" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
    
    <category term="机器学习" scheme="https://deepcity.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="MindSpore" scheme="https://deepcity.github.io/tags/MindSpore/"/>
    
    <category term="目录" scheme="https://deepcity.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>MindSpore专题——第六章——函数式微分</title>
    <link href="https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Sixth_FunctionAutoDifferentalCalc/article.html"/>
    <id>https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/Sixth_FunctionAutoDifferentalCalc/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-16T08:59:11.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="函数式自动微分"><a href="#函数式自动微分" class="headerlink" title="函数式自动微分"></a>函数式自动微分</h2><blockquote><p>神经网络的训练主要使用反向传播算法，模型预测值（logits）与正确标签（label）送入损失函数（loss function）获得loss，然后进行反向传播计算，求得梯度（gradients），最终更新至模型参数（parameters）。自动微分能够计算可导函数在某点处的导数值，是反向传播算法的一般化。自动微分主要解决的问题是将一个复杂的数学运算分解为一系列简单的基本运算，该功能对用户屏蔽了大量的求导细节和过程，大大降低了框架的使用门槛。</p></blockquote><span id="more"></span><blockquote><p>MindSpore使用函数式自动微分的设计理念，提供更接近于数学语义的自动微分接口<code>grad</code>和<code>value_and_grad</code>。下面我们使用一个简单的单层线性变换模型进行介绍。</p></blockquote><p>这里总算是提到了反向传播，最近我看到了一系列视频有关Machine Learning，传送门如下：</p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj1JbGczZ0dld1E1VQ==">🔴 World of Warships / USS Des Moines cut (youtube.com)<i class="fa fa-external-link-alt"></i></span></p><p>如果你试图看下去的话，可能会发现，事情好像突然变难了，似乎一群从未见过的知识组合在了一起，神经网络就像一个黑箱连着另一个黑箱，而你根本不知道如何优化它，使得黑箱在给定的输入下输出正确答案</p><h2 id="神经网络到底代表了什么"><a href="#神经网络到底代表了什么" class="headerlink" title="神经网络到底代表了什么"></a>神经网络到底代表了什么</h2><p>首先让我们定义什么是神经：他是一个携带一个浮点数的结构，然后让我们看向神经网络</p><p><img src="https://s2.loli.net/2024/06/07/MLN1Ap2wslU4SQB.jpg" alt="R"></p><p>对于每一个点，我们从最后看起，显然，他们代表0-9，更准确的说，他们代表0-9的图像。为什么这样的网络是生效的呢？</p><p><strong><em>因为分形思想</em></strong>，我们将一段连续的图像区分为一段一段，比如9是⚪在上而线条在下。4由多端线段1组成。而⚪和线条又可以继续再分，我们可以将神经网络中的每一个节点代表的数据想象成这种规律图案的集合。他们之间的传递就是图案在网络中不断组合。这也是为什么在网络中使用全连接的原因，因为每一个图案都能与其他任何图案组合。最终我们使图案变成了不断分形像素的组合。</p><p>但如何做到这一点呢？ 考虑我们前面提到的参数，权值。</p><p><img src="./../../../../../AppData/Roaming/Typora/typora-user-images/image-20240607181215798.png" alt="image-20240607181215798"></p><p>这张图相信有很多人见过类似的图，实际上权值代表的就是神经网络之间的连线，假设我们让正权值在下表中为绿负权值在下表中为红，我们将这样描述一条“线段”：一段由红色包围的长条状绿色区域这样我们就能得出，如果这段线条是成立得话，比如确实原图这里存在一条线段，我们得到的这个神经节点上得值就会很接近1，否则就会很接近零。这就是权值得意义。但同时，我们会注意到神经得值是许多这样计算的累和，因此我们需要一个bias，偏差值将其计算到到0-1。</p><p>注意这里得权值和偏差值均是变量，是训练出来的。并且注意，我们并不知道机器是如何分形得，这取决于学习数据和使用的算法，以上只为举例理解。</p><p>如果将最初得神经网络拿去使用，你只会得到一大堆垃圾数据。我们都知道神经网络存在“进化”过程，但他是如何知道自己错得有多离谱的呢？</p><h2 id="Cost-Function（Maybe-also-loss-function-）"><a href="#Cost-Function（Maybe-also-loss-function-）" class="headerlink" title="Cost Function（Maybe also loss function?）"></a>Cost Function（Maybe also loss function?）</h2><p>初略的定义是他是输出的张量与正确的张量的差值平方和，比如，机器输出了一个全是0.5的10个数的张量，而正确答案是其中之一，那么</p><script type="math/tex; mode=display">\text{Cost} = (1-0.5) + 0.5*9</script><p>显然这个数字更接近0，说明结果更加准确</p><p>考虑如何让模型表现得更好，显然是需要找到一组参数，使得每次输出的cost值最小。我们可以考虑这样一种方式，以参数作为输入，cost的值作为输出，而训练数据则是参数。</p><h3 id="梯度下降-Gradient-Descent"><a href="#梯度下降-Gradient-Descent" class="headerlink" title="梯度下降 (Gradient Descent)"></a>梯度下降 (Gradient Descent)</h3><p>似乎难以理解，假设我们只有一个参数cost=f(c)，c是唯一的参数。于是变为了函数的最值问题，只需要求导数然后慢慢移动我们的初始点。很显然，一个函数在常数域上可能存在多个极大值而只有一个最大值。当我们从一个点出发寻找最大值时，很有可能（概率学上讲应该是绝对）我们只会找到一个极大值。即在神经网络中，我们不能保证我们的参数是最优的，只能保证我们的参数是局部最优的（这取决于我们的起始点）。</p><p>变到多维，我们意识到，一个数的导数是否只有正或负两种信息有效（代表是应该增加这个数还是减少这个数）。假定两个变量在一个点上的导数其中一个是另一个的三倍，这至少说明在该点的邻域内，这一变量应该减少的更多是正确的。（可能有一些函数存在极端的尖点导致错误，但这在神经网络中是低概率的，掌控好更改数据的大小即可）。</p><p>一个简单的例子是，维护好一个<script type="math/tex">\nabla C</script>矩阵，一阶导数对应的值高则其增加，反之则减少。</p><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>从特殊到一般，我们先观察这样一个样例</p><p><img src="https://s2.loli.net/2024/06/07/SJ5Rf7m6cXFs8yN.png" alt="image-20240607205110764"></p><p>显然我们需要增加2，并且如果给我们要做的事情做出一个排序，增加2显然排在减少8之前。</p><p>因此，让我们继续看增加2所涉及的值</p><ol><li>更改偏差值</li><li>更改权值（根据节点值）</li><li>更改上一层节点的值（根据权值）</li></ol><p>我们对权值和边权同时改变，并统计下一层节点需要的变化对上一层的节点影响的累和</p><p>通过多组数据得出权值的总共改变值改变值。这就是随机梯度下降（Stochastic gradient descent）</p><p>下面简单讲一讲其他的名词解释</p><h2 id="Mini-batches"><a href="#Mini-batches" class="headerlink" title="Mini-batches"></a>Mini-batches</h2><p>和他的名字一样，这个技术就是将训练数据分为几组以提高收敛参数的效率</p><h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><p>反向传播是一种梯度下降法的应用，通过链式法则计算损失函数相对于每个权重的梯度，然后利用这些梯度来更新权重。</p><h2 id="函数与计算图"><a href="#函数与计算图" class="headerlink" title="函数与计算图"></a>函数与计算图</h2><p><img src="https://s2.loli.net/2024/06/07/iqHnjI12DSKR6P7.png" alt="compute-graph"></p><blockquote><p>计算图是用图论语言表示数学函数的一种方式，也是深度学习框架表达神经网络模型的统一方法。我们将根据下面的计算图构造计算函数和神经网络。</p><p>在这个模型中，𝑥为输入，𝑦为正确值，𝑤和𝑏是我们需要优化的参数。</p></blockquote><ol><li>𝑥为输入</li><li>𝑦为正确值</li><li>𝑤和𝑏是我们需要优化的参数</li></ol><p>即对应了原始数据，输出结果，权重和偏差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = ops.ones(<span class="number">5</span>, mindspore.float32)  <span class="comment"># input tensor</span></span><br><span class="line">y = ops.zeros(<span class="number">3</span>, mindspore.float32)  <span class="comment"># expected output</span></span><br><span class="line">w = Parameter(Tensor(np.random.randn(<span class="number">5</span>, <span class="number">3</span>), mindspore.float32), name=<span class="string">&#x27;w&#x27;</span>) <span class="comment"># weight</span></span><br><span class="line">b = Parameter(Tensor(np.random.randn(<span class="number">3</span>,), mindspore.float32), name=<span class="string">&#x27;b&#x27;</span>) <span class="comment"># bias</span></span><br></pre></td></tr></table></figure><blockquote><p>我们根据计算图描述的计算过程，构造计算函数。 其中，<span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL29wcy9taW5kc3BvcmUub3BzLmJpbmFyeV9jcm9zc19lbnRyb3B5X3dpdGhfbG9naXRzLmh0bWw=">binary_cross_entropy_with_logits<i class="fa fa-external-link-alt"></i></span> 是一个损失函数，计算预测值和目标值之间的二值交叉熵损失。</p></blockquote><p>解释一下Parameter(): <strong>Parameter</strong> 是 Tensor 的子类，当它们被绑定为Cell的属性时，会自动添加到其参数列表中，并且可以通过Cell的某些方法获取，例如 cell.get_<strong>parameter</strong>s() 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">function</span>(<span class="params">x, y, w, b</span>):</span><br><span class="line">    z = ops.matmul(x, w) + b</span><br><span class="line">    loss = ops.binary_cross_entropy_with_logits(z, y, ops.ones_like(z), ops.ones_like(z))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">loss = function(x, y, w, b)</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br></pre></td></tr></table></figure><p>这里有复杂概念<a href="#二值交叉熵损失"><em>二值交叉熵损失</em></a>，如果你不想深究只需要这是一个对参数的函数，当这个函数值最低时，整体参数就是一个准确率较高的局部最优解即可。</p><h2 id="微分函数与梯度计算"><a href="#微分函数与梯度计算" class="headerlink" title="微分函数与梯度计算"></a>微分函数与梯度计算</h2><blockquote><p> 为了优化模型参数，需要求参数对loss的导数：<script type="math/tex">\frac{𝜕loss}{𝜕𝑤}</script>和<script type="math/tex">\frac{𝜕loss}{𝜕𝑏}</script>，此时我们调用<code>mindspore.grad</code>函数，来获得<code>function</code>的微分函数。</p><p>这里使用了<code>grad</code>函数的两个入参，分别为：</p><ul><li><code>fn</code>：待求导的函数。</li><li><code>grad_position</code>：指定求导输入位置的索引。</li></ul><p>由于我们对<script type="math/tex">𝑤</script>和<script type="math/tex">𝑏</script>​求导，因此配置其在<code>function</code>入参对应的位置<code>(2, 3)</code>。</p><p><em>使用<code>grad</code>获得微分函数是一种函数变换，即输入为函数，输出也为函数。</em></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">grad_fn = mindspore.grad(function, (<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">grads = grad_fn(x, y, w, b)</span><br><span class="line"><span class="built_in">print</span>(grads)</span><br></pre></td></tr></table></figure><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(Tensor(shape=[5, 3], dtype=Float32, value=</span><br><span class="line">[[ 8.17961693e-02,  1.48393542e-01,  6.00685179e-03],</span><br><span class="line"> [ 8.17961693e-02,  1.48393542e-01,  6.00685179e-03],</span><br><span class="line"> [ 8.17961693e-02,  1.48393542e-01,  6.00685179e-03],</span><br><span class="line"> [ 8.17961693e-02,  1.48393542e-01,  6.00685179e-03],</span><br><span class="line"> [ 8.17961693e-02,  1.48393542e-01,  6.00685179e-03]]), Tensor(shape=[3], dtype=Float32, value= [ 8.17961693e-02,  1.48393542e-01,  6.00685179e-03]))</span><br></pre></td></tr></table></figure></blockquote><p>执行微分函数，即可获得<script type="math/tex">𝑤</script>、<script type="math/tex">𝑏</script>​对应的梯度。可以注意到w,b的梯度与最初始的梯度是一致的。</p><h3 id="Stop-Gradient"><a href="#Stop-Gradient" class="headerlink" title="Stop Gradient"></a>Stop Gradient</h3><blockquote><p>通常情况下，求导时会求loss对参数的导数，因此函数的输出只有loss一项。<strong>当我们希望函数输出多项时，微分函数会求所有输出项对参数的导数</strong>。此时如果想实现对某个输出项的梯度截断，或消除某个Tensor对梯度的影响，需要用到Stop Gradient操作。</p><p>这里我们将<code>function</code>改为同时输出loss和z的<code>function_with_logits</code>，获得微分函数并执行。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">function_with_logits</span>(<span class="params">x, y, w, b</span>):</span><br><span class="line">    z = ops.matmul(x, w) + b</span><br><span class="line">    loss = ops.binary_cross_entropy_with_logits(z, y, ops.ones_like(z), ops.ones_like(z))</span><br><span class="line">    <span class="keyword">return</span> loss, z</span><br><span class="line"></span><br><span class="line">grad_fn = mindspore.grad(function_with_logits, (<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">grads = grad_fn(x, y, w, b)</span><br><span class="line"><span class="built_in">print</span>(grads)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">function_stop_gradient</span>(<span class="params">x, y, w, b</span>):</span><br><span class="line">    z = ops.matmul(x, w) + b</span><br><span class="line">    loss = ops.binary_cross_entropy_with_logits(z, y, ops.ones_like(z), ops.ones_like(z))</span><br><span class="line">    <span class="keyword">return</span> loss, ops.stop_gradient(z)</span><br><span class="line"></span><br><span class="line">grad_fn = mindspore.grad(function_stop_gradient, (<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">grads = grad_fn(x, y, w, b)</span><br><span class="line"><span class="built_in">print</span>(grads)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>ops.stop_gradient(z)</code>:重点在该函数，表示屏蔽了z对梯度的影响，即仍只求参数对loss的导数。</p><p>这里解释一下一些api的含义</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mindspore.grad(fn, grad_position=<span class="number">0</span>, weights=<span class="literal">None</span>, has_aux=<span class="literal">False</span>, return_ids=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL21pbmRzcG9yZS9taW5kc3BvcmUuZ3JhZC5odG1sP2hpZ2hsaWdodD1ncmFkI21pbmRzcG9yZS5ncmFk">MindSpore<i class="fa fa-external-link-alt"></i></span></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mindspore.numpy.matmul(x1, x2, dtype=None)</span><br></pre></td></tr></table></figure><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cubWluZHNwb3JlLmNuL2RvY3MvemgtQ04vcjIuMi9hcGlfcHl0aG9uL251bXB5L21pbmRzcG9yZS5udW1weS5tYXRtdWwuaHRtbD9oaWdobGlnaHQ9bWF0bXVsI21pbmRzcG9yZS5udW1weS5tYXRtdWw=">MindSpore<i class="fa fa-external-link-alt"></i></span></li></ul><h3 id="Auxiliary-data"><a href="#Auxiliary-data" class="headerlink" title="Auxiliary data"></a>Auxiliary data</h3><p>Auxiliary data意为辅助数据，是函数除第一个输出项外的其他输出。通常我们会将函数的loss设置为函数的第一个输出，其他的输出即为辅助数据。</p><p><code>grad</code>和<code>value_and_grad</code>提供<code>has_aux</code>参数，当其设置为<code>True</code>时，可以自动实现前文手动添加<code>stop_gradient</code>的功能，满足返回辅助数据的同时不影响梯度计算的效果。</p><p>下面仍使用<code>function_with_logits</code>，配置<code>has_aux=True</code>，并执行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grad_fn = mindspore.grad(function_with_logits, (<span class="number">2</span>, <span class="number">3</span>), has_aux=<span class="literal">True</span>)</span><br><span class="line">grads, (z,) = grad_fn(x, y, w, b)</span><br><span class="line"><span class="built_in">print</span>(grads, z)</span><br></pre></td></tr></table></figure><h3 id="神经网络梯度计算"><a href="#神经网络梯度计算" class="headerlink" title="神经网络梯度计算"></a>神经网络梯度计算</h3><blockquote><p> 前述章节主要根据计算图对应的函数介绍了MindSpore的函数式自动微分，但我们的神经网络构造是继承自面向对象编程范式的<code>nn.Cell</code>。接下来我们通过<code>Cell</code>构造同样的神经网络，利用函数式自动微分来实现反向传播。</p><p>首先我们继承<code>nn.Cell</code>构造单层线性变换神经网络。这里我们直接使用前文的𝑤、𝑏作为模型参数，使用<code>mindspore.Parameter</code>进行包装后，作为内部属性，并在<code>construct</code>内实现相同的Tensor操作。</p></blockquote><p>这里出现了反向传播方法,并且是包装好的,建议读者仔细看一下代码并尝试自己运行一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义神经网络模型</span></span><br><span class="line"><span class="comment"># Define model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Network</span>(nn.Cell):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.w = w</span><br><span class="line">        <span class="variable language_">self</span>.b = b</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">construct</span>(<span class="params">self, x</span>):</span><br><span class="line">        z = ops.matmul(x, <span class="variable language_">self</span>.w) + <span class="variable language_">self</span>.b</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Instantiate model</span></span><br><span class="line">model = Network()</span><br><span class="line"><span class="comment"># Instantiate loss function</span></span><br><span class="line">loss_fn = nn.BCEWithLogitsLoss()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define forward function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_fn</span>(<span class="params">x, y</span>):</span><br><span class="line">    z = model(x)</span><br><span class="line">    loss = loss_fn(z, y)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注入损失函数</span></span><br><span class="line">grad_fn = mindspore.value_and_grad(forward_fn, <span class="literal">None</span>, weights=model.trainable_params())</span><br><span class="line">loss, grads = grad_fn(x, y)</span><br><span class="line"><span class="built_in">print</span>(grads)</span><br></pre></td></tr></table></figure><h3 id="总结输出（单次）"><a href="#总结输出（单次）" class="headerlink" title="总结输出（单次）"></a>总结输出（单次）</h3><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">0.92031693</span><br><span class="line">(Tensor(shape=[5, 3], dtype=Float32, value=</span><br><span class="line">[[ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01]]), Tensor(shape=[3], dtype=Float32, value= [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01]))</span><br><span class="line">计算多个参数的导数</span><br><span class="line">(Tensor(shape=[5, 3], dtype=Float32, value=</span><br><span class="line">[[ 1.23408186e+00,  1.21728730e+00,  1.13000238e+00],</span><br><span class="line"> [ 1.23408186e+00,  1.21728730e+00,  1.13000238e+00],</span><br><span class="line"> [ 1.23408186e+00,  1.21728730e+00,  1.13000238e+00],</span><br><span class="line"> [ 1.23408186e+00,  1.21728730e+00,  1.13000238e+00],</span><br><span class="line"> [ 1.23408186e+00,  1.21728730e+00,  1.13000238e+00]]), Tensor(shape=[3], dtype=Float32, value= [ 1.23408186e+00,  1.21728730e+00,  1.13000238e+00]))</span><br><span class="line">消除部分张量对梯度的影响</span><br><span class="line">(Tensor(shape=[5, 3], dtype=Float32, value=</span><br><span class="line">[[ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01]]), Tensor(shape=[3], dtype=Float32, value= [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01]))</span><br><span class="line">Auxiliary data 辅助数据测试</span><br><span class="line">(Tensor(shape=[5, 3], dtype=Float32, value=</span><br><span class="line">[[ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01]]), Tensor(shape=[3], dtype=Float32, value= [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01])) [ 0.8580145   0.62723386 -0.44728255]      </span><br><span class="line">开始实测网络模型的反向传播</span><br><span class="line">(Tensor(shape=[5, 3], dtype=Float32, value=</span><br><span class="line">[[ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01],</span><br><span class="line"> [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01]]), Tensor(shape=[3], dtype=Float32, value= [ 2.34081909e-01,  2.17287347e-01,  1.30002365e-01]))</span><br></pre></td></tr></table></figure></blockquote><p>可见，除了在计算z的导数对梯度的影响情况下，均保持了相同的输出，并且可以观察到w,b的权值</p><h2 id="二值交叉熵损失"><a href="#二值交叉熵损失" class="headerlink" title="二值交叉熵损失"></a>二值交叉熵损失</h2><p><strong><em>以下的对数均为自然对数</em></strong></p><p>Binary cross entropy 二元<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5Lqk5Y+J54a1">交叉熵<i class="fa fa-external-link-alt"></i></span>是二分类问题中常用的一个Loss损失函数，在常见的机器学习模块中都有实现。就二元交叉熵这个损失函数的原理，简单地进行解释。下面是二元交叉熵损失函数的公式</p><script type="math/tex; mode=display">L=-\frac1N \sum_{i=1}^{N}[y_ilog(p_i)+(1-y_i)log(1-p_i)]</script><p>先不尝试理解他，先看看他是如何运作的</p><p><img src="https://s2.loli.net/2024/06/07/MAOZxqKodRSW6uy.jpg" alt="img"></p><script type="math/tex; mode=display">L=\frac13[(1*log0.8+(1-1)*log(1-0.8))+(0*log0.2+(1-0)*log(1-0.2))+(0*log0.4+(1-0)*log(1-0.4))]=0.319 \\</script><p>对于以上的案例计算损失函数，结果是0.31903</p><h3 id="从熵来看交叉熵损失"><a href="#从熵来看交叉熵损失" class="headerlink" title="从熵来看交叉熵损失"></a>从熵来看交叉熵损失</h3><h4 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a>信息量</h4><p>信息量来衡量一个事件的不确定性，一个事件发生的概率越大，不确定性越小，则其携带的信息量就越小。</p><p>设<script type="math/tex">X</script>是一个离散型随机变量，其取值为集合<script type="math/tex">X = {x_0,x_1,\dots,x_n}</script>，则其概率分布函数为<script type="math/tex">p(x) = Pr(X = x),x \in X</script>，则定义事件<script type="math/tex">X=x_0</script>的信息量为：</p><script type="math/tex; mode=display">I(x_0) = -\log(p(x_0))</script><p>当<script type="math/tex">p(x_0) = 1</script>时，其携带的信息量为0。</p><h4 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h4><p>熵用来衡量一个系统的混乱程度，代表系统中信息量的总和；熵值越大，表明这个系统的不确定性就越大。具体而数学的讲，熵就是一个系统中所有信息量的期望。</p><p>信息量是衡量某个事件的不确定性，而熵是衡量一个系统（所有事件）的不确定性。</p><p>熵的计算公式</p><script type="math/tex; mode=display">H(x) = -\sum_{i=1}^np(x_i)\log(p(x_i))</script><p>比较特殊的有二项分布熵</p><script type="math/tex; mode=display">\begin{eqnarray}H(X)&=&-\sum_{i=1}^n p(x_i)log(p(x_i))\\&=&-p(x)log(p(x))-(1-p(x))log(1-p(x))\end{eqnarray}</script><p><em>熵也有其他类型的计算公式，这里是信息学上的定义</em></p><p>其中<script type="math/tex">p(x)</script>为这件事发生的概率，<script type="math/tex">-log(p(x_i))</script>是事件<script type="math/tex">x_i</script>所携带的信息量。</p><p>可以看出，熵是信息量的期望值，是一个随机变量（一个系统，事件所有可能性）不确定性的度量。熵值越大，随机变量的取值就越难确定，系统也就越不稳定；熵值越小，随机变量的取值也就越容易确定，系统越稳定。</p><h4 id="相对熵-（Relative-entropy）-KL散度"><a href="#相对熵-（Relative-entropy）-KL散度" class="headerlink" title="相对熵 （Relative entropy）/  KL散度"></a>相对熵 （Relative entropy）/  KL散度</h4><p>wiki对相对熵的定义如下：<code>In the context of machine learning, DKL(P‖Q) is often called the information gain achieved if P is used instead of Q.</code></p><p>即如果用P来描述目标问题，而不是用Q来描述目标问题，得到的信息增量。</p><p>在机器学习中，P往往用来表示样本的真实分布，比如[1,0,0]表示当前样本属于第一类。Q用来表示模型所预测的分布，比如[0.7,0.2,0.1]直观的理解就是如果用P来描述样本，那么就非常完美。而用Q来描述样本，虽然可以大致描述，但是不是那么的完美，信息量不足，需要额外的一些“信息增量”才能达到和P一样完美的描述。如果我们的Q通过反复训练，也能完美的描述样本，那么就不再需要额外的“信息增量”，Q等价于P。</p><p>总结：相对熵也称为KL散度(Kullback-Leibler divergence)，表示同一个随机变量的两个不同分布间的距离。</p><p>设 <script type="math/tex">p(x),𝑞(𝑥)</script>分别是 离散随机变量<script type="math/tex">X</script>的两个概率分布，则<script type="math/tex">p</script>对<script type="math/tex">q</script>的相对熵是：</p><script type="math/tex; mode=display">D_{KL}(p \parallel q) = \sum_i p(x_i) log(\frac{p(x_i)}{q(x_i)})</script><p>相对熵具有以下性质：</p><ul><li>如果p(x)和q(x)的分布相同，则其相对熵等于0</li><li><script type="math/tex">D_{KL}(p∥q)≠D_{KL}(q∥p)𝐷_{𝐾𝐿}(𝑝∥𝑞)≠𝐷_{𝐾𝐿}(𝑞∥𝑝)</script>，也就是相对熵不具有对称性。</li><li><script type="math/tex; mode=display">D_{KL}(p∥q)≥0</script></li></ul><p>总的来说，相对熵是用来衡量同一个随机变量的两个不同分布之间的距离。<strong>在实际应用中，假如p(x)是目标真实的分布，而q(x)是预测得来的分布，为了让这两个分布尽可能的相同的，就需要最小化KL散度。</strong></p><h4 id="交叉熵-Cross-Entropy"><a href="#交叉熵-Cross-Entropy" class="headerlink" title="交叉熵 Cross Entropy"></a>交叉熵 Cross Entropy</h4><p>设<script type="math/tex">p(x),q(x)</script>分别是 离散随机变量<script type="math/tex">X</script>的两个概率分布，其中<script type="math/tex">p(x)</script>是目标分布，<script type="math/tex">p</script>和<script type="math/tex">q</script>的交叉熵可以看做是，使用分布<script type="math/tex">q(x)</script>表示目标分布<script type="math/tex">p(x)</script>的困难程度</p><script type="math/tex; mode=display">H(p,q) = \sum_ip(x_i)log\frac{1}{\log q(x_i)} = -\sum_ip(x_i)\log q(x_i)</script><p>将熵、相对熵以及交叉熵的公式放到一起，</p><script type="math/tex; mode=display">\begin{align}H(p) &= -\sum_{i}p(x_i) \log p(x_i) \\D_{KL}(p \parallel q) &= \sum_{i}p(x_i)\log \frac{p(x_i)}{q(x_i)} = \sum_i (p(x_i)\log p(x_i) - p(x_i) \log q(x_i)) \\H(p,q) &=  -\sum_ip(x_i)\log q(x_i)\end{align}</script><p>通过上面三个公式就可以得到</p><script type="math/tex; mode=display">D_{KL}(p,q) = H(p,q)- H(p)</script><p>其中，前一项<script type="math/tex">H(p,q)</script>就是<script type="math/tex">p,q</script>的交叉熵。在机器学习中，目标的分布<script type="math/tex">p(x)</script>通常是训练数据的分布是固定，即是<script type="math/tex">H(p)</script>是一个常量。这样两个分布的交叉熵<script type="math/tex">H(p,q)</script>也就等价于最小化这两个分布的相对熵<script type="math/tex">D_{KL}(p \parallel q)</script></p><p>设<script type="math/tex">p(x)</script>是目标分布（训练数据的分布），我们的目标的就让训练得到的分布<script type="math/tex">q(x)</script>尽可能的接近<script type="math/tex">p(x)</script>，这时候就可以最小化<script type="math/tex">D_{KL}(p∥q)</script>，等价于最小化交叉熵<script type="math/tex">H(p,q)</script>​。</p><h3 id="为什么要用交叉熵做loss函数"><a href="#为什么要用交叉熵做loss函数" class="headerlink" title="为什么要用交叉熵做loss函数"></a>为什么要用交叉熵做loss函数</h3><p>在线性回归问题中，常常使用MSE（Mean Squared Error）作为loss函数，比如：</p><script type="math/tex; mode=display">loss = \frac{1}{2m}\sum_{i=1}^m(y_i-\hat{y_i})^2</script><p>这里的m表示m个样本的，loss为m个样本的loss均值。<br>MSE在<a href="# 回归问题">线性回归问题</a>中比较好用，那么在逻辑分类问题中还是如此么？</p><h3 id="交叉熵在单分类问题中的使用"><a href="#交叉熵在单分类问题中的使用" class="headerlink" title="交叉熵在单分类问题中的使用"></a>交叉熵在单分类问题中的使用</h3><p>这里的单类别是指，每一张图像样本只能有一个类别，比如只能是狗或只能是猫。<br>交叉熵在单分类问题上基本是标配的方法</p><script type="math/tex; mode=display">loss=-\sum_{i=1}^{n}y_ilog(\hat{y_i})</script><p>上式为一张样本的loss计算方法。n代表着n种类别。<br>举例说明,比如有如下样本</p><p>对应的标签和预测值</p><div class="table-container"><table><thead><tr><th>*</th><th>猫</th><th>青蛙</th><th>老鼠</th></tr></thead><tbody><tr><td>Label</td><td>0</td><td>1</td><td>0</td></tr><tr><td>Pred</td><td>0.3</td><td>0.6</td><td>0.1</td></tr></tbody></table></div><script type="math/tex; mode=display">\begin{eqnarray}loss&=&-(0\times log(0.3)+1\times log(0.6)+0\times log(0.1)\\&=&-log(0.6)\end{eqnarray}</script><p>对应的一个batch的loss就是</p><script type="math/tex; mode=display">loss=-\frac{1}{m}\sum_{j=1}^m\sum_{i=1}^{n}y_{ji}log(\hat{y_{ji}})</script><p>m为当前batch的样本数</p><h3 id="交叉熵在多分类问题中的使用"><a href="#交叉熵在多分类问题中的使用" class="headerlink" title="交叉熵在多分类问题中的使用"></a>交叉熵在多分类问题中的使用</h3><p>这里的多类别是指，每一张图像样本可以有多个类别，比如同时包含一只猫和一只狗<br>和单分类问题的标签不同，多分类的标签是n-hot。<br>比如下面这张样本图，即有青蛙，又有老鼠，所以是一个多分类问题</p><p>栗子</p><div class="table-container"><table><thead><tr><th>*</th><th>猫</th><th>青蛙</th><th>老鼠</th></tr></thead><tbody><tr><td>Label</td><td>0</td><td>1</td><td>1</td></tr><tr><td>Pred</td><td>0.1</td><td>0.7</td><td>0.8</td></tr></tbody></table></div><p>值得注意的是，这里的Pred不再是通过softmax计算的了，这里采用的是sigmoid。将每一个节点的输出归一化到[0,1]之间。所有Pred值的和也不再为1。换句话说，就是每一个Label都是独立分布的，相互之间没有影响。所以交叉熵在这里是单独对每一个节点进行计算，每一个节点只有两种可能值，所以是一个二项分布。前面说过对于二项分布这种特殊的分布，熵的计算可以进行简化。</p><p>同样的，交叉熵的计算也可以简化，即</p><script type="math/tex; mode=display">loss =-ylog(\hat{y})-(1-y)log(1-\hat{y})</script><p>注意，上式只是针对一个节点的计算公式。这一点一定要和单分类loss区分开来。<br>例子中可以计算为：</p><script type="math/tex; mode=display">\begin{eqnarray}loss_猫 &=&-0\times log(0.1)-(1-0)log(1-0.1)=-log(0.9)\\loss_蛙 &=&-1\times log(0.7)-(1-1)log(1-0.7)=-log(0.7)\\loss_鼠 &=&-1\times log(0.8)-(1-1)log(1-0.8)=-log(0.8)\end{eqnarray}</script><p>单张样本的loss即为<br>每一个batch的loss就是：</p><script type="math/tex; mode=display">loss =\sum_{j=1}^{m}\sum_{i=1}^{n}-y_{ji}log(\hat{y_{ji}})-(1-y_{ji})log(1-\hat{y_{ji}})</script><p>式中m为当前batch中的样本量，n为类别数。</p><h3 id="从最大似然看交叉熵"><a href="#从最大似然看交叉熵" class="headerlink" title="从最大似然看交叉熵"></a>从<a href="# 最大似然估计">最大似然</a>看交叉熵</h3><p>设有一组训练样本$X= {x_1,x_2,\cdots,x_m}$ ,该样本的分布为$p(x)$ 。假设使用$\theta$ 参数化模型得到$q(x;\theta)$ ，现用这个模型来估计$X$ 的概率分布，得到似然函数</p><script type="math/tex; mode=display">L(\theta) = q(X; \theta) = \prod_i^mq(x_i;\theta)</script><p>最大似然估计就是求得$\theta$ 使得$L(\theta)$ 的值最大，也就是</p><script type="math/tex; mode=display">\theta_{ML} = arg \max_{\theta} \prod_i^mq(x_i;\theta)</script><p>对上式的两边同时取$\log$ ，等价优化$\log$ 的最大似然估计即<code>log-likelyhood</code> ，最大对数似然估计</p><script type="math/tex; mode=display">\theta_{ML} = arg \max_\theta \sum_i^m \log q(x_i;\theta)</script><p>对上式的右边进行缩放并不会改变$arg \max$ 的解，上式的右边除以样本的个数$m$</p><script type="math/tex; mode=display">\theta_{ML} = arg \max_\theta \frac{1}{m}\sum_i^m\log q(x_i;\theta)</script><h4 id="和相对熵等价"><a href="#和相对熵等价" class="headerlink" title="和相对熵等价"></a>和相对熵等价</h4><p>上式的最大化$\theta_{ML}$ 是和没有训练样本没有关联的，就需要某种变换使其可以用训练的样本分布来表示，因为训练样本的分布可以看作是已知的，也是对最大化似然的一个约束条件。</p><p>注意上式的</p><script type="math/tex; mode=display">\frac{1}{m}\sum_i^m\log q(x_i;\theta)</script><p>相当于<strong>求随机变量$X$ 的函数$\log (X;\theta)$ 的均值</strong> ，根据大数定理，<strong>随着样本容量的增加，样本的算术平均值将趋近于随机变量的期望。</strong> 也就是说</p><script type="math/tex; mode=display">\frac{1}{m}\sum_i^m \log q(x_i;\theta) \rightarrow E_{x\sim P}(\log q(x;\theta))</script><p>其中$E_{X\sim P}$ 表示符合样本分布$P$ 的期望，这样就将最大似然估计使用真实样本的期望来表示</p><script type="math/tex; mode=display">\begin{aligned} \theta_{ML} &= arg \max_{\theta} E_{x\sim P}({\log q(x;\theta)}) \\ &= arg \min_{\theta} E_{x \sim P}(- \log q(x;\theta)) \end{aligned}</script><p>对右边取负号，将最大化变成最小化运算。</p><blockquote><p>上述的推导过程，可以参考 《Deep Learning》 的第五章。 但是，在书中变为期望的只有一句话，将式子的右边除以样本数量$m$ 进行缩放，从而可以将其变为$E_{x \sim p}\log q(x;\theta)$，没有细节过程，也可能是作者默认上面的变换对读者是一直。 确实是理解不了，查了很多文章，都是对这个变换的细节含糊其辞。一个周，对这个点一直耿耿于怀，就看了些关于概率论的科普书籍，其中共有介绍大数定理的：<strong>当样本容量趋于无穷时，样本的均值趋于其期望</strong>。</p><p>针对上面公式，除以$m$后，$\frac{1}{m}\sum<em>i^m\log q(x_i;\theta)$ ，确实是关于随机变量函数$\log q(x)$ 的算术平均值，而$x$ 是训练样本其分布是已知的$p(x)$ ，这样就得到了$E</em>{x \sim p}(\log q(x))$ 。</p></blockquote><script type="math/tex; mode=display">\begin{aligned} D_{KL}(p \parallel q) &= \sum_i p(x_i) log(\frac{p(x_i)}{q(x_i)})\\ &= E_{x\sim p}(\log \frac{p(x)}{q(x)}) \\ &= E_{x \sim p}(\log p(x) - \log q(x)) \\ &= E_{x \sim p}(\log p(x)) - E_{x \sim p} (\log q(x)) \end{aligned}</script><p>由于$E<em>{x \sim p} (\log p(x))$ 是训练样本的期望，是个固定的常数，在求最小值时可以忽略，所以最小化$D</em>{KL}(p \parallel q)$ 就变成了最小化$-E_{x\sim p}(\log q(x))$ ，这和最大似然估计是等价的。</p><h4 id="和交叉熵等价"><a href="#和交叉熵等价" class="headerlink" title="和交叉熵等价"></a>和交叉熵等价</h4><p>最大似然估计、相对熵、交叉熵的公式如下</p><script type="math/tex; mode=display">\begin{aligned}\theta_{ML} &= -arg \min_\theta E_{x\sim p}\log q(x;\theta) \\D_{KL} &= E_{x \sim p}\log p(x) - E_{x \sim p} \log q(x) \\H(p,q) &= -\sum_i^m p(x_i) \log q(x_i) = -E_{x \sim p} \log q(x)\end{aligned}\begin{aligned}\theta_{ML} &= arg \min_\theta E_{x\sim p}\log q(x;\theta) \\D_{KL} &= E_{x \sim p}\log p(x) - E_{x \sim p} \log q(x) \\H(p,q) &= -\sum_i^m p(x_i) \log q(x_i) = -E_{x \sim p} \log q(x)\end{aligned}</script><p>从上面可以看出，最小化交叉熵，也就是最小化$D<em>{KL}$ ，从而预测的分布$q(x)$ 和训练样本的真实分布$p(x)$ 最接近。而最小化$D</em>{KL}$ 和最大似然估计是等价的。</p><h3 id="多分类交叉熵"><a href="#多分类交叉熵" class="headerlink" title="多分类交叉熵"></a>多分类交叉熵</h3><p>多分类任务中输出的是目标属于<strong>每个类别的概率，所有类别概率的和为1，其中概率最大的类别就是目标所属的分类。</strong> 而<code>softmax</code> 函数能将一个向量的每个分量映射到$[0,1]$ 区间，并且对整个向量的输出做了归一化，保证所有分量输出的和为1，正好满足多分类任务的输出要求。所以，在多分类中，在最后就需要将提取的到特征经过<code>softmax</code>函数的，输出为每个类别的概率，然后再使用<strong>交叉熵</strong> 作为损失函数。</p><p><code>softmax</code>函数定义如下：</p><script type="math/tex; mode=display">S_i = \frac{e^{z_i}}{\sum^n_{i=1}e^{z_i}}</script><p>其中，输入的向量为$z_i(i = 1,2,\dots,n)$ 。</p><p>更直观的参见下图</p><p><img src="https://s2.loli.net/2024/06/07/XvLsuFKjBe39AaD.png" alt="img"></p><p>通过前面的特征提取到的特征向量为$(z_1,z_2,\dots,z_k)$ ，将向量输入到<code>softmax</code>函数中，即可得到目标属于每个类别的概率，概率最大的就是预测得到的目标的类别。</p><h4 id="Cross-Entropy-Loss"><a href="#Cross-Entropy-Loss" class="headerlink" title="Cross Entropy Loss"></a>Cross Entropy Loss</h4><p>使用<code>softmax</code>函数可以将特征向量映射为所属类别的概率，可以看作是预测类别的概率分布$q(c_i)$ ，有</p><script type="math/tex; mode=display">q(c_i) = \frac{e^{z_i}}{\sum^n_{i=1}e^{z_i}}</script><p>其中$c_i$ 为某个类别。</p><p>设训练数据中类别的概率分布为$p(c_i)$ ，那么目标分布$p(c_i)$ 和预测分布$q(c_i)$的交叉熵为</p><script type="math/tex; mode=display">H(p,q) =-\sum_ip(c_i)\log q(c_i)</script><p>每个训练样本所属的类别是已知的，并且每个样本只会属于一个类别（概率为1），属于其他类别概率为0。具体的，可以假设有个三分类任务，三个类分别是：猫，猪，狗。现有一个训练样本类别为猫，则有：</p><script type="math/tex; mode=display">\begin{align} p(cat) & = 1 \\ p(pig) &= 0 \\ p(dog) & = 0 \end{align}</script><p>通过预测得到的三个类别的概率分别为：$q(cat) = 0.6,q(pig) = 0.2,q(dog) = 0.2$ ，计算$p$ 和$q$ 的交叉熵为：</p><script type="math/tex; mode=display">\begin{aligned} H(p,q) &= -(p(cat) \log q(cat) + p(pig) + \log q(pig) + \log q(dog)) \\ &= - (1 \cdot \log 0.6 + 0 \cdot \log 0.2 +0 \cdot \log 0.2) \\ &= - \log 0.6 \\ &= - \log q(cat) \end{aligned}</script><p>利用这种特性，可以将样本的类别进行重新编码，就可以简化交叉熵的计算，这种编码方式就是<strong>one-hot</strong> 编码。以上面例子为例，</p><script type="math/tex; mode=display">\begin{aligned} \text{cat} &= (1 0 0) \\ \text{pig} &= (010) \\ \text{dog} &= (001) \end{aligned}</script><p>通过这种编码方式，在计算交叉熵时，只需要计算和训练样本对应类别预测概率的值，其他的项都是$0 \cdot \log q(c_i) = 0$ 。</p><p>具体的，交叉熵计算公式变成如下：</p><script type="math/tex; mode=display">(p,q) = - \log q(c_i)</script><p>其中$c_i$ 为训练样本对应的类别，上式也被称为<strong>负对数似然（negative log-likelihood,nll）</strong>。</p><h4 id="PyTorch中的Cross-Entropy"><a href="#PyTorch中的Cross-Entropy" class="headerlink" title="PyTorch中的Cross Entropy"></a>PyTorch中的Cross Entropy</h4><p>PyTorch中实现交叉熵损失的有三个函数<code>torch.nn.CrossEntropyLoss</code>，<code>torch.nn.LogSoftmax</code>以及<code>torch.nn.NLLLoss</code>。</p><ul><li><code>torch.nn.functional.log_softmax</code> 比较简单，输入为$n$维向量，指定要计算的维度<code>dim</code>，输出为$log(Softmax(x))$。其计算公式如下：</li></ul><script type="math/tex; mode=display">\text{LogSoftmax}(x_i) = \log (\frac{\exp(x_i)}{\sum_j \exp(x_j)})</script><p>没有额外的处理，就是对输入的$n$维向量的每个元素进行上述运算。</p><ul><li><code>torch.nn.functional.nll_loss</code> 负对数似然损失（Negative Log Likelihood Loss)，用于多分类，其输入的通常是<code>torch.nn.functional.log_softmax</code>的输出值。其函数如下</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.nll_loss(<span class="built_in">input</span>, target, weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index=-<span class="number">100</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><p><code>input</code> 也就是<code>log_softmax</code>的输出值，各个类别的对数概率。<code>target</code> 目标正确类别,<code>weight</code> 针对类别不平衡问题，可以为类别设置不同的权值；<code>ignore_index</code> 要忽略的类别，不参与loss的计算；比较重要的是<code>reduction</code> 的值，有三个取值：<code>none</code> 不做处理，输出的结果为向量；<code>mean</code> 将<code>none</code>结果求均值后输出；<code>sum</code> 将<code>none</code> 结果求和后输出。</p><ul><li><code>torch.nn.CrossEntropyLoss</code>就是上面两个函数的组合<code>nll_loss(log_softmax(input))</code>。</li></ul><h3 id="二分类交叉熵"><a href="#二分类交叉熵" class="headerlink" title="二分类交叉熵"></a>二分类交叉熵</h3><p>多分类中使用<code>softmax</code>函数将最后的输出映射为每个类别的概率，而在二分类中则通常使用<code>sigmoid</code> 将输出映射为正样本的概率。这是因为二分类中，只有两个类别：{正样本，负样本}，只需要求得正样本的概率$q$,则$1-q$ 就是负样本的概率。这也是多分类和二分类不同的地方。</p><p>$\text{sigmoid}$ 函数的表达式如下：</p><script type="math/tex; mode=display">\sigma(z) = \frac{1}{1 + e^{-z}}</script><p>sigmoid的输入为$z$ ，其输出为$(0,1)$ ，可以表示分类为正样本的概率。</p><p>二分类的交叉熵可以看作是交叉熵损失的一个特列，交叉熵为</p><script type="math/tex; mode=display">\text{$Cross\_Entorpy$}(p,q) = -\sum_i^m p(x_i) \log q(x_i)</script><p>这里只有两个类别$x \in {x_1,x_2}$ ，则有</p><script type="math/tex; mode=display">\begin{aligned}\text{$Cross\_Entorpy$}(p,q) &= -(p(x_1) \log q(x_1) + p(x_2) \log q(x_2)) \end{aligned}</script><p>因为只有两个选择，则有$p(x_1) + p(x_2) = 1,q(x_1) + q(x_2) = 1$ 。设，训练样本中$x_1$的概率为$p$，则$x_2$为$1-p$; 预测的$x_1$的概率为$q$，则$x_2$的预测概率为$1 - q$ 。则上式可改写为</p><script type="math/tex; mode=display">\text{$Cross\_Entropy$}(p,q) = -(p \log q + (1-p) \log (1-q))</script><p>也就是二分类交叉熵的损失函数。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>相对熵可以用来度量两个分布相似性，假设分布$p$是训练样本的分布，$q$是预测得到的分布。分类训练的过程实际上就是最小化$D_{KL}(p \parallel q)$，由于由于交叉熵</p><script type="math/tex; mode=display">H(p,q)= D_{KL}(p \parallel q) + H(p)</script><p>其中,$H(p)$是训练样本的熵，是一个已知的常量，这样最小化相对熵就等价于最小化交叉熵。</p><p>从最大似然估计转化为最小化负对数似然</p><script type="math/tex; mode=display">\theta_{ML} = -arg \min_\theta E_{x\sim p}\log q(x;\theta)</script><p>也等价于最小化相对熵。</p><h2 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h2><p>回归：人们在测量事物的时候因为客观条件所限，求得的都是测量值，而不是事物真实的值，为了能够得到真实值，无限次的进行测量，最后通过这些测量数据计算<strong>回归到真实值</strong>，这就是回归的由来。</p><p>回归分析的主要算法包括：</p><ol><li>线性回归(Linear Regression)</li><li>逻辑回归（Logistic regressions）</li><li>多项式回归(Polynomial Regression)</li><li>逐步回归(Step Regression)</li><li>岭回归(Ridge Regression)</li><li>套索回归(Lasso Regression)</li><li>弹性网回归(ElasticNet)</li></ol><h2 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h2><p>wiki定义：<code>在统计学中，最大似然估计（英语：maximum likelihood estimation，简作MLE），也称极大似然估计，是用来估计一个概率模型的参数的一种方法。</code></p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>给定一个概率分布𝐷，已知其<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5qaC546H5a+G5bqm5Ye95pWw">概率密度函数<i class="fa fa-external-link-alt"></i></span>（连续分布）或<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5qaC546H6LSo6YeP5Ye95pWw">概率质量函数<i class="fa fa-external-link-alt"></i></span>（离散分布）为𝑓𝐷，以及一个分布参数𝜃，我们可以从这个分布中抽出一个具有𝑛个值的采样𝑋1,𝑋2,…,𝑋𝑛，利用𝑓𝐷计算出其<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5Ly854S25Ye95pWw">似然函数<i class="fa fa-external-link-alt"></i></span>：</p><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a9702eeec5a8eb416883af66665ac11bd8151f0f" alt="{\displaystyle {\mbox{L}}(\theta \mid x_{1},\dots ,x_{n})=f_{\theta }(x_{1},\dots ,x_{n}).}"></p><p>若𝐷是离散分布，𝑓𝜃即是在参数为𝜃时观测到这一采样的概率；若其是连续分布，𝑓𝜃则为𝑋1,𝑋2,…,𝑋𝑛联合分布的概率密度函数在观测值处的取值。一旦我们获得𝑋1,𝑋2,…,𝑋𝑛，我们就能求得一个关于𝜃的估计。最大似然估计会寻找关于𝜃的最可能的值（即，在所有可能的𝜃取值中，寻找一个值使这个采样的“可能性”最大化）。从数学上来说，我们可以在𝜃的所有可能取值中寻找一个值使得似然<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5Ye95pWw">函数<i class="fa fa-external-link-alt"></i></span>取到最大值。这个使可能性最大的<script type="math/tex">\hat 𝜃</script>值即称为𝜃的<strong>最大似然估计</strong>。由定义，最大似然估计是样本的函数。</p><p><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5pyA5aSn5Ly854S25Lyw6K6h">最大似然估计 - 维基百科，自由的百科全书 (wikipedia.org)<i class="fa fa-external-link-alt"></i></span></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;函数式自动微分&quot;&gt;&lt;a href=&quot;#函数式自动微分&quot; class=&quot;headerlink&quot; title=&quot;函数式自动微分&quot;&gt;&lt;/a&gt;函数式自动微分&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;神经网络的训练主要使用反向传播算法，模型预测值（logits）与正确标签（label）送入损失函数（loss function）获得loss，然后进行反向传播计算，求得梯度（gradients），最终更新至模型参数（parameters）。自动微分能够计算可导函数在某点处的导数值，是反向传播算法的一般化。自动微分主要解决的问题是将一个复杂的数学运算分解为一系列简单的基本运算，该功能对用户屏蔽了大量的求导细节和过程，大大降低了框架的使用门槛。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="专题" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/"/>
    
    <category term="机器学习" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Mindspore" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/"/>
    
    <category term="基本概念" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
    
    <category term="机器学习" scheme="https://deepcity.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="MindSpore" scheme="https://deepcity.github.io/tags/MindSpore/"/>
    
    <category term="目录" scheme="https://deepcity.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>MindSpore专题——番外、Trans Fore模型</title>
    <link href="https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/TransformerStructure/article.html"/>
    <id>https://deepcity.github.io/2024/special_subject/MindSpore/Chapters/TransformerStructure/article.html</id>
    <published>2024-08-14T11:47:58.000Z</published>
    <updated>2024-08-16T08:59:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p>Transformer是一种神经网络结构，有Vaswani等人在2017年的论文“Attention Is All You Need”中提出，用于处理机器翻译、语言建模和文本生成登自然语言处理任务。</p><span id="more"></span><p>Transformer与传统NLP特征提取类模型的区别主要在以下两点。</p><ul><li>Transformer是一个纯基于注意力机制的结构，并将自<strong>注意力机制</strong>和<strong>多头注意力机制</strong>的概念运用到模型中；</li><li>由于缺少RNN模型的时序性，Transformer引入了位置编码，在数据上而非模型中添加位置信息；</li></ul><p>以上的处理带来了几个优点</p><ul><li>更容易并行化，训练更加高效；</li><li>在处理长序列的任务中表现优秀，可以快速捕捉长距离中的关联信息；</li></ul><h2 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h2><p>注意力机制是判断词在句子中的重要性，通过<strong>注意力分数</strong>来表达某个词在句子中的重要性</p><h3 id="注意力分数的计算"><a href="#注意力分数的计算" class="headerlink" title="注意力分数的计算"></a>注意力分数的计算</h3><h4 id="query、key、value"><a href="#query、key、value" class="headerlink" title="query、key、value"></a>query、key、value</h4><ul><li>query:任务内容<em>目标序列</em></li><li>key:索引/标签（帮助定位到答案）<em>原序列</em></li><li>value:答案</li></ul><p><img src="https://s2.loli.net/2024/06/29/ESPv4kLWxinFZqy.png" alt="image-20240629145758835"></p><h4 id="常用的计算注意力分数的方法"><a href="#常用的计算注意力分数的方法" class="headerlink" title="常用的计算注意力分数的方法"></a>常用的计算注意力分数的方法</h4><p>additive attention可加性注意力计算方法</p><p>scaled dot-product attention缩放的“点-积”注意力</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Transformer&quot;&gt;&lt;a href=&quot;#Transformer&quot; class=&quot;headerlink&quot; title=&quot;Transformer&quot;&gt;&lt;/a&gt;Transformer&lt;/h1&gt;&lt;p&gt;Transformer是一种神经网络结构，有Vaswani等人在2017年的论文“Attention Is All You Need”中提出，用于处理机器翻译、语言建模和文本生成登自然语言处理任务。&lt;/p&gt;</summary>
    
    
    
    <category term="专题" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/"/>
    
    <category term="机器学习" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="Mindspore" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/"/>
    
    <category term="基本概念" scheme="https://deepcity.github.io/categories/%E4%B8%93%E9%A2%98/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Mindspore/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    
    
    <category term="机器学习" scheme="https://deepcity.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="MindSpore" scheme="https://deepcity.github.io/tags/MindSpore/"/>
    
    <category term="目录" scheme="https://deepcity.github.io/tags/%E7%9B%AE%E5%BD%95/"/>
    
  </entry>
  
</feed>
